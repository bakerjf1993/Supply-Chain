{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# For Prediction:\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib as mpl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# For nice Plots\n",
    "%matplotlib inline\n",
    "plt.style.use('default')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.abspath(\"\")\n",
    "fname = dir_path+'\\countrydf.csv'\n",
    "countrydf = pd.read_csv(fname, encoding='latin-1')\n",
    "countrydf = countrydf.drop([\"Country\", \"Year\"],axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0   level_0     index  \\\n",
      "0      -1.730448 -1.735120 -1.732732   \n",
      "1      -1.727240 -1.731986 -1.729883   \n",
      "2      -1.724033 -1.728851 -1.727033   \n",
      "3      -1.720825 -1.725717 -1.724184   \n",
      "4      -1.717618 -1.722583 -1.721334   \n",
      "...          ...       ...       ...   \n",
      "1075    1.717618  1.697043  1.695225   \n",
      "1076    1.720825  1.700177  1.698074   \n",
      "1077    1.724033  1.703312  1.700924   \n",
      "1078    1.727240  1.706446  1.703773   \n",
      "1079    1.730448  1.709581  1.712322   \n",
      "\n",
      "      Average dietary energy supply adequacy (percent) (3-year average)  \\\n",
      "0                                              1.031639                   \n",
      "1                                              1.169786                   \n",
      "2                                              1.238859                   \n",
      "3                                              1.238859                   \n",
      "4                                              1.307932                   \n",
      "...                                                 ...                   \n",
      "1075                                           0.202758                   \n",
      "1076                                           0.202758                   \n",
      "1077                                           0.202758                   \n",
      "1078                                           0.202758                   \n",
      "1079                                                NaN                   \n",
      "\n",
      "      Dietary energy supply used in the estimation of prevalence of undernourishment (kcal/cap/day) (3-year average)  \\\n",
      "0                                              1.101521                                                                \n",
      "1                                              1.244594                                                                \n",
      "2                                              1.338241                                                                \n",
      "3                                              1.372058                                                                \n",
      "4                                              1.447497                                                                \n",
      "...                                                 ...                                                                \n",
      "1075                                           0.196263                                                                \n",
      "1076                                           0.191060                                                                \n",
      "1077                                           0.193661                                                                \n",
      "1078                                           0.193661                                                                \n",
      "1079                                                NaN                                                                \n",
      "\n",
      "      Share of dietary energy supply derived from cereals, roots and tubers (kcal/cap/day) (3-year average)  \\\n",
      "0                                             -0.153666                                                       \n",
      "1                                             -0.153666                                                       \n",
      "2                                             -0.153666                                                       \n",
      "3                                             -0.153666                                                       \n",
      "4                                             -0.153666                                                       \n",
      "...                                                 ...                                                       \n",
      "1075                                           0.069055                                                       \n",
      "1076                                           0.180416                                                       \n",
      "1077                                           0.180416                                                       \n",
      "1078                                                NaN                                                       \n",
      "1079                                                NaN                                                       \n",
      "\n",
      "      Average protein supply (g/cap/day) (3-year average)  \\\n",
      "0                                              0.851812     \n",
      "1                                              1.006831     \n",
      "2                                              1.136014     \n",
      "3                                              1.239360     \n",
      "4                                              1.258737     \n",
      "...                                                 ...     \n",
      "1075                                          -0.013711     \n",
      "1076                                          -0.007252     \n",
      "1077                                          -0.033088     \n",
      "1078                                                NaN     \n",
      "1079                                                NaN     \n",
      "\n",
      "      Average supply of protein of animal origin (g/cap/day) (3-year average)  \\\n",
      "0                                              0.286648                         \n",
      "1                                              0.321965                         \n",
      "2                                              0.404369                         \n",
      "3                                              0.439685                         \n",
      "4                                              0.522090                         \n",
      "...                                                 ...                         \n",
      "1075                                          -0.349043                         \n",
      "1076                                          -0.360816                         \n",
      "1077                                          -0.372588                         \n",
      "1078                                                NaN                         \n",
      "1079                                                NaN                         \n",
      "\n",
      "      Rail lines density (total route in km per 100 square km of land area)  \\\n",
      "0                                             -0.709593                       \n",
      "1                                             -0.709593                       \n",
      "2                                             -0.709593                       \n",
      "3                                             -0.709593                       \n",
      "4                                             -0.709593                       \n",
      "...                                                 ...                       \n",
      "1075                                                NaN                       \n",
      "1076                                                NaN                       \n",
      "1077                                                NaN                       \n",
      "1078                                                NaN                       \n",
      "1079                                                NaN                       \n",
      "\n",
      "      Gross domestic product per capita, PPP, (constant 2017 international $)  \\\n",
      "0                                                   NaN                         \n",
      "1                                                   NaN                         \n",
      "2                                                   NaN                         \n",
      "3                                                   NaN                         \n",
      "4                                                   NaN                         \n",
      "...                                                 ...                         \n",
      "1075                                          -0.101883                         \n",
      "1076                                          -0.095549                         \n",
      "1077                                          -0.094331                         \n",
      "1078                                          -0.132666                         \n",
      "1079                                                NaN                         \n",
      "\n",
      "      ...  Number of severely food insecure people (million) (annual value)  \\\n",
      "0     ...                                                NaN                  \n",
      "1     ...                                                NaN                  \n",
      "2     ...                                                NaN                  \n",
      "3     ...                                                NaN                  \n",
      "4     ...                                                NaN                  \n",
      "...   ...                                                ...                  \n",
      "1075  ...                                           0.208498                  \n",
      "1076  ...                                           0.173330                  \n",
      "1077  ...                                           0.683272                  \n",
      "1078  ...                                           1.747117                  \n",
      "1079  ...                                                NaN                  \n",
      "\n",
      "      Number of severely food insecure male adults (million) (annual value)  \\\n",
      "0                                                   NaN                       \n",
      "1                                                   NaN                       \n",
      "2                                                   NaN                       \n",
      "3                                                   NaN                       \n",
      "4                                                   NaN                       \n",
      "...                                                 ...                       \n",
      "1075                                           0.817332                       \n",
      "1076                                           0.289449                       \n",
      "1077                                           0.553391                       \n",
      "1078                                           1.399557                       \n",
      "1079                                                NaN                       \n",
      "\n",
      "      Number of severely food insecure female adults (million) (annual value)  \\\n",
      "0                                                   NaN                         \n",
      "1                                                   NaN                         \n",
      "2                                                   NaN                         \n",
      "3                                                   NaN                         \n",
      "4                                                   NaN                         \n",
      "...                                                 ...                         \n",
      "1075                                           0.456586                         \n",
      "1076                                           0.341618                         \n",
      "1077                                           0.694185                         \n",
      "1078                                           1.537281                         \n",
      "1079                                                NaN                         \n",
      "\n",
      "      Number of moderately or severely food insecure people (million) (annual value)  \\\n",
      "0                                                   NaN                                \n",
      "1                                                   NaN                                \n",
      "2                                                   NaN                                \n",
      "3                                                   NaN                                \n",
      "4                                                   NaN                                \n",
      "...                                                 ...                                \n",
      "1075                                           0.189034                                \n",
      "1076                                           0.366241                                \n",
      "1077                                           0.765928                                \n",
      "1078                                           1.618335                                \n",
      "1079                                                NaN                                \n",
      "\n",
      "      Number of moderately or severely food insecure male adults (million) (annual value)  \\\n",
      "0                                                   NaN                                     \n",
      "1                                                   NaN                                     \n",
      "2                                                   NaN                                     \n",
      "3                                                   NaN                                     \n",
      "4                                                   NaN                                     \n",
      "...                                                 ...                                     \n",
      "1075                                           0.408950                                     \n",
      "1076                                           0.510033                                     \n",
      "1077                                           0.683894                                     \n",
      "1078                                           1.460207                                     \n",
      "1079                                                NaN                                     \n",
      "\n",
      "      Number of moderately or severely food insecure female adults (million) (annual value)  \\\n",
      "0                                                   NaN                                       \n",
      "1                                                   NaN                                       \n",
      "2                                                   NaN                                       \n",
      "3                                                   NaN                                       \n",
      "4                                                   NaN                                       \n",
      "...                                                 ...                                       \n",
      "1075                                           0.407193                                       \n",
      "1076                                           0.329493                                       \n",
      "1077                                           0.812048                                       \n",
      "1078                                           1.478629                                       \n",
      "1079                                                NaN                                       \n",
      "\n",
      "          Port  Resiliency  Scraper Average year  Future Undernourishment  \n",
      "0     1.187051    3.529440             -1.602383                     -0.7  \n",
      "1     1.187051    3.529440             -1.602383                     -0.3  \n",
      "2     1.187051    3.529440             -1.602966                      0.0  \n",
      "3     1.187051    3.529440             -1.602383                     -0.3  \n",
      "4     1.187051    3.529440             -1.602383                     -0.3  \n",
      "...        ...         ...                   ...                      ...  \n",
      "1075 -0.842424   -0.031036              0.013426                      0.4  \n",
      "1076 -0.842424   -0.031036              0.013426                      0.3  \n",
      "1077 -0.842424   -0.031036              0.013426                      1.1  \n",
      "1078 -0.842424   -0.031036              0.013205                      1.1  \n",
      "1079 -0.842424   -0.031036              0.013426                      NaN  \n",
      "\n",
      "[1080 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "# Build a test set and training set\n",
    "\n",
    "cols_to_standardize = countrydf.columns.drop(['Future Undernourishment'])\n",
    "scaler = StandardScaler()\n",
    "countrydf[cols_to_standardize] = scaler.fit_transform(countrydf[cols_to_standardize])\n",
    "\n",
    "# Print the standardized dataframe\n",
    "print(countrydf)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  countrydf.drop([\"Future Undernourishment\"], axis=1), countrydf[\"Future Undernourishment\"], test_size=1/3, random_state = 42)\n",
    "\n",
    "# Replace all the NaNs with the column mean, \n",
    "# and build the test set and training set using the indicies from the first set\n",
    "countrydf2 = countrydf.fillna(countrydf.mean())\n",
    "# Build a test set and training set\n",
    "X_train2 = countrydf2.drop([\"Future Undernourishment\"], axis=1).iloc[X_train.index]\n",
    "X_test2 = countrydf2.drop([\"Future Undernourishment\"], axis=1).iloc[X_test.index]\n",
    "y_train2 = countrydf2[\"Future Undernourishment\"].iloc[y_train.index]\n",
    "y_test2 = countrydf2[\"Future Undernourishment\"].iloc[y_test.index]\n",
    "\n",
    "# Use only rows with non-NaN response variable, then replace all the NaNs with the column mean \n",
    "# and build the test set and training set using the indicies from the first set\n",
    "keep_indices_test = np.where(y_test.notna())\n",
    "keep_indices_train = np.where(y_train.notna())\n",
    "# Build a test set and training set\n",
    "X_train3 = X_train2.iloc[keep_indices_train]\n",
    "X_test3 = X_test2.iloc[keep_indices_test]\n",
    "y_train3 = y_train2.iloc[keep_indices_train]\n",
    "y_test3 = y_test2.iloc[keep_indices_test]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(loss, val_loss):\n",
    "    plt.plot(np.arange(len(loss)) + 0.5, loss, \"b.-\", label=\"Training loss\")\n",
    "    plt.plot(np.arange(len(val_loss)) + 1, val_loss, \"r.-\", label=\"Validation loss\")\n",
    "    plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
    "    #plt.axis([1, 20, 0, 0.05])\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN for Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def build_model2(n_hidden=1, n_neurons=60, learning_rate=1e-3, input_shape=X_train2.shape[1]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stvp2\\AppData\\Local\\Temp\\ipykernel_2940\\3141062689.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model2)\n"
     ]
    }
   ],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "Epoch 1/160\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 2.0848 - val_loss: 1.5086\n",
      "Epoch 2/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.8889 - val_loss: 1.4109\n",
      "Epoch 3/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.7278 - val_loss: 1.3543\n",
      "Epoch 4/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.5375 - val_loss: 1.3510\n",
      "Epoch 5/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.3376 - val_loss: 1.3180\n",
      "Epoch 6/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.1716 - val_loss: 1.3311\n",
      "Epoch 7/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.0989 - val_loss: 1.2482\n",
      "Epoch 8/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.0183 - val_loss: 1.3749\n",
      "Epoch 9/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.8857 - val_loss: 1.3109\n",
      "Epoch 10/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.8355 - val_loss: 1.2352\n",
      "Epoch 11/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.7491 - val_loss: 1.2552\n",
      "Epoch 12/160\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.7194 - val_loss: 1.1912\n",
      "Epoch 13/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6318 - val_loss: 1.2227\n",
      "Epoch 14/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5840 - val_loss: 1.2393\n",
      "Epoch 15/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5523 - val_loss: 1.2942\n",
      "Epoch 16/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5933 - val_loss: 1.2279\n",
      "Epoch 17/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5194 - val_loss: 1.1979\n",
      "Epoch 18/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5090 - val_loss: 1.2731\n",
      "Epoch 19/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3861 - val_loss: 1.2018\n",
      "Epoch 20/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4011 - val_loss: 1.3395\n",
      "Epoch 21/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4338 - val_loss: 1.2313\n",
      "Epoch 22/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4159 - val_loss: 1.2031\n",
      "Epoch 23/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3616 - val_loss: 1.2795\n",
      "Epoch 24/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3399 - val_loss: 1.1773\n",
      "Epoch 25/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3269 - val_loss: 1.2184\n",
      "Epoch 26/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2994 - val_loss: 1.2009\n",
      "Epoch 27/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2898 - val_loss: 1.2316\n",
      "Epoch 28/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2997 - val_loss: 1.2496\n",
      "Epoch 29/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3301 - val_loss: 1.2914\n",
      "Epoch 30/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2705 - val_loss: 1.1759\n",
      "Epoch 31/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2654 - val_loss: 1.2584\n",
      "Epoch 32/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2828 - val_loss: 1.2895\n",
      "Epoch 33/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2893 - val_loss: 1.3069\n",
      "Epoch 34/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2550 - val_loss: 1.2365\n",
      "Epoch 35/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2384 - val_loss: 1.2040\n",
      "Epoch 36/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3196 - val_loss: 1.3640\n",
      "Epoch 37/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2533 - val_loss: 1.2899\n",
      "Epoch 38/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2356 - val_loss: 1.2086\n",
      "Epoch 39/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2331 - val_loss: 1.2252\n",
      "Epoch 40/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2498 - val_loss: 1.3260\n",
      "Epoch 41/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2743 - val_loss: 1.2189\n",
      "Epoch 42/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2153 - val_loss: 1.2638\n",
      "Epoch 43/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2198 - val_loss: 1.1957\n",
      "Epoch 44/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2155 - val_loss: 1.2062\n",
      "Epoch 45/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1984 - val_loss: 1.1361\n",
      "Epoch 46/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1880 - val_loss: 1.2027\n",
      "Epoch 47/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2159 - val_loss: 1.2377\n",
      "Epoch 48/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2014 - val_loss: 1.1952\n",
      "Epoch 49/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1536 - val_loss: 1.2141\n",
      "Epoch 50/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1447 - val_loss: 1.1854\n",
      "Epoch 51/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1953 - val_loss: 1.1674\n",
      "Epoch 52/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2155 - val_loss: 1.1716\n",
      "Epoch 53/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1578 - val_loss: 1.1871\n",
      "Epoch 54/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1498 - val_loss: 1.1789\n",
      "Epoch 55/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1303 - val_loss: 1.2208\n",
      "Epoch 56/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1286 - val_loss: 1.1760\n",
      "Epoch 57/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1356 - val_loss: 1.2011\n",
      "Epoch 58/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1232 - val_loss: 1.2270\n",
      "Epoch 59/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1355 - val_loss: 1.1906\n",
      "Epoch 60/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1167 - val_loss: 1.1917\n",
      "Epoch 61/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1468 - val_loss: 1.1349\n",
      "Epoch 62/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1430 - val_loss: 1.2038\n",
      "Epoch 63/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1391 - val_loss: 1.1673\n",
      "Epoch 64/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1540 - val_loss: 1.2149\n",
      "Epoch 65/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1439 - val_loss: 1.1621\n",
      "Epoch 66/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1951 - val_loss: 1.3078\n",
      "Epoch 67/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1647 - val_loss: 1.2532\n",
      "Epoch 68/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1905 - val_loss: 1.1928\n",
      "Epoch 69/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1517 - val_loss: 1.1824\n",
      "Epoch 70/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1269 - val_loss: 1.1596\n",
      "Epoch 71/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1196 - val_loss: 1.2270\n",
      "Epoch 72/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1134 - val_loss: 1.1719\n",
      "Epoch 73/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1161 - val_loss: 1.1519\n",
      "Epoch 74/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1414 - val_loss: 1.2168\n",
      "Epoch 75/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1293 - val_loss: 1.1904\n",
      "Epoch 76/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1028 - val_loss: 1.2111\n",
      "Epoch 77/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1135 - val_loss: 1.3517\n",
      "Epoch 78/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1350 - val_loss: 1.1551\n",
      "Epoch 79/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1069 - val_loss: 1.2057\n",
      "Epoch 80/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0997 - val_loss: 1.2025\n",
      "Epoch 81/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0914 - val_loss: 1.2594\n",
      "Epoch 82/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1073 - val_loss: 1.1697\n",
      "Epoch 83/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1170 - val_loss: 1.2457\n",
      "Epoch 84/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1009 - val_loss: 1.2942\n",
      "Epoch 85/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1029 - val_loss: 1.1602\n",
      "Epoch 86/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1318 - val_loss: 1.2153\n",
      "Epoch 87/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1459 - val_loss: 1.2790\n",
      "Epoch 88/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1268 - val_loss: 1.1521\n",
      "Epoch 89/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1024 - val_loss: 1.1605\n",
      "Epoch 90/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0962 - val_loss: 1.1723\n",
      "Epoch 91/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1058 - val_loss: 1.1616\n",
      "Epoch 92/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0898 - val_loss: 1.2000\n",
      "Epoch 93/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0851 - val_loss: 1.2318\n",
      "Epoch 94/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0920 - val_loss: 1.2311\n",
      "Epoch 95/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1084 - val_loss: 1.1795\n",
      "Epoch 96/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1125 - val_loss: 1.1859\n",
      "Epoch 97/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0828 - val_loss: 1.2241\n",
      "Epoch 98/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0835 - val_loss: 1.2029\n",
      "Epoch 99/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0749 - val_loss: 1.1755\n",
      "Epoch 100/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0739 - val_loss: 1.1461\n",
      "Epoch 101/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 1.1610\n",
      "Epoch 102/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 1.1560\n",
      "Epoch 103/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0718 - val_loss: 1.2110\n",
      "Epoch 104/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1047 - val_loss: 1.1875\n",
      "Epoch 105/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1158 - val_loss: 1.2407\n",
      "Epoch 106/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1065 - val_loss: 1.1663\n",
      "Epoch 107/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 1.2587\n",
      "Epoch 108/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0882 - val_loss: 1.1617\n",
      "Epoch 109/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0749 - val_loss: 1.1938\n",
      "Epoch 110/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0779 - val_loss: 1.1434\n",
      "Epoch 111/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0944 - val_loss: 1.1694\n",
      "Epoch 112/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0991 - val_loss: 1.2684\n",
      "Epoch 113/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0788 - val_loss: 1.3330\n",
      "Epoch 114/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1086 - val_loss: 1.1988\n",
      "Epoch 115/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1684 - val_loss: 1.2102\n",
      "Epoch 116/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1210 - val_loss: 1.2704\n",
      "Epoch 117/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1010 - val_loss: 1.2007\n",
      "Epoch 118/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0905 - val_loss: 1.1732\n",
      "Epoch 119/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0735 - val_loss: 1.1907\n",
      "Epoch 120/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0886 - val_loss: 1.1851\n",
      "Epoch 121/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0949 - val_loss: 1.2299\n",
      "Epoch 122/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0855 - val_loss: 1.2001\n",
      "Epoch 123/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 1.1800\n",
      "Epoch 124/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0681 - val_loss: 1.2149\n",
      "Epoch 125/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 1.1494\n",
      "Epoch 126/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0932 - val_loss: 1.1571\n",
      "Epoch 127/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0910 - val_loss: 1.1865\n",
      "Epoch 128/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0608 - val_loss: 1.1850\n",
      "Epoch 129/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0542 - val_loss: 1.1663\n",
      "Epoch 130/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 1.1620\n",
      "Epoch 131/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0592 - val_loss: 1.1910\n",
      "Epoch 132/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0702 - val_loss: 1.1544\n",
      "Epoch 133/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0915 - val_loss: 1.2706\n",
      "Epoch 134/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0730 - val_loss: 1.1791\n",
      "Epoch 135/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0700 - val_loss: 1.1834\n",
      "Epoch 136/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 1.1736\n",
      "Epoch 137/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0816 - val_loss: 1.1700\n",
      "Epoch 138/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 1.1649\n",
      "Epoch 139/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0782 - val_loss: 1.2137\n",
      "Epoch 140/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1078 - val_loss: 1.2279\n",
      "Epoch 141/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0818 - val_loss: 1.2253\n",
      "Epoch 142/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0833 - val_loss: 1.1619\n",
      "Epoch 143/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0636 - val_loss: 1.2193\n",
      "Epoch 144/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0692 - val_loss: 1.2784\n",
      "Epoch 145/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0837 - val_loss: 1.1841\n",
      "Epoch 146/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 1.2293\n",
      "Epoch 147/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0709 - val_loss: 1.2274\n",
      "Epoch 148/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 1.1853\n",
      "Epoch 149/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0713 - val_loss: 1.1584\n",
      "Epoch 150/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 1.2382\n",
      "Epoch 151/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0779 - val_loss: 1.1934\n",
      "Epoch 152/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1821 - val_loss: 1.1821\n",
      "Epoch 153/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1248 - val_loss: 1.2736\n",
      "Epoch 154/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1099 - val_loss: 1.1872\n",
      "Epoch 155/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1201 - val_loss: 1.3096\n",
      "Epoch 156/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0998 - val_loss: 1.2270\n",
      "Epoch 157/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1311 - val_loss: 1.1533\n",
      "Epoch 158/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0989 - val_loss: 1.1824\n",
      "Epoch 159/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0781 - val_loss: 1.2107\n",
      "Epoch 160/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0957 - val_loss: 1.1244\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.random.set_seed(42)\n",
    "# define the input shape and number of classes\n",
    "input_shape = X_train2.shape[1]\n",
    "num_classes = 1\n",
    "\n",
    "# define the model architecture\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(70, activation='relu', input_shape=(input_shape,)))\n",
    "for i in range(3):\n",
    "    model.add(layers.Dense(70, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='linear'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "# compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "#print(model.summary())\n",
    "print(input_shape)\n",
    "\n",
    "# train the model\n",
    "history2 = model.fit(X_train2, y_train2, epochs=160, validation_data=(X_test2, y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0847818851470947, 1.888895869255066, 1.7278438806533813, 1.5375350713729858, 1.3376026153564453, 1.1716220378875732, 1.0989210605621338, 1.0183454751968384, 0.8856675028800964, 0.835529088973999, 0.749119222164154, 0.7194255590438843, 0.631784975528717, 0.5840088129043579, 0.5522759556770325, 0.5932582020759583, 0.5193998217582703, 0.5089846253395081, 0.38608962297439575, 0.4010925590991974, 0.4337930381298065, 0.41592204570770264, 0.36159032583236694, 0.3398534059524536, 0.3268947899341583, 0.29944977164268494, 0.2898210287094116, 0.2997189164161682, 0.3301297426223755, 0.27045950293540955, 0.26537024974823, 0.2827637493610382, 0.289347767829895, 0.25502145290374756, 0.23844201862812042, 0.31962090730667114, 0.2533334493637085, 0.2355915904045105, 0.23309169709682465, 0.24978934228420258, 0.27428844571113586, 0.21525166928768158, 0.2197580188512802, 0.21545936167240143, 0.19838331639766693, 0.1880050003528595, 0.21593967080116272, 0.20144765079021454, 0.15358327329158783, 0.14468495547771454, 0.19526168704032898, 0.21545928716659546, 0.157806396484375, 0.14975546300411224, 0.13028961420059204, 0.12857897579669952, 0.13561558723449707, 0.12323120981454849, 0.13550041615962982, 0.11674639582633972, 0.14681211113929749, 0.14297610521316528, 0.13914704322814941, 0.15398669242858887, 0.14394798874855042, 0.19514380395412445, 0.16467627882957458, 0.19045884907245636, 0.1516808569431305, 0.12687772512435913, 0.11963192373514175, 0.11339756846427917, 0.1160958856344223, 0.14139796793460846, 0.12929390370845795, 0.1027512326836586, 0.11350967735052109, 0.13502854108810425, 0.10693436861038208, 0.09971962869167328, 0.09144081175327301, 0.10727909952402115, 0.1170249730348587, 0.1008734256029129, 0.10287093371152878, 0.13178464770317078, 0.1459493190050125, 0.12678737938404083, 0.10241289436817169, 0.09617029130458832, 0.10583298653364182, 0.08980897068977356, 0.08510900288820267, 0.09197498857975006, 0.1084425300359726, 0.11246894299983978, 0.08284222334623337, 0.08349081873893738, 0.07492004334926605, 0.07386282086372375, 0.07194684445858002, 0.08059313148260117, 0.07184997946023941, 0.10469265282154083, 0.11577516049146652, 0.10653410106897354, 0.080476313829422, 0.088226817548275, 0.074858158826828, 0.0779326856136322, 0.09440089017152786, 0.0991184264421463, 0.07881234586238861, 0.1085599809885025, 0.16836956143379211, 0.12103715538978577, 0.10102171450853348, 0.09050871431827545, 0.07351832091808319, 0.08856718242168427, 0.09490916877985, 0.08551594614982605, 0.06858931481838226, 0.06807684898376465, 0.07714059948921204, 0.09315932542085648, 0.09102413058280945, 0.06078135222196579, 0.054213639348745346, 0.045460134744644165, 0.059238310903310776, 0.0702303946018219, 0.09150043874979019, 0.0729939416050911, 0.07000929862260818, 0.07060681283473969, 0.08161159604787827, 0.05855875089764595, 0.07820284366607666, 0.10781765729188919, 0.08179346472024918, 0.08329872041940689, 0.0635596364736557, 0.06919194012880325, 0.08371055126190186, 0.070339635014534, 0.07092180103063583, 0.05697369948029518, 0.0713028684258461, 0.07512345910072327, 0.07785011827945709, 0.18207626044750214, 0.124763622879982, 0.10986430943012238, 0.12006843090057373, 0.09975898265838623, 0.13110555708408356, 0.09892504662275314, 0.07807827740907669, 0.09566116333007812]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history2.history[\"loss\"])\n",
    "plot_learning_curves(np.sqrt(history2.history[\"loss\"]), np.sqrt(history2.history[\"val_loss\"]))\n",
    "plt.ylim(0,2)\n",
    "plt.show()\n",
    "#plt.savefig(\"deepfoodsecurity.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 10ms/step - loss: 2.1563 - val_loss: 1.5829\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0289 - val_loss: 1.5429\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9692 - val_loss: 1.5253\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8964 - val_loss: 1.5199\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8256 - val_loss: 1.5070\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6860 - val_loss: 1.5054\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5591 - val_loss: 1.5539\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4614 - val_loss: 1.4844\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2842 - val_loss: 1.4962\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1691 - val_loss: 1.5562\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0142 - val_loss: 1.4396\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9244 - val_loss: 1.5366\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8355 - val_loss: 1.5688\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7608 - val_loss: 1.4923\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6488 - val_loss: 1.4857\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6017 - val_loss: 1.4365\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5488 - val_loss: 1.3972\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4995 - val_loss: 1.4266\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4623 - val_loss: 1.4951\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4441 - val_loss: 1.3902\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5053 - val_loss: 1.3703\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4739 - val_loss: 1.3723\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4460 - val_loss: 1.5205\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4002 - val_loss: 1.4750\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3775 - val_loss: 1.4258\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3686 - val_loss: 1.5165\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3408 - val_loss: 1.4644\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3043 - val_loss: 1.4645\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3106 - val_loss: 1.5162\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3242 - val_loss: 1.4266\n",
      "Epoch 31/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3293 - val_loss: 1.5112\n",
      "8/8 [==============================] - 0s 861us/step - loss: 1.3841\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=5, n_neurons=33; total time=   2.0s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 2.2593 - val_loss: 1.5761\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.1367 - val_loss: 1.5278\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0591 - val_loss: 1.4869\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9610 - val_loss: 1.4519\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8570 - val_loss: 1.4401\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7375 - val_loss: 1.4287\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6025 - val_loss: 1.4115\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4797 - val_loss: 1.3889\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3814 - val_loss: 1.4245\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2742 - val_loss: 1.4147\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1507 - val_loss: 1.3862\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0987 - val_loss: 1.5583\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0448 - val_loss: 1.3435\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9586 - val_loss: 1.3304\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9038 - val_loss: 1.3617\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8257 - val_loss: 1.4606\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7758 - val_loss: 1.3077\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7394 - val_loss: 1.5003\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6914 - val_loss: 1.3584\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6302 - val_loss: 1.2963\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6396 - val_loss: 1.3820\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5897 - val_loss: 1.2881\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5887 - val_loss: 1.3877\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4822 - val_loss: 1.3161\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4132 - val_loss: 1.3743\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.3872 - val_loss: 1.3325\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3804 - val_loss: 1.4267\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3690 - val_loss: 1.3424\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3224 - val_loss: 1.3425\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3146 - val_loss: 1.3456\n",
      "Epoch 31/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2773 - val_loss: 1.4032\n",
      "Epoch 32/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2610 - val_loss: 1.3561\n",
      "8/8 [==============================] - 0s 851us/step - loss: 1.4345\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=5, n_neurons=33; total time=   2.0s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 1.9397 - val_loss: 1.5527\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8781 - val_loss: 1.5270\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8233 - val_loss: 1.4914\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7527 - val_loss: 1.4675\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6464 - val_loss: 1.4715\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4953 - val_loss: 1.4397\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3997 - val_loss: 1.4201\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2544 - val_loss: 1.4063\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2187 - val_loss: 1.4250\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1320 - val_loss: 1.4685\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9685 - val_loss: 1.3423\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8835 - val_loss: 1.3281\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8129 - val_loss: 1.3497\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8011 - val_loss: 1.3512\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8362 - val_loss: 1.5981\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7866 - val_loss: 1.3960\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6441 - val_loss: 1.3368\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6045 - val_loss: 1.4654\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5689 - val_loss: 1.3688\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5578 - val_loss: 1.3735\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5386 - val_loss: 1.4829\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5380 - val_loss: 1.3507\n",
      "8/8 [==============================] - 0s 926us/step - loss: 1.5332\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=5, n_neurons=33; total time=   1.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 2.0678 - val_loss: 1.5269\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9665 - val_loss: 1.4961\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8934 - val_loss: 1.4620\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7970 - val_loss: 1.4174\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7148 - val_loss: 1.3656\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5644 - val_loss: 1.3076\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4363 - val_loss: 1.2704\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3027 - val_loss: 1.2771\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1773 - val_loss: 1.2532\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0562 - val_loss: 1.2688\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9750 - val_loss: 1.2915\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9009 - val_loss: 1.2795\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8342 - val_loss: 1.2462\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7463 - val_loss: 1.2542\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6542 - val_loss: 1.2539\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 1.2960\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5558 - val_loss: 1.2494\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5403 - val_loss: 1.2950\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5265 - val_loss: 1.3332\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4810 - val_loss: 1.3292\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5389 - val_loss: 1.3049\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4647 - val_loss: 1.2796\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4759 - val_loss: 1.4327\n",
      "8/8 [==============================] - 0s 851us/step - loss: 1.8376\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=5, n_neurons=32; total time=   1.7s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 2.1639 - val_loss: 1.5204\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0820 - val_loss: 1.4761\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9914 - val_loss: 1.4557\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8943 - val_loss: 1.4301\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7942 - val_loss: 1.4287\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6434 - val_loss: 1.4178\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5102 - val_loss: 1.4138\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3924 - val_loss: 1.4199\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2638 - val_loss: 1.3815\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1835 - val_loss: 1.4123\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1331 - val_loss: 1.3667\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0471 - val_loss: 1.3874\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9714 - val_loss: 1.4342\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9293 - val_loss: 1.3356\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8447 - val_loss: 1.4208\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8489 - val_loss: 1.4122\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8021 - val_loss: 1.3947\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7040 - val_loss: 1.4194\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6246 - val_loss: 1.4543\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5820 - val_loss: 1.4005\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6881 - val_loss: 1.5041\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5989 - val_loss: 1.3865\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5969 - val_loss: 1.4727\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4874 - val_loss: 1.4631\n",
      "8/8 [==============================] - 0s 851us/step - loss: 1.5594\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=5, n_neurons=32; total time=   1.7s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 1.9445 - val_loss: 1.5632\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8958 - val_loss: 1.5369\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8528 - val_loss: 1.5023\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7978 - val_loss: 1.4747\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7293 - val_loss: 1.4359\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6295 - val_loss: 1.3921\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5406 - val_loss: 1.3315\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4111 - val_loss: 1.3006\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3026 - val_loss: 1.3263\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2047 - val_loss: 1.2991\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0369 - val_loss: 1.1898\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9639 - val_loss: 1.1997\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8917 - val_loss: 1.1825\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8410 - val_loss: 1.1939\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7953 - val_loss: 1.3171\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7620 - val_loss: 1.2622\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6649 - val_loss: 1.2189\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6183 - val_loss: 1.2810\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5642 - val_loss: 1.2384\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5637 - val_loss: 1.2432\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5493 - val_loss: 1.2519\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5145 - val_loss: 1.3232\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4490 - val_loss: 1.2831\n",
      "8/8 [==============================] - 0s 850us/step - loss: 1.5008\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=5, n_neurons=32; total time=   1.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 8ms/step - loss: 2.0601 - val_loss: 1.4703\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8154 - val_loss: 1.4306\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6356 - val_loss: 1.4009\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4599 - val_loss: 1.3812\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3420 - val_loss: 1.3601\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1549 - val_loss: 1.3428\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0760 - val_loss: 1.3371\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9769 - val_loss: 1.3530\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8767 - val_loss: 1.3204\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7850 - val_loss: 1.3002\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6880 - val_loss: 1.3435\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6446 - val_loss: 1.3180\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6059 - val_loss: 1.3656\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5297 - val_loss: 1.3197\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5091 - val_loss: 1.3650\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4849 - val_loss: 1.3517\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4436 - val_loss: 1.3285\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4299 - val_loss: 1.3466\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4147 - val_loss: 1.3814\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3953 - val_loss: 1.4135\n",
      "8/8 [==============================] - 0s 992us/step - loss: 1.5521\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=3, n_neurons=76; total time=   1.4s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 8ms/step - loss: 2.1542 - val_loss: 1.5148\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9045 - val_loss: 1.4397\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7131 - val_loss: 1.3944\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5253 - val_loss: 1.3859\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3971 - val_loss: 1.3717\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2652 - val_loss: 1.4213\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1524 - val_loss: 1.3372\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0245 - val_loss: 1.3294\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9218 - val_loss: 1.2993\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8687 - val_loss: 1.3714\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8128 - val_loss: 1.2774\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7644 - val_loss: 1.2669\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6984 - val_loss: 1.3281\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6507 - val_loss: 1.2831\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5962 - val_loss: 1.2892\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5702 - val_loss: 1.2800\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5743 - val_loss: 1.3362\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5177 - val_loss: 1.2804\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4756 - val_loss: 1.2983\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4366 - val_loss: 1.2841\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4802 - val_loss: 1.3286\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4377 - val_loss: 1.3003\n",
      "8/8 [==============================] - 0s 850us/step - loss: 1.5123\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=3, n_neurons=76; total time=   1.4s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 8ms/step - loss: 1.8925 - val_loss: 1.4782\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6427 - val_loss: 1.4400\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4900 - val_loss: 1.4085\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3449 - val_loss: 1.3542\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2200 - val_loss: 1.3321\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0895 - val_loss: 1.3170\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0493 - val_loss: 1.3695\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9404 - val_loss: 1.3076\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8774 - val_loss: 1.2260\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8515 - val_loss: 1.3846\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7475 - val_loss: 1.2728\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7145 - val_loss: 1.2343\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6741 - val_loss: 1.3193\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6337 - val_loss: 1.3048\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6382 - val_loss: 1.4246\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6348 - val_loss: 1.3022\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5136 - val_loss: 1.2754\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4796 - val_loss: 1.3223\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4514 - val_loss: 1.3153\n",
      "8/8 [==============================] - 0s 779us/step - loss: 1.4373\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=3, n_neurons=76; total time=   1.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 2.0311 - val_loss: 1.5148\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8107 - val_loss: 1.4301\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5815 - val_loss: 1.3743\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3714 - val_loss: 1.4024\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2340 - val_loss: 1.4652\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1010 - val_loss: 1.3215\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9535 - val_loss: 1.2639\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8801 - val_loss: 1.3531\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7627 - val_loss: 1.3597\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7440 - val_loss: 1.4246\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6324 - val_loss: 1.5060\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6633 - val_loss: 1.4228\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5592 - val_loss: 1.4251\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5254 - val_loss: 1.4324\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4544 - val_loss: 1.4553\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4460 - val_loss: 1.4038\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4112 - val_loss: 1.4001\n",
      "8/8 [==============================] - 0s 865us/step - loss: 1.3791\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=4, n_neurons=43; total time=   1.3s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 2.1569 - val_loss: 1.4955\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8851 - val_loss: 1.4205\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6800 - val_loss: 1.4081\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4882 - val_loss: 1.4177\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3808 - val_loss: 1.3987\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3162 - val_loss: 1.5498\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1487 - val_loss: 1.5179\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0266 - val_loss: 1.3349\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9273 - val_loss: 1.4098\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8636 - val_loss: 1.5417\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7764 - val_loss: 1.4056\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7892 - val_loss: 1.4516\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7148 - val_loss: 1.3592\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6111 - val_loss: 1.4198\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5459 - val_loss: 1.3823\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4959 - val_loss: 1.4825\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5547 - val_loss: 1.3646\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5349 - val_loss: 1.6090\n",
      "8/8 [==============================] - 0s 851us/step - loss: 1.6414\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=4, n_neurons=43; total time=   1.4s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 1.9112 - val_loss: 1.4857\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7318 - val_loss: 1.4664\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5876 - val_loss: 1.4221\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3819 - val_loss: 1.3782\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1986 - val_loss: 1.4155\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9800 - val_loss: 1.4181\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9654 - val_loss: 1.3764\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8812 - val_loss: 1.4120\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7733 - val_loss: 1.3951\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7222 - val_loss: 1.4353\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6937 - val_loss: 1.4289\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6010 - val_loss: 1.4084\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5894 - val_loss: 1.2703\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5327 - val_loss: 1.4248\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5296 - val_loss: 1.6636\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6661 - val_loss: 1.3535\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4548 - val_loss: 1.4290\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3948 - val_loss: 1.3541\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3645 - val_loss: 1.4034\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3383 - val_loss: 1.3478\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3245 - val_loss: 1.4060\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2877 - val_loss: 1.3840\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2763 - val_loss: 1.3143\n",
      "8/8 [==============================] - 0s 783us/step - loss: 1.5122\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=4, n_neurons=43; total time=   1.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 2.0278 - val_loss: 1.4920\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7355 - val_loss: 1.4616\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4365 - val_loss: 1.3415\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1998 - val_loss: 1.4142\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0133 - val_loss: 1.4748\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8618 - val_loss: 1.4340\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7411 - val_loss: 1.3421\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8137 - val_loss: 1.4490\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6527 - val_loss: 1.4472\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6210 - val_loss: 1.4056\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5587 - val_loss: 1.5229\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5528 - val_loss: 1.4284\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4752 - val_loss: 1.3956\n",
      "8/8 [==============================] - 0s 927us/step - loss: 1.1817\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=4, n_neurons=86; total time=   1.4s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 2.2192 - val_loss: 1.4965\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9163 - val_loss: 1.4812\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.6222 - val_loss: 1.3700\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3531 - val_loss: 1.3954\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1981 - val_loss: 1.4288\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0577 - val_loss: 1.3686\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8882 - val_loss: 1.3866\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7271 - val_loss: 1.2088\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6606 - val_loss: 1.5520\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6463 - val_loss: 1.5542\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5449 - val_loss: 1.3470\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5790 - val_loss: 1.4919\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5494 - val_loss: 1.5024\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5438 - val_loss: 1.2671\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4187 - val_loss: 1.3556\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3835 - val_loss: 1.2861\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3977 - val_loss: 1.3596\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4213 - val_loss: 1.4974\n",
      "8/8 [==============================] - 0s 921us/step - loss: 1.6135\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=4, n_neurons=86; total time=   1.4s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 1.9244 - val_loss: 1.4630\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6839 - val_loss: 1.3708\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4770 - val_loss: 1.4601\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2821 - val_loss: 1.2238\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0666 - val_loss: 1.3043\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9379 - val_loss: 1.4304\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8680 - val_loss: 1.1908\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.2744\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7891 - val_loss: 1.2518\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6841 - val_loss: 1.3155\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5716 - val_loss: 1.2366\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6244 - val_loss: 1.2285\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5413 - val_loss: 1.1533\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4752 - val_loss: 1.2606\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3908 - val_loss: 1.3146\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5623 - val_loss: 1.3788\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3856 - val_loss: 1.1484\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3101 - val_loss: 1.1593\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2996 - val_loss: 1.2534\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2661 - val_loss: 1.1674\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2836 - val_loss: 1.1283\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2657 - val_loss: 1.1392\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2173 - val_loss: 1.1354\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2790 - val_loss: 1.1718\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2252 - val_loss: 1.0831\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2023 - val_loss: 1.1352\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.2021 - val_loss: 1.1557\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2063 - val_loss: 1.1900\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1879 - val_loss: 1.1954\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1496 - val_loss: 1.0716\n",
      "Epoch 31/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1284 - val_loss: 1.1623\n",
      "Epoch 32/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1672 - val_loss: 1.2056\n",
      "Epoch 33/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1393 - val_loss: 1.2329\n",
      "Epoch 34/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1840 - val_loss: 1.1483\n",
      "Epoch 35/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1649 - val_loss: 1.1293\n",
      "Epoch 36/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1789 - val_loss: 1.1679\n",
      "Epoch 37/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1473 - val_loss: 1.2553\n",
      "Epoch 38/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1148 - val_loss: 1.1244\n",
      "Epoch 39/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1049 - val_loss: 1.1200\n",
      "Epoch 40/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0829 - val_loss: 1.1396\n",
      "8/8 [==============================] - 0s 921us/step - loss: 1.6560\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=4, n_neurons=86; total time=   2.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 2.0227 - val_loss: 1.4845\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7826 - val_loss: 1.3763\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4545 - val_loss: 1.3622\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2786 - val_loss: 1.3770\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1393 - val_loss: 1.3969\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8462 - val_loss: 1.4034\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.7657 - val_loss: 1.3359\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7682 - val_loss: 1.5979\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6960 - val_loss: 1.5373\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6843 - val_loss: 1.3161\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6318 - val_loss: 1.3497\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5875 - val_loss: 1.5158\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5264 - val_loss: 1.4437\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4645 - val_loss: 1.3330\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4016 - val_loss: 1.4295\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3769 - val_loss: 1.4596\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3834 - val_loss: 1.3929\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3637 - val_loss: 1.4217\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3593 - val_loss: 1.3965\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3356 - val_loss: 1.4118\n",
      "8/8 [==============================] - 0s 850us/step - loss: 1.4803\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=5, n_neurons=66; total time=   1.6s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 2.0971 - val_loss: 1.4579\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7680 - val_loss: 1.3890\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4802 - val_loss: 1.3510\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3251 - val_loss: 1.3186\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1605 - val_loss: 1.4979\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0418 - val_loss: 1.4207\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9108 - val_loss: 1.3545\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7953 - val_loss: 1.2384\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6776 - val_loss: 1.4690\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5691 - val_loss: 1.6088\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6274 - val_loss: 1.3143\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5829 - val_loss: 1.5012\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4847 - val_loss: 1.4313\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4525 - val_loss: 1.3184\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3539 - val_loss: 1.3519\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3406 - val_loss: 1.4875\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3591 - val_loss: 1.2201\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3226 - val_loss: 1.5163\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4454 - val_loss: 1.4200\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 1.1319\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2810 - val_loss: 1.4801\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2523 - val_loss: 1.2759\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2807 - val_loss: 1.3847\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2505 - val_loss: 1.4103\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2193 - val_loss: 1.3547\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1811 - val_loss: 1.3226\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1827 - val_loss: 1.3183\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2266 - val_loss: 1.3766\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1773 - val_loss: 1.3116\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1859 - val_loss: 1.3816\n",
      "8/8 [==============================] - 0s 939us/step - loss: 1.4161\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=5, n_neurons=66; total time=   2.0s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 1.9477 - val_loss: 1.5156\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7727 - val_loss: 1.4120\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5721 - val_loss: 1.3401\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3456 - val_loss: 1.2618\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2050 - val_loss: 1.2962\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0513 - val_loss: 1.2510\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0184 - val_loss: 1.2059\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0333 - val_loss: 1.3244\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9149 - val_loss: 1.3322\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8110 - val_loss: 1.3271\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6953 - val_loss: 1.3718\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6355 - val_loss: 1.3160\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5747 - val_loss: 1.2824\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4758 - val_loss: 1.3792\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4191 - val_loss: 1.4424\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6297 - val_loss: 1.2845\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4294 - val_loss: 1.2933\n",
      "8/8 [==============================] - 0s 854us/step - loss: 1.5128\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=5, n_neurons=66; total time=   1.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 2.0847 - val_loss: 1.5012\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8630 - val_loss: 1.4446\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6679 - val_loss: 1.4008\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4427 - val_loss: 1.4590\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2546 - val_loss: 1.4529\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0907 - val_loss: 1.3763\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9404 - val_loss: 1.4084\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8945 - val_loss: 1.5488\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7642 - val_loss: 1.3682\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7437 - val_loss: 1.3717\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6228 - val_loss: 1.3699\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6018 - val_loss: 1.4675\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5265 - val_loss: 1.3885\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4673 - val_loss: 1.3541\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4149 - val_loss: 1.3797\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3931 - val_loss: 1.4084\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3669 - val_loss: 1.3601\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3670 - val_loss: 1.3637\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3270 - val_loss: 1.4681\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3570 - val_loss: 1.3985\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3848 - val_loss: 1.3227\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3083 - val_loss: 1.3926\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3537 - val_loss: 1.5452\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3809 - val_loss: 1.4232\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3395 - val_loss: 1.3958\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3174 - val_loss: 1.3614\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2639 - val_loss: 1.3435\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2324 - val_loss: 1.3980\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2224 - val_loss: 1.3927\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2306 - val_loss: 1.3483\n",
      "Epoch 31/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2477 - val_loss: 1.3685\n",
      "8/8 [==============================] - 0s 924us/step - loss: 1.2456\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=4, n_neurons=94; total time=   2.0s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 2.1223 - val_loss: 1.4921\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8348 - val_loss: 1.4337\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5768 - val_loss: 1.4061\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3526 - val_loss: 1.3984\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1603 - val_loss: 1.3921\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0385 - val_loss: 1.3970\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8984 - val_loss: 1.3676\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7754 - val_loss: 1.3109\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6677 - val_loss: 1.3169\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6235 - val_loss: 1.4258\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5472 - val_loss: 1.2570\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5834 - val_loss: 1.4096\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5324 - val_loss: 1.3873\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5166 - val_loss: 1.3020\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4250 - val_loss: 1.2671\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3720 - val_loss: 1.3647\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4452 - val_loss: 1.4552\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4921 - val_loss: 1.5704\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4406 - val_loss: 1.4711\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3144 - val_loss: 1.3417\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3124 - val_loss: 1.3889\n",
      "8/8 [==============================] - 0s 854us/step - loss: 1.4706\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=4, n_neurons=94; total time=   1.5s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 1.9828 - val_loss: 1.4988\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7559 - val_loss: 1.4215\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5669 - val_loss: 1.3510\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3592 - val_loss: 1.3050\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1650 - val_loss: 1.2558\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9922 - val_loss: 1.2956\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9687 - val_loss: 1.3010\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8671 - val_loss: 1.2985\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7832 - val_loss: 1.2885\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7375 - val_loss: 1.3535\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6587 - val_loss: 1.2974\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6050 - val_loss: 1.3269\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5295 - val_loss: 1.2361\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4370 - val_loss: 1.3465\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4252 - val_loss: 1.3161\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4446 - val_loss: 1.2911\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3513 - val_loss: 1.2851\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3051 - val_loss: 1.2767\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2930 - val_loss: 1.2686\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2854 - val_loss: 1.2076\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2950 - val_loss: 1.3306\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2603 - val_loss: 1.2944\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2276 - val_loss: 1.2478\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2425 - val_loss: 1.2298\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2267 - val_loss: 1.2995\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1973 - val_loss: 1.2582\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1645 - val_loss: 1.2915\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1518 - val_loss: 1.2227\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1651 - val_loss: 1.3106\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1719 - val_loss: 1.3124\n",
      "8/8 [==============================] - 0s 918us/step - loss: 1.5030\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=4, n_neurons=94; total time=   1.9s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 2.1179 - val_loss: 1.5325\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9294 - val_loss: 1.4969\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7913 - val_loss: 1.4393\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6240 - val_loss: 1.4194\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4825 - val_loss: 1.3790\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2754 - val_loss: 1.4074\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1545 - val_loss: 1.3918\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0281 - val_loss: 1.5117\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8973 - val_loss: 1.4010\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8143 - val_loss: 1.4622\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7103 - val_loss: 1.4525\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6497 - val_loss: 1.4994\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5936 - val_loss: 1.4521\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5406 - val_loss: 1.4547\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5487 - val_loss: 1.4763\n",
      "8/8 [==============================] - 0s 922us/step - loss: 1.6553\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=4, n_neurons=70; total time=   1.3s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 2.1641 - val_loss: 1.4717\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9549 - val_loss: 1.4274\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7666 - val_loss: 1.3994\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5418 - val_loss: 1.3784\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4092 - val_loss: 1.3775\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2412 - val_loss: 1.4707\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1030 - val_loss: 1.4764\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9547 - val_loss: 1.3385\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8522 - val_loss: 1.4099\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7808 - val_loss: 1.5238\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7377 - val_loss: 1.3663\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6746 - val_loss: 1.3867\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5735 - val_loss: 1.4138\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5480 - val_loss: 1.3876\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5660 - val_loss: 1.3803\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4881 - val_loss: 1.4520\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5053 - val_loss: 1.4525\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4737 - val_loss: 1.4419\n",
      "8/8 [==============================] - 0s 921us/step - loss: 1.6071\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=4, n_neurons=70; total time=   1.6s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 1.9118 - val_loss: 1.5037\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7174 - val_loss: 1.4289\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5381 - val_loss: 1.4138\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3442 - val_loss: 1.2995\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1746 - val_loss: 1.3007\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0321 - val_loss: 1.3257\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9730 - val_loss: 1.3539\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8934 - val_loss: 1.3479\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8233 - val_loss: 1.3089\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7936 - val_loss: 1.4161\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7257 - val_loss: 1.2541\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6557 - val_loss: 1.3162\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6053 - val_loss: 1.3075\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5765 - val_loss: 1.3513\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5538 - val_loss: 1.5949\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6186 - val_loss: 1.3670\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4793 - val_loss: 1.2961\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4162 - val_loss: 1.3845\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3653 - val_loss: 1.3245\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3538 - val_loss: 1.3177\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3547 - val_loss: 1.4224\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.4557\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=4, n_neurons=70; total time=   1.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 8ms/step - loss: 2.4924 - val_loss: 1.8643\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.3387 - val_loss: 1.7520\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.2402 - val_loss: 1.6746\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.1655 - val_loss: 1.6279\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.1187 - val_loss: 1.5941\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0806 - val_loss: 1.5693\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0543 - val_loss: 1.5476\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0284 - val_loss: 1.5334\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0084 - val_loss: 1.5218\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9902 - val_loss: 1.5110\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9718 - val_loss: 1.5037\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9570 - val_loss: 1.4950\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9401 - val_loss: 1.4884\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9264 - val_loss: 1.4814\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9115 - val_loss: 1.4760\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8983 - val_loss: 1.4708\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8853 - val_loss: 1.4655\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8714 - val_loss: 1.4593\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8586 - val_loss: 1.4552\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8452 - val_loss: 1.4509\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8349 - val_loss: 1.4458\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8205 - val_loss: 1.4416\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8063 - val_loss: 1.4370\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7933 - val_loss: 1.4322\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7801 - val_loss: 1.4278\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7659 - val_loss: 1.4241\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7524 - val_loss: 1.4202\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7399 - val_loss: 1.4157\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7266 - val_loss: 1.4118\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7136 - val_loss: 1.4088\n",
      "Epoch 31/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7013 - val_loss: 1.4045\n",
      "Epoch 32/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6882 - val_loss: 1.4014\n",
      "Epoch 33/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6729 - val_loss: 1.3987\n",
      "Epoch 34/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6605 - val_loss: 1.3953\n",
      "Epoch 35/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6474 - val_loss: 1.3931\n",
      "Epoch 36/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6357 - val_loss: 1.3905\n",
      "Epoch 37/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6212 - val_loss: 1.3869\n",
      "Epoch 38/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6086 - val_loss: 1.3844\n",
      "Epoch 39/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5962 - val_loss: 1.3825\n",
      "Epoch 40/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5813 - val_loss: 1.3806\n",
      "Epoch 41/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5687 - val_loss: 1.3783\n",
      "Epoch 42/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5541 - val_loss: 1.3760\n",
      "Epoch 43/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5419 - val_loss: 1.3742\n",
      "Epoch 44/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5309 - val_loss: 1.3722\n",
      "Epoch 45/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5172 - val_loss: 1.3703\n",
      "Epoch 46/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5033 - val_loss: 1.3698\n",
      "Epoch 47/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4899 - val_loss: 1.3689\n",
      "Epoch 48/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4792 - val_loss: 1.3679\n",
      "Epoch 49/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4661 - val_loss: 1.3662\n",
      "Epoch 50/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4518 - val_loss: 1.3645\n",
      "Epoch 51/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4417 - val_loss: 1.3642\n",
      "Epoch 52/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4317 - val_loss: 1.3639\n",
      "Epoch 53/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4184 - val_loss: 1.3646\n",
      "Epoch 54/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4029 - val_loss: 1.3625\n",
      "Epoch 55/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3921 - val_loss: 1.3632\n",
      "Epoch 56/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3809 - val_loss: 1.3616\n",
      "Epoch 57/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3660 - val_loss: 1.3607\n",
      "Epoch 58/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3544 - val_loss: 1.3609\n",
      "Epoch 59/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3427 - val_loss: 1.3604\n",
      "Epoch 60/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3330 - val_loss: 1.3602\n",
      "Epoch 61/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3213 - val_loss: 1.3591\n",
      "Epoch 62/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3096 - val_loss: 1.3600\n",
      "Epoch 63/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2965 - val_loss: 1.3593\n",
      "Epoch 64/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2862 - val_loss: 1.3582\n",
      "Epoch 65/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2764 - val_loss: 1.3582\n",
      "Epoch 66/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2639 - val_loss: 1.3571\n",
      "Epoch 67/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2537 - val_loss: 1.3588\n",
      "Epoch 68/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2444 - val_loss: 1.3599\n",
      "Epoch 69/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2325 - val_loss: 1.3587\n",
      "Epoch 70/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2221 - val_loss: 1.3590\n",
      "Epoch 71/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2127 - val_loss: 1.3606\n",
      "Epoch 72/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2016 - val_loss: 1.3609\n",
      "Epoch 73/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1905 - val_loss: 1.3599\n",
      "Epoch 74/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1811 - val_loss: 1.3601\n",
      "Epoch 75/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1698 - val_loss: 1.3611\n",
      "Epoch 76/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1658 - val_loss: 1.3614\n",
      "8/8 [==============================] - 0s 787us/step - loss: 1.6496\n",
      "[CV] END .....learning_rate=0.0001, n_hidden=3, n_neurons=49; total time=   3.7s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 8ms/step - loss: 2.4178 - val_loss: 1.7763\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.3030 - val_loss: 1.6737\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.2315 - val_loss: 1.6153\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.1900 - val_loss: 1.5815\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.1616 - val_loss: 1.5596\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.1361 - val_loss: 1.5435\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.1122 - val_loss: 1.5304\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0915 - val_loss: 1.5207\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0728 - val_loss: 1.5117\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0565 - val_loss: 1.5010\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0382 - val_loss: 1.4938\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0235 - val_loss: 1.4850\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0061 - val_loss: 1.4802\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9904 - val_loss: 1.4714\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9747 - val_loss: 1.4651\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9592 - val_loss: 1.4581\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9450 - val_loss: 1.4527\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9303 - val_loss: 1.4467\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9150 - val_loss: 1.4412\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9040 - val_loss: 1.4380\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8908 - val_loss: 1.4310\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8731 - val_loss: 1.4243\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8595 - val_loss: 1.4196\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8468 - val_loss: 1.4136\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8302 - val_loss: 1.4100\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8177 - val_loss: 1.4055\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8010 - val_loss: 1.3990\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7881 - val_loss: 1.3935\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7735 - val_loss: 1.3875\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7594 - val_loss: 1.3843\n",
      "Epoch 31/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7439 - val_loss: 1.3779\n",
      "Epoch 32/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7272 - val_loss: 1.3736\n",
      "Epoch 33/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7139 - val_loss: 1.3699\n",
      "Epoch 34/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6965 - val_loss: 1.3641\n",
      "Epoch 35/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6825 - val_loss: 1.3599\n",
      "Epoch 36/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6661 - val_loss: 1.3551\n",
      "Epoch 37/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6506 - val_loss: 1.3510\n",
      "Epoch 38/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6350 - val_loss: 1.3455\n",
      "Epoch 39/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6192 - val_loss: 1.3417\n",
      "Epoch 40/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6044 - val_loss: 1.3394\n",
      "Epoch 41/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5920 - val_loss: 1.3337\n",
      "Epoch 42/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5721 - val_loss: 1.3307\n",
      "Epoch 43/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5563 - val_loss: 1.3279\n",
      "Epoch 44/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5423 - val_loss: 1.3250\n",
      "Epoch 45/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5270 - val_loss: 1.3224\n",
      "Epoch 46/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5117 - val_loss: 1.3182\n",
      "Epoch 47/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4998 - val_loss: 1.3176\n",
      "Epoch 48/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4815 - val_loss: 1.3147\n",
      "Epoch 49/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4687 - val_loss: 1.3126\n",
      "Epoch 50/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4542 - val_loss: 1.3100\n",
      "Epoch 51/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4416 - val_loss: 1.3100\n",
      "Epoch 52/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4277 - val_loss: 1.3074\n",
      "Epoch 53/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4144 - val_loss: 1.3072\n",
      "Epoch 54/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3994 - val_loss: 1.3061\n",
      "Epoch 55/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3875 - val_loss: 1.3037\n",
      "Epoch 56/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3759 - val_loss: 1.3031\n",
      "Epoch 57/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3619 - val_loss: 1.3032\n",
      "Epoch 58/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3504 - val_loss: 1.3008\n",
      "Epoch 59/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3389 - val_loss: 1.3014\n",
      "Epoch 60/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3263 - val_loss: 1.2997\n",
      "Epoch 61/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3140 - val_loss: 1.2979\n",
      "Epoch 62/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3038 - val_loss: 1.3007\n",
      "Epoch 63/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2921 - val_loss: 1.3005\n",
      "Epoch 64/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2818 - val_loss: 1.2982\n",
      "Epoch 65/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2689 - val_loss: 1.2984\n",
      "Epoch 66/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2589 - val_loss: 1.2989\n",
      "Epoch 67/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2516 - val_loss: 1.2990\n",
      "Epoch 68/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2419 - val_loss: 1.2999\n",
      "Epoch 69/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2311 - val_loss: 1.2996\n",
      "Epoch 70/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2169 - val_loss: 1.2980\n",
      "Epoch 71/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2078 - val_loss: 1.3029\n",
      "8/8 [==============================] - 0s 850us/step - loss: 1.5363\n",
      "[CV] END .....learning_rate=0.0001, n_hidden=3, n_neurons=49; total time=   3.5s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 8ms/step - loss: 2.3588 - val_loss: 2.0198\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.1998 - val_loss: 1.8682\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0905 - val_loss: 1.7579\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0109 - val_loss: 1.6900\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9630 - val_loss: 1.6422\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9273 - val_loss: 1.6112\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9012 - val_loss: 1.5904\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8778 - val_loss: 1.5755\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8568 - val_loss: 1.5618\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8397 - val_loss: 1.5485\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8200 - val_loss: 1.5373\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8020 - val_loss: 1.5303\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7867 - val_loss: 1.5232\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7693 - val_loss: 1.5142\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7550 - val_loss: 1.5063\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7390 - val_loss: 1.5012\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7252 - val_loss: 1.4956\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7116 - val_loss: 1.4900\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6954 - val_loss: 1.4858\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6830 - val_loss: 1.4822\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6688 - val_loss: 1.4762\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6552 - val_loss: 1.4698\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6409 - val_loss: 1.4686\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6286 - val_loss: 1.4638\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6154 - val_loss: 1.4588\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6042 - val_loss: 1.4581\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5898 - val_loss: 1.4522\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5774 - val_loss: 1.4495\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5645 - val_loss: 1.4456\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5524 - val_loss: 1.4446\n",
      "Epoch 31/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5396 - val_loss: 1.4410\n",
      "Epoch 32/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5269 - val_loss: 1.4364\n",
      "Epoch 33/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5163 - val_loss: 1.4352\n",
      "Epoch 34/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5045 - val_loss: 1.4279\n",
      "Epoch 35/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4926 - val_loss: 1.4286\n",
      "Epoch 36/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4799 - val_loss: 1.4267\n",
      "Epoch 37/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4676 - val_loss: 1.4217\n",
      "Epoch 38/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4560 - val_loss: 1.4188\n",
      "Epoch 39/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4438 - val_loss: 1.4145\n",
      "Epoch 40/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4313 - val_loss: 1.4165\n",
      "Epoch 41/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4237 - val_loss: 1.4115\n",
      "Epoch 42/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4073 - val_loss: 1.4098\n",
      "Epoch 43/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3954 - val_loss: 1.4087\n",
      "Epoch 44/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3829 - val_loss: 1.4061\n",
      "Epoch 45/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3718 - val_loss: 1.4046\n",
      "Epoch 46/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3588 - val_loss: 1.3993\n",
      "Epoch 47/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3471 - val_loss: 1.3987\n",
      "Epoch 48/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3333 - val_loss: 1.3981\n",
      "Epoch 49/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3217 - val_loss: 1.3948\n",
      "Epoch 50/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3105 - val_loss: 1.3917\n",
      "Epoch 51/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2999 - val_loss: 1.3935\n",
      "Epoch 52/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2854 - val_loss: 1.3896\n",
      "Epoch 53/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2760 - val_loss: 1.3875\n",
      "Epoch 54/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2621 - val_loss: 1.3819\n",
      "Epoch 55/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2516 - val_loss: 1.3812\n",
      "Epoch 56/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2392 - val_loss: 1.3802\n",
      "Epoch 57/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2295 - val_loss: 1.3817\n",
      "Epoch 58/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2148 - val_loss: 1.3780\n",
      "Epoch 59/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2045 - val_loss: 1.3737\n",
      "Epoch 60/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1931 - val_loss: 1.3744\n",
      "Epoch 61/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1806 - val_loss: 1.3705\n",
      "Epoch 62/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1697 - val_loss: 1.3686\n",
      "Epoch 63/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1620 - val_loss: 1.3675\n",
      "Epoch 64/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1480 - val_loss: 1.3649\n",
      "Epoch 65/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1375 - val_loss: 1.3623\n",
      "Epoch 66/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1272 - val_loss: 1.3633\n",
      "Epoch 67/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1173 - val_loss: 1.3584\n",
      "Epoch 68/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1087 - val_loss: 1.3585\n",
      "Epoch 69/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0963 - val_loss: 1.3588\n",
      "Epoch 70/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0871 - val_loss: 1.3587\n",
      "Epoch 71/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0760 - val_loss: 1.3547\n",
      "Epoch 72/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0678 - val_loss: 1.3508\n",
      "Epoch 73/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0571 - val_loss: 1.3520\n",
      "Epoch 74/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0483 - val_loss: 1.3552\n",
      "Epoch 75/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0417 - val_loss: 1.3491\n",
      "Epoch 76/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0305 - val_loss: 1.3520\n",
      "Epoch 77/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0261 - val_loss: 1.3551\n",
      "Epoch 78/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0137 - val_loss: 1.3455\n",
      "Epoch 79/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0056 - val_loss: 1.3486\n",
      "Epoch 80/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9957 - val_loss: 1.3464\n",
      "Epoch 81/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9876 - val_loss: 1.3510\n",
      "Epoch 82/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9815 - val_loss: 1.3509\n",
      "Epoch 83/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9707 - val_loss: 1.3427\n",
      "Epoch 84/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9636 - val_loss: 1.3495\n",
      "Epoch 85/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9539 - val_loss: 1.3480\n",
      "Epoch 86/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9463 - val_loss: 1.3512\n",
      "Epoch 87/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9392 - val_loss: 1.3439\n",
      "Epoch 88/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9348 - val_loss: 1.3523\n",
      "Epoch 89/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9234 - val_loss: 1.3486\n",
      "Epoch 90/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9169 - val_loss: 1.3469\n",
      "Epoch 91/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9092 - val_loss: 1.3502\n",
      "Epoch 92/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9034 - val_loss: 1.3513\n",
      "Epoch 93/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8941 - val_loss: 1.3512\n",
      "8/8 [==============================] - 0s 851us/step - loss: 1.6865\n",
      "[CV] END .....learning_rate=0.0001, n_hidden=3, n_neurons=49; total time=   4.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 2.0016 - val_loss: 1.4899\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7552 - val_loss: 1.3989\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5584 - val_loss: 1.3422\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3978 - val_loss: 1.4043\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1757 - val_loss: 1.3125\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9302 - val_loss: 1.4263\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9023 - val_loss: 1.2176\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7878 - val_loss: 1.3199\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8438 - val_loss: 1.5115\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8095 - val_loss: 1.3766\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6399 - val_loss: 1.4520\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5939 - val_loss: 1.3890\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4864 - val_loss: 1.3764\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4666 - val_loss: 1.3899\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3598 - val_loss: 1.2848\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3789 - val_loss: 1.3405\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3296 - val_loss: 1.2310\n",
      "8/8 [==============================] - 0s 927us/step - loss: 1.2919\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=6, n_neurons=74; total time=   1.6s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 2.1957 - val_loss: 1.5250\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9767 - val_loss: 1.5032\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7134 - val_loss: 1.4293\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4539 - val_loss: 1.4351\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3892 - val_loss: 1.5538\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1501 - val_loss: 1.3708\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9198 - val_loss: 1.3510\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9065 - val_loss: 1.2543\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7230 - val_loss: 1.3463\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5868 - val_loss: 1.3269\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5593 - val_loss: 1.3624\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5887 - val_loss: 1.4314\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5928 - val_loss: 1.3645\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5132 - val_loss: 1.2540\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4646 - val_loss: 1.3426\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3986 - val_loss: 1.3033\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3683 - val_loss: 1.3380\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2999 - val_loss: 1.3262\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2923 - val_loss: 1.3682\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2489 - val_loss: 1.2510\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2717 - val_loss: 1.3423\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2595 - val_loss: 1.3219\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2969 - val_loss: 1.4018\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.2770 - val_loss: 1.4527\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3138 - val_loss: 1.3419\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2060 - val_loss: 1.2595\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2048 - val_loss: 1.3813\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2509 - val_loss: 1.4001\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1823 - val_loss: 1.3527\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1944 - val_loss: 1.3104\n",
      "8/8 [==============================] - 0s 996us/step - loss: 1.4394\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=6, n_neurons=74; total time=   2.2s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 1.9339 - val_loss: 1.4995\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7518 - val_loss: 1.4192\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5509 - val_loss: 1.4072\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2646 - val_loss: 1.2391\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0596 - val_loss: 1.3092\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9730 - val_loss: 1.4636\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9022 - val_loss: 1.1954\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9488 - val_loss: 1.2240\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9095 - val_loss: 1.1971\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7306 - val_loss: 1.3455\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6533 - val_loss: 1.2719\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6005 - val_loss: 1.2212\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5293 - val_loss: 1.2162\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4719 - val_loss: 1.1623\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3984 - val_loss: 1.2966\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5264 - val_loss: 1.3256\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4613 - val_loss: 1.1862\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3384 - val_loss: 1.1464\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3365 - val_loss: 1.4673\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3291 - val_loss: 1.2402\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2751 - val_loss: 1.2053\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2860 - val_loss: 1.2360\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2701 - val_loss: 1.2199\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3113 - val_loss: 1.2444\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 1.2633\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2735 - val_loss: 1.2408\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2475 - val_loss: 1.1338\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2986 - val_loss: 1.3866\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2149 - val_loss: 1.4287\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2303 - val_loss: 1.1935\n",
      "Epoch 31/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1610 - val_loss: 1.2807\n",
      "Epoch 32/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1369 - val_loss: 1.3097\n",
      "Epoch 33/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1079 - val_loss: 1.2417\n",
      "Epoch 34/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1116 - val_loss: 1.4496\n",
      "Epoch 35/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1116 - val_loss: 1.3288\n",
      "Epoch 36/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0756 - val_loss: 1.2777\n",
      "Epoch 37/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0763 - val_loss: 1.3714\n",
      "8/8 [==============================] - 0s 992us/step - loss: 1.6904\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=6, n_neurons=74; total time=   2.5s\n",
      "Epoch 1/300\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 2.0234 - val_loss: 1.4866\n",
      "Epoch 2/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.7488 - val_loss: 1.3193\n",
      "Epoch 3/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.4452 - val_loss: 1.2945\n",
      "Epoch 4/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.2296 - val_loss: 1.3885\n",
      "Epoch 5/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.1678 - val_loss: 1.2080\n",
      "Epoch 6/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.9592 - val_loss: 1.2999\n",
      "Epoch 7/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.8821 - val_loss: 1.2566\n",
      "Epoch 8/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.7881 - val_loss: 1.6133\n",
      "Epoch 9/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.7335 - val_loss: 1.3551\n",
      "Epoch 10/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6726 - val_loss: 1.1896\n",
      "Epoch 11/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5593 - val_loss: 1.1948\n",
      "Epoch 12/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5878 - val_loss: 1.1558\n",
      "Epoch 13/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4856 - val_loss: 1.1482\n",
      "Epoch 14/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4786 - val_loss: 1.1821\n",
      "Epoch 15/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4425 - val_loss: 1.2514\n",
      "Epoch 16/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 1.1130\n",
      "Epoch 17/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4887 - val_loss: 1.1400\n",
      "Epoch 18/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5990 - val_loss: 1.2094\n",
      "Epoch 19/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3522 - val_loss: 1.1184\n",
      "Epoch 20/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3566 - val_loss: 1.2306\n",
      "Epoch 21/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4134 - val_loss: 1.1064\n",
      "Epoch 22/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4542 - val_loss: 1.1194\n",
      "Epoch 23/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3297 - val_loss: 1.1528\n",
      "Epoch 24/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2988 - val_loss: 1.0983\n",
      "Epoch 25/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3313 - val_loss: 1.1157\n",
      "Epoch 26/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2845 - val_loss: 1.1212\n",
      "Epoch 27/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2810 - val_loss: 1.0831\n",
      "Epoch 28/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2608 - val_loss: 1.0913\n",
      "Epoch 29/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2741 - val_loss: 1.1829\n",
      "Epoch 30/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2567 - val_loss: 1.1101\n",
      "Epoch 31/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2430 - val_loss: 1.0850\n",
      "Epoch 32/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2694 - val_loss: 1.1390\n",
      "Epoch 33/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3269 - val_loss: 1.2605\n",
      "Epoch 34/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2743 - val_loss: 1.1965\n",
      "Epoch 35/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2345 - val_loss: 1.0836\n",
      "Epoch 36/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2807 - val_loss: 1.2450\n",
      "Epoch 37/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2596 - val_loss: 1.2061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=3,\n",
       "              estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x00000273CDBF1340>,\n",
       "              n_iter=10,\n",
       "              search_spaces={'learning_rate': array([0.0001, 0.0011, 0.0021]),\n",
       "                             'n_hidden': [2, 3, 4, 5, 6],\n",
       "                             'n_neurons': array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,\n",
       "       27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43,\n",
       "       44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n",
       "       61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77,\n",
       "       78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94,\n",
       "       95, 96, 97, 98, 99])},\n",
       "              verbose=2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import skopt\n",
    "\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [2,3, 4, 5, 6],\n",
    "    \"n_neurons\": np.arange(10,100),\n",
    "    \"learning_rate\": np.arange(0.0001, 0.003, 0.001),\n",
    "}\n",
    "\n",
    "bayes_search_cv = skopt.BayesSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "bayes_search_cv.fit(X_train2, y_train2, epochs=300,\n",
    "                  validation_data=(X_test2, y_test2),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('learning_rate', 0.0011), ('n_hidden', 4), ('n_neurons', 94)])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.4063807725906372"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 814us/step - loss: 1.2061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.2061419486999512"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_search_cv.score(X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_95\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_512 (Dense)           (None, 94)                6580      \n",
      "                                                                 \n",
      " dense_513 (Dense)           (None, 94)                8930      \n",
      "                                                                 \n",
      " dense_514 (Dense)           (None, 94)                8930      \n",
      "                                                                 \n",
      " dense_515 (Dense)           (None, 94)                8930      \n",
      "                                                                 \n",
      " dense_516 (Dense)           (None, 1)                 95        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,465\n",
      "Trainable params: 33,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = bayes_search_cv.best_estimator_.model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 859us/step - loss: 1.2061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.2061419486999512"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test2, y_test2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN for Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(n_hidden=1, n_neurons=60, learning_rate=1e-3, input_shape=X_train3.shape[1]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stvp2\\AppData\\Local\\Temp\\ipykernel_2940\\1370646454.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model3)\n"
     ]
    }
   ],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "Epoch 1/160\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.6591 - val_loss: 1.9881\n",
      "Epoch 2/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3857 - val_loss: 1.9270\n",
      "Epoch 3/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.1537 - val_loss: 1.8873\n",
      "Epoch 4/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.9047 - val_loss: 1.8717\n",
      "Epoch 5/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6956 - val_loss: 1.7687\n",
      "Epoch 6/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4892 - val_loss: 1.7228\n",
      "Epoch 7/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2786 - val_loss: 1.6742\n",
      "Epoch 8/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1007 - val_loss: 1.6014\n",
      "Epoch 9/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0224 - val_loss: 1.7223\n",
      "Epoch 10/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9012 - val_loss: 1.7327\n",
      "Epoch 11/160\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8406 - val_loss: 1.7365\n",
      "Epoch 12/160\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8035 - val_loss: 1.6556\n",
      "Epoch 13/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8558 - val_loss: 1.6351\n",
      "Epoch 14/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7312 - val_loss: 1.6906\n",
      "Epoch 15/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6707 - val_loss: 1.6771\n",
      "Epoch 16/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6745 - val_loss: 1.6715\n",
      "Epoch 17/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6813 - val_loss: 1.6503\n",
      "Epoch 18/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5969 - val_loss: 1.5712\n",
      "Epoch 19/160\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5671 - val_loss: 1.6344\n",
      "Epoch 20/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5601 - val_loss: 1.6187\n",
      "Epoch 21/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5139 - val_loss: 1.6094\n",
      "Epoch 22/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4968 - val_loss: 1.5815\n",
      "Epoch 23/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5484 - val_loss: 1.5891\n",
      "Epoch 24/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5151 - val_loss: 1.5768\n",
      "Epoch 25/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - val_loss: 1.5661\n",
      "Epoch 26/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - val_loss: 1.5359\n",
      "Epoch 27/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4156 - val_loss: 1.6420\n",
      "Epoch 28/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3768 - val_loss: 1.4940\n",
      "Epoch 29/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - val_loss: 1.5859\n",
      "Epoch 30/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3796 - val_loss: 1.8479\n",
      "Epoch 31/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - val_loss: 1.4567\n",
      "Epoch 32/160\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3572 - val_loss: 1.5889\n",
      "Epoch 33/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3336 - val_loss: 1.6250\n",
      "Epoch 34/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3497 - val_loss: 1.5166\n",
      "Epoch 35/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3415 - val_loss: 1.6219\n",
      "Epoch 36/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3591 - val_loss: 1.6071\n",
      "Epoch 37/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3206 - val_loss: 1.6526\n",
      "Epoch 38/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3351 - val_loss: 1.5858\n",
      "Epoch 39/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2889 - val_loss: 1.5375\n",
      "Epoch 40/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2796 - val_loss: 1.5270\n",
      "Epoch 41/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2978 - val_loss: 1.5223\n",
      "Epoch 42/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2717 - val_loss: 1.5936\n",
      "Epoch 43/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3015 - val_loss: 1.4688\n",
      "Epoch 44/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2852 - val_loss: 1.5483\n",
      "Epoch 45/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2692 - val_loss: 1.6216\n",
      "Epoch 46/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2544 - val_loss: 1.5279\n",
      "Epoch 47/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2813 - val_loss: 1.7210\n",
      "Epoch 48/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2648 - val_loss: 1.5915\n",
      "Epoch 49/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2399 - val_loss: 1.5333\n",
      "Epoch 50/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2505 - val_loss: 1.5790\n",
      "Epoch 51/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2366 - val_loss: 1.4926\n",
      "Epoch 52/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2399 - val_loss: 1.5566\n",
      "Epoch 53/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1995 - val_loss: 1.5542\n",
      "Epoch 54/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1971 - val_loss: 1.5621\n",
      "Epoch 55/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2300 - val_loss: 1.6718\n",
      "Epoch 56/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2207 - val_loss: 1.5485\n",
      "Epoch 57/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2066 - val_loss: 1.5780\n",
      "Epoch 58/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1906 - val_loss: 1.5276\n",
      "Epoch 59/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1923 - val_loss: 1.5649\n",
      "Epoch 60/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1974 - val_loss: 1.5154\n",
      "Epoch 61/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1874 - val_loss: 1.6667\n",
      "Epoch 62/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2128 - val_loss: 1.5997\n",
      "Epoch 63/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1870 - val_loss: 1.5100\n",
      "Epoch 64/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1696 - val_loss: 1.5122\n",
      "Epoch 65/160\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1547 - val_loss: 1.5713\n",
      "Epoch 66/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1881 - val_loss: 1.5762\n",
      "Epoch 67/160\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1897 - val_loss: 1.5764\n",
      "Epoch 68/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1898 - val_loss: 1.5142\n",
      "Epoch 69/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2045 - val_loss: 1.6391\n",
      "Epoch 70/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1873 - val_loss: 1.5844\n",
      "Epoch 71/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1708 - val_loss: 1.6412\n",
      "Epoch 72/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1687 - val_loss: 1.4394\n",
      "Epoch 73/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1917 - val_loss: 1.4997\n",
      "Epoch 74/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1721 - val_loss: 1.4682\n",
      "Epoch 75/160\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1667 - val_loss: 1.5710\n",
      "Epoch 76/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1990 - val_loss: 1.5712\n",
      "Epoch 77/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1451 - val_loss: 1.4338\n",
      "Epoch 78/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1336 - val_loss: 1.5097\n",
      "Epoch 79/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1488 - val_loss: 1.5195\n",
      "Epoch 80/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1579 - val_loss: 1.5554\n",
      "Epoch 81/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1453 - val_loss: 1.4972\n",
      "Epoch 82/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1433 - val_loss: 1.5498\n",
      "Epoch 83/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1397 - val_loss: 1.4757\n",
      "Epoch 84/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1346 - val_loss: 1.5421\n",
      "Epoch 85/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1256 - val_loss: 1.5050\n",
      "Epoch 86/160\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1151 - val_loss: 1.5522\n",
      "Epoch 87/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1288 - val_loss: 1.5741\n",
      "Epoch 88/160\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1322 - val_loss: 1.5007\n",
      "Epoch 89/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1213 - val_loss: 1.4604\n",
      "Epoch 90/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1343 - val_loss: 1.5885\n",
      "Epoch 91/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1468 - val_loss: 1.5078\n",
      "Epoch 92/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1359 - val_loss: 1.4868\n",
      "Epoch 93/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1255 - val_loss: 1.5829\n",
      "Epoch 94/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1097 - val_loss: 1.5378\n",
      "Epoch 95/160\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1183 - val_loss: 1.5178\n",
      "Epoch 96/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1257 - val_loss: 1.5196\n",
      "Epoch 97/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1093 - val_loss: 1.5732\n",
      "Epoch 98/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1377 - val_loss: 1.5310\n",
      "Epoch 99/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1323 - val_loss: 1.4284\n",
      "Epoch 100/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1379 - val_loss: 1.5722\n",
      "Epoch 101/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1198 - val_loss: 1.5127\n",
      "Epoch 102/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1012 - val_loss: 1.5526\n",
      "Epoch 103/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0971 - val_loss: 1.5053\n",
      "Epoch 104/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1127 - val_loss: 1.5439\n",
      "Epoch 105/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1032 - val_loss: 1.5034\n",
      "Epoch 106/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 1.4918\n",
      "Epoch 107/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0993 - val_loss: 1.5109\n",
      "Epoch 108/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1074 - val_loss: 1.5803\n",
      "Epoch 109/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1217 - val_loss: 1.5312\n",
      "Epoch 110/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1292 - val_loss: 1.4828\n",
      "Epoch 111/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1674 - val_loss: 1.5760\n",
      "Epoch 112/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1663 - val_loss: 1.6354\n",
      "Epoch 113/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1334 - val_loss: 1.4683\n",
      "Epoch 114/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1139 - val_loss: 1.5601\n",
      "Epoch 115/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1144 - val_loss: 1.5692\n",
      "Epoch 116/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1017 - val_loss: 1.5428\n",
      "Epoch 117/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0991 - val_loss: 1.4361\n",
      "Epoch 118/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0895 - val_loss: 1.5393\n",
      "Epoch 119/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0815 - val_loss: 1.5338\n",
      "Epoch 120/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0998 - val_loss: 1.5642\n",
      "Epoch 121/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0980 - val_loss: 1.5503\n",
      "Epoch 122/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1160 - val_loss: 1.5354\n",
      "Epoch 123/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0919 - val_loss: 1.5097\n",
      "Epoch 124/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0832 - val_loss: 1.5230\n",
      "Epoch 125/160\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1062 - val_loss: 1.5887\n",
      "Epoch 126/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1031 - val_loss: 1.5925\n",
      "Epoch 127/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1067 - val_loss: 1.4896\n",
      "Epoch 128/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 1.5256\n",
      "Epoch 129/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0756 - val_loss: 1.5363\n",
      "Epoch 130/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0763 - val_loss: 1.5975\n",
      "Epoch 131/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0912 - val_loss: 1.5557\n",
      "Epoch 132/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0951 - val_loss: 1.5650\n",
      "Epoch 133/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1167 - val_loss: 1.5751\n",
      "Epoch 134/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1019 - val_loss: 1.4824\n",
      "Epoch 135/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0970 - val_loss: 1.5428\n",
      "Epoch 136/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 1.5469\n",
      "Epoch 137/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0625 - val_loss: 1.4928\n",
      "Epoch 138/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0538 - val_loss: 1.4756\n",
      "Epoch 139/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0690 - val_loss: 1.5775\n",
      "Epoch 140/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 1.5072\n",
      "Epoch 141/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0921 - val_loss: 1.5729\n",
      "Epoch 142/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1097 - val_loss: 1.5670\n",
      "Epoch 143/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1316 - val_loss: 1.7311\n",
      "Epoch 144/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1660 - val_loss: 1.5700\n",
      "Epoch 145/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1440 - val_loss: 1.4636\n",
      "Epoch 146/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1291 - val_loss: 1.5542\n",
      "Epoch 147/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 1.6187\n",
      "Epoch 148/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 1.5116\n",
      "Epoch 149/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 1.5303\n",
      "Epoch 150/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0695 - val_loss: 1.5645\n",
      "Epoch 151/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0864 - val_loss: 1.5519\n",
      "Epoch 152/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 1.5543\n",
      "Epoch 153/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0847 - val_loss: 1.5594\n",
      "Epoch 154/160\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0813 - val_loss: 1.6150\n",
      "Epoch 155/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0597 - val_loss: 1.5625\n",
      "Epoch 156/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 1.6099\n",
      "Epoch 157/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 1.5939\n",
      "Epoch 158/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0770 - val_loss: 1.5604\n",
      "Epoch 159/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0588 - val_loss: 1.6223\n",
      "Epoch 160/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0571 - val_loss: 1.5924\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "# define the input shape and number of classes\n",
    "input_shape = X_train3.shape[1]\n",
    "num_classes = 1\n",
    "\n",
    "# define the model architecture\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(70, activation='relu', input_shape=(input_shape,)))\n",
    "for i in range(3):\n",
    "    model.add(layers.Dense(70, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='linear'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "# compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "#print(model.summary())\n",
    "print(input_shape)\n",
    "\n",
    "# train the model\n",
    "history = model.fit(X_train3, y_train3, epochs=160, validation_data=(X_test3, y_test3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.6590638160705566, 2.3857028484344482, 2.153658866882324, 1.9047346115112305, 1.6956048011779785, 1.4892066717147827, 1.2785617113113403, 1.1006510257720947, 1.0223662853240967, 0.9011593461036682, 0.8406015634536743, 0.8034873604774475, 0.8557878732681274, 0.7311902642250061, 0.670657217502594, 0.6745337843894958, 0.6812929511070251, 0.5969199538230896, 0.5670982599258423, 0.5600918531417847, 0.5138742923736572, 0.49683940410614014, 0.5483642220497131, 0.515095055103302, 0.4288164973258972, 0.42043694853782654, 0.4155559837818146, 0.3767501711845398, 0.4312555491924286, 0.3795539140701294, 0.42205724120140076, 0.3571602702140808, 0.333624929189682, 0.34971022605895996, 0.34154996275901794, 0.35907992720603943, 0.32064008712768555, 0.3350626528263092, 0.288891077041626, 0.27956467866897583, 0.29783162474632263, 0.2716990113258362, 0.30154484510421753, 0.2851720452308655, 0.2691831588745117, 0.2543932795524597, 0.2812919020652771, 0.2647929787635803, 0.23989079892635345, 0.2505479156970978, 0.23655499517917633, 0.23994290828704834, 0.19950023293495178, 0.1971142292022705, 0.23004090785980225, 0.2207101434469223, 0.20661483705043793, 0.1905582845211029, 0.1923336684703827, 0.19739015400409698, 0.18744534254074097, 0.2128094732761383, 0.18696026504039764, 0.16964276134967804, 0.15469768643379211, 0.18808482587337494, 0.18973924219608307, 0.18979158997535706, 0.2045024186372757, 0.18731993436813354, 0.17077328264713287, 0.16870588064193726, 0.19170989096164703, 0.1721138209104538, 0.16668903827667236, 0.19904328882694244, 0.14505290985107422, 0.1336299180984497, 0.14882369339466095, 0.1579369157552719, 0.1453312188386917, 0.14331091940402985, 0.13965030014514923, 0.13461078703403473, 0.12556156516075134, 0.11513838917016983, 0.12878602743148804, 0.13220982253551483, 0.12129434943199158, 0.13434088230133057, 0.14677834510803223, 0.1358991116285324, 0.12553195655345917, 0.10969008505344391, 0.11826276034116745, 0.12572771310806274, 0.10927285999059677, 0.13771171867847443, 0.13227267563343048, 0.13794730603694916, 0.11978592723608017, 0.1012289822101593, 0.09707929939031601, 0.11273583024740219, 0.10322809964418411, 0.087090402841568, 0.09926571696996689, 0.10742314904928207, 0.12166524678468704, 0.12915579974651337, 0.1674107015132904, 0.16625893115997314, 0.1334238499403, 0.11391809582710266, 0.11441414058208466, 0.10170699656009674, 0.09907473623752594, 0.08946166187524796, 0.0814855620265007, 0.09981729090213776, 0.0979560986161232, 0.11600425094366074, 0.0918923169374466, 0.08317267149686813, 0.10619745403528214, 0.10307605564594269, 0.10674116015434265, 0.08058791607618332, 0.0755850076675415, 0.07634580135345459, 0.09122385829687119, 0.09507699310779572, 0.1166747435927391, 0.1018601581454277, 0.09695743769407272, 0.07828167825937271, 0.06252112984657288, 0.05382413789629936, 0.0690203458070755, 0.0783044844865799, 0.0920790582895279, 0.10974812507629395, 0.13164611160755157, 0.16603006422519684, 0.14395593106746674, 0.12907454371452332, 0.09517867863178253, 0.07549358904361725, 0.07412878423929214, 0.06954117864370346, 0.08637509495019913, 0.07504166662693024, 0.084740549325943, 0.08128117769956589, 0.05973758175969124, 0.06028277426958084, 0.049161750823259354, 0.07699619233608246, 0.058760933578014374, 0.05706407129764557]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history[\"loss\"])\n",
    "plot_learning_curves(np.sqrt(history.history[\"loss\"]), np.sqrt(history.history[\"val_loss\"]))\n",
    "plt.ylim(0,2)\n",
    "plt.show()\n",
    "#plt.savefig(\"deepfoodsecurity.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 13ms/step - loss: 2.7086 - val_loss: 2.1044\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6378 - val_loss: 2.0619\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5903 - val_loss: 2.0240\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5297 - val_loss: 1.9896\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4828 - val_loss: 1.9630\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4119 - val_loss: 1.9331\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3385 - val_loss: 1.8898\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2275 - val_loss: 1.8421\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1018 - val_loss: 1.8053\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9452 - val_loss: 1.8248\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8122 - val_loss: 1.8472\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6405 - val_loss: 1.9081\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5166 - val_loss: 1.9103\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4144 - val_loss: 2.0026\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3153 - val_loss: 1.9402\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1997 - val_loss: 1.9914\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1501 - val_loss: 1.9694\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0682 - val_loss: 1.9858\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0264 - val_loss: 2.0621\n",
      "6/6 [==============================] - 0s 940us/step - loss: 2.0247\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=6, n_neurons=18; total time=   1.8s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.7676 - val_loss: 2.0670\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.7083 - val_loss: 2.0389\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6642 - val_loss: 2.0207\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6084 - val_loss: 2.0103\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.5274 - val_loss: 1.9996\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4010 - val_loss: 1.9747\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2866 - val_loss: 1.9783\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1508 - val_loss: 1.9717\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0370 - val_loss: 1.9314\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9413 - val_loss: 1.9850\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8974 - val_loss: 1.9367\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8024 - val_loss: 1.9745\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7026 - val_loss: 1.8884\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6199 - val_loss: 1.9202\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6225 - val_loss: 2.0291\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5053 - val_loss: 1.8625\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3836 - val_loss: 1.9176\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3148 - val_loss: 1.7764\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2297 - val_loss: 1.7999\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1960 - val_loss: 1.9900\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1238 - val_loss: 1.7689\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0542 - val_loss: 1.7677\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0371 - val_loss: 1.9126\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0079 - val_loss: 1.9446\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9388 - val_loss: 1.7720\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9430 - val_loss: 1.9969\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9111 - val_loss: 1.9291\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8377 - val_loss: 1.8352\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8295 - val_loss: 1.9270\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7921 - val_loss: 1.8635\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7776 - val_loss: 1.8272\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7334 - val_loss: 2.0094\n",
      "6/6 [==============================] - 0s 893us/step - loss: 2.1164\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=6, n_neurons=18; total time=   2.0s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.5017 - val_loss: 2.0535\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4192 - val_loss: 2.0245\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.3407 - val_loss: 1.9899\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2293 - val_loss: 1.9659\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0911 - val_loss: 1.9247\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9581 - val_loss: 1.9155\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8390 - val_loss: 1.9135\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7242 - val_loss: 1.9053\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6202 - val_loss: 1.9067\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5158 - val_loss: 1.9081\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4596 - val_loss: 1.8891\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3503 - val_loss: 1.8324\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2741 - val_loss: 1.8609\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.2237 - val_loss: 1.8100\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1314 - val_loss: 1.8764\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0622 - val_loss: 1.8229\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0190 - val_loss: 1.8360\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9894 - val_loss: 1.8593\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9103 - val_loss: 1.8774\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8701 - val_loss: 1.9264\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8367 - val_loss: 1.8773\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7881 - val_loss: 1.9591\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7549 - val_loss: 1.9512\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7278 - val_loss: 1.9009\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 2.0234\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=6, n_neurons=18; total time=   1.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.6389 - val_loss: 1.9834\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4664 - val_loss: 1.9449\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2540 - val_loss: 1.8625\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9841 - val_loss: 1.8480\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6959 - val_loss: 1.8562\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5410 - val_loss: 1.8726\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.2315 - val_loss: 1.9809\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0777 - val_loss: 2.0745\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1083 - val_loss: 2.0552\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9432 - val_loss: 2.1060\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8541 - val_loss: 2.7821\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1037 - val_loss: 1.9570\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8673 - val_loss: 1.9562\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.7099 - val_loss: 1.9334\n",
      "6/6 [==============================] - 0s 893us/step - loss: 1.9831\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=5, n_neurons=50; total time=   1.3s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.7317 - val_loss: 1.9632\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4396 - val_loss: 1.9418\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1128 - val_loss: 1.8822\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8921 - val_loss: 1.9607\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6259 - val_loss: 1.7950\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4787 - val_loss: 1.7367\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2244 - val_loss: 1.9332\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0309 - val_loss: 1.7730\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9358 - val_loss: 1.8005\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7653 - val_loss: 1.7312\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6929 - val_loss: 1.6251\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5627 - val_loss: 1.6930\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5201 - val_loss: 1.7489\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5288 - val_loss: 1.7318\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4974 - val_loss: 1.7879\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4732 - val_loss: 1.6313\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4096 - val_loss: 1.8310\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3778 - val_loss: 1.7137\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3794 - val_loss: 1.7654\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3324 - val_loss: 1.6250\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4294 - val_loss: 1.9042\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3662 - val_loss: 1.7179\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3683 - val_loss: 1.7388\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3327 - val_loss: 1.7594\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2837 - val_loss: 1.8831\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3123 - val_loss: 1.9451\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3042 - val_loss: 1.7487\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2764 - val_loss: 1.7818\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2246 - val_loss: 1.7950\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2300 - val_loss: 1.6391\n",
      "6/6 [==============================] - 0s 893us/step - loss: 1.8248\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=5, n_neurons=50; total time=   1.9s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.5268 - val_loss: 2.0449\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3357 - val_loss: 1.9129\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0536 - val_loss: 1.8715\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8118 - val_loss: 1.9050\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5903 - val_loss: 1.7705\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3941 - val_loss: 1.7922\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1992 - val_loss: 1.9428\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1516 - val_loss: 1.8752\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9953 - val_loss: 1.8335\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9184 - val_loss: 1.8122\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8968 - val_loss: 1.7744\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9109 - val_loss: 1.7657\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7643 - val_loss: 1.9004\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7597 - val_loss: 1.9596\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6569 - val_loss: 1.7934\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6136 - val_loss: 1.9206\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4785 - val_loss: 1.6701\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4480 - val_loss: 1.8907\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3989 - val_loss: 1.8333\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4310 - val_loss: 1.7725\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4268 - val_loss: 1.8142\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3599 - val_loss: 1.7801\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3201 - val_loss: 1.8155\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2832 - val_loss: 1.8064\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 1.9604\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3036 - val_loss: 1.8157\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3090 - val_loss: 1.8050\n",
      "6/6 [==============================] - 0s 969us/step - loss: 2.0811\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=5, n_neurons=50; total time=   1.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.6203 - val_loss: 1.9461\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4518 - val_loss: 1.9012\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2910 - val_loss: 1.8470\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1047 - val_loss: 1.7569\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8952 - val_loss: 1.7438\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7168 - val_loss: 1.7250\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5112 - val_loss: 1.8034\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3415 - val_loss: 1.7724\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1992 - val_loss: 1.8030\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1148 - val_loss: 1.7645\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9919 - val_loss: 1.9322\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0326 - val_loss: 1.7782\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9443 - val_loss: 1.7758\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7998 - val_loss: 1.8956\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7044 - val_loss: 1.8643\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6082 - val_loss: 1.8816\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.7590\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=5, n_neurons=47; total time=   1.4s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.8065 - val_loss: 2.0200\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6383 - val_loss: 1.9899\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4854 - val_loss: 1.9422\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2672 - val_loss: 1.8905\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9609 - val_loss: 1.9038\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.6414 - val_loss: 1.9161\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4524 - val_loss: 1.8602\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2755 - val_loss: 1.7691\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1239 - val_loss: 1.7450\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0295 - val_loss: 1.8530\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9567 - val_loss: 1.6687\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8956 - val_loss: 1.7735\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7657 - val_loss: 1.6775\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7391 - val_loss: 1.9723\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7683 - val_loss: 1.7289\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7088 - val_loss: 1.6463\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6796 - val_loss: 1.7969\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6207 - val_loss: 1.7896\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6505 - val_loss: 1.7310\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6041 - val_loss: 1.7336\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5034 - val_loss: 1.5999\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4740 - val_loss: 1.7866\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4529 - val_loss: 1.6243\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4264 - val_loss: 1.6449\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4088 - val_loss: 1.9215\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4502 - val_loss: 1.8168\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4042 - val_loss: 1.6925\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3385 - val_loss: 1.7020\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3446 - val_loss: 1.7292\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3490 - val_loss: 1.7510\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3053 - val_loss: 1.7283\n",
      "6/6 [==============================] - 0s 998us/step - loss: 1.7606\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=5, n_neurons=47; total time=   1.8s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.5128 - val_loss: 2.0142\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3625 - val_loss: 1.9666\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2159 - val_loss: 1.9265\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0757 - val_loss: 1.9244\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.9151 - val_loss: 1.8349\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7253 - val_loss: 1.7870\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5302 - val_loss: 1.7281\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3883 - val_loss: 1.6575\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1950 - val_loss: 1.7085\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0464 - val_loss: 1.6682\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0320 - val_loss: 1.6292\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9232 - val_loss: 1.6505\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7805 - val_loss: 1.9695\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9200 - val_loss: 1.7862\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8375 - val_loss: 1.6425\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7286 - val_loss: 1.6487\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6246 - val_loss: 1.7149\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6693 - val_loss: 1.6027\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5965 - val_loss: 1.6852\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5228 - val_loss: 1.6486\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4954 - val_loss: 1.6901\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4300 - val_loss: 1.7036\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3779 - val_loss: 1.7239\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3543 - val_loss: 1.6636\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4149 - val_loss: 1.7458\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3503 - val_loss: 1.6354\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3570 - val_loss: 1.9004\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3508 - val_loss: 1.7032\n",
      "6/6 [==============================] - 0s 897us/step - loss: 1.9301\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=5, n_neurons=47; total time=   1.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.6163 - val_loss: 1.9517\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3248 - val_loss: 1.8751\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0698 - val_loss: 1.8389\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7941 - val_loss: 1.8492\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5751 - val_loss: 1.8705\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.4465 - val_loss: 1.9339\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.2594 - val_loss: 1.9139\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1529 - val_loss: 1.9418\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0468 - val_loss: 1.9400\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8991 - val_loss: 1.8525\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7733 - val_loss: 1.9936\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8121 - val_loss: 1.8888\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7333 - val_loss: 2.0759\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.8563\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=4, n_neurons=87; total time=   1.4s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.7649 - val_loss: 1.9048\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4450 - val_loss: 1.8386\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1886 - val_loss: 1.7349\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8795 - val_loss: 1.7865\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6296 - val_loss: 1.7878\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4633 - val_loss: 1.8091\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3055 - val_loss: 1.7796\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1650 - val_loss: 1.7551\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0630 - val_loss: 1.7191\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9611 - val_loss: 1.6783\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8508 - val_loss: 1.6250\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7809 - val_loss: 1.7173\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.7038 - val_loss: 1.6001\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6512 - val_loss: 1.8780\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6453 - val_loss: 1.7495\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5930 - val_loss: 1.5740\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5651 - val_loss: 1.7095\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5546 - val_loss: 1.7057\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5515 - val_loss: 1.7140\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5045 - val_loss: 1.6606\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4254 - val_loss: 1.5612\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4287 - val_loss: 1.7620\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3991 - val_loss: 1.6749\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4007 - val_loss: 1.6131\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3430 - val_loss: 1.8337\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3712 - val_loss: 1.8611\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3576 - val_loss: 1.7319\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3256 - val_loss: 1.7732\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2950 - val_loss: 1.7515\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2769 - val_loss: 1.6422\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2708 - val_loss: 1.7638\n",
      "6/6 [==============================] - 0s 905us/step - loss: 1.7519\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=4, n_neurons=87; total time=   1.9s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.5822 - val_loss: 2.0021\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3192 - val_loss: 1.9215\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1142 - val_loss: 1.8249\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8739 - val_loss: 1.8269\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6499 - val_loss: 1.7310\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.4075 - val_loss: 1.7211\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.2883 - val_loss: 1.7157\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1688 - val_loss: 1.7593\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9907 - val_loss: 1.7242\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8818 - val_loss: 1.7399\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8825 - val_loss: 1.7580\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7873 - val_loss: 1.7463\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6963 - val_loss: 1.9828\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8276 - val_loss: 1.6931\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7023 - val_loss: 1.6531\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6650 - val_loss: 1.6449\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5168 - val_loss: 1.6954\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5419 - val_loss: 1.6288\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4915 - val_loss: 1.6158\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4367 - val_loss: 1.6034\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4392 - val_loss: 1.6037\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3764 - val_loss: 1.6179\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3270 - val_loss: 1.5616\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2985 - val_loss: 1.5687\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3075 - val_loss: 1.6629\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2811 - val_loss: 1.6013\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2990 - val_loss: 1.5942\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2756 - val_loss: 1.5725\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2742 - val_loss: 1.5317\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2601 - val_loss: 1.5330\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2717 - val_loss: 1.5990\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3019 - val_loss: 1.5560\n",
      "Epoch 33/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2889 - val_loss: 1.7890\n",
      "Epoch 34/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2174 - val_loss: 1.5208\n",
      "Epoch 35/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2368 - val_loss: 1.5202\n",
      "Epoch 36/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2005 - val_loss: 1.6589\n",
      "Epoch 37/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2076 - val_loss: 1.5157\n",
      "Epoch 38/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1927 - val_loss: 1.6249\n",
      "Epoch 39/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1611 - val_loss: 1.6368\n",
      "Epoch 40/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1561 - val_loss: 1.5658\n",
      "Epoch 41/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1402 - val_loss: 1.5665\n",
      "Epoch 42/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1498 - val_loss: 1.5600\n",
      "Epoch 43/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1492 - val_loss: 1.6516\n",
      "Epoch 44/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1068 - val_loss: 1.5968\n",
      "Epoch 45/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1235 - val_loss: 1.6080\n",
      "Epoch 46/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1265 - val_loss: 1.6735\n",
      "Epoch 47/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1440 - val_loss: 1.5869\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.7281\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=4, n_neurons=87; total time=   2.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.6392 - val_loss: 1.9808\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4254 - val_loss: 1.9371\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2326 - val_loss: 1.8716\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9806 - val_loss: 1.7781\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7399 - val_loss: 1.8310\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5799 - val_loss: 1.8700\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3801 - val_loss: 1.7742\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2343 - val_loss: 1.6983\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0485 - val_loss: 1.7954\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9449 - val_loss: 1.6453\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7901 - val_loss: 1.7876\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8524 - val_loss: 1.7644\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7851 - val_loss: 1.6628\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6016 - val_loss: 1.7366\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5124 - val_loss: 1.7731\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5083 - val_loss: 1.7847\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4712 - val_loss: 1.7708\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4243 - val_loss: 1.8115\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4215 - val_loss: 1.8539\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4188 - val_loss: 1.8000\n",
      "6/6 [==============================] - 0s 916us/step - loss: 1.8435\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=4, n_neurons=85; total time=   1.4s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.7484 - val_loss: 1.9273\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4491 - val_loss: 1.8796\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1646 - val_loss: 1.7715\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7958 - val_loss: 1.8054\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5325 - val_loss: 1.7518\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3948 - val_loss: 1.6525\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3300 - val_loss: 1.8082\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2327 - val_loss: 1.6836\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0001 - val_loss: 1.6450\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8949 - val_loss: 1.7320\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8075 - val_loss: 1.5806\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7368 - val_loss: 1.6831\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6702 - val_loss: 1.6332\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5860 - val_loss: 1.7845\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5760 - val_loss: 1.7113\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4980 - val_loss: 1.6466\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4404 - val_loss: 1.7082\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4373 - val_loss: 1.7073\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4117 - val_loss: 1.8211\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3884 - val_loss: 1.6589\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3545 - val_loss: 1.6322\n",
      "6/6 [==============================] - 0s 987us/step - loss: 1.7115\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=4, n_neurons=85; total time=   1.5s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.5507 - val_loss: 2.0052\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2993 - val_loss: 1.9299\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0623 - val_loss: 1.8626\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8161 - val_loss: 1.8594\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5922 - val_loss: 1.7202\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3321 - val_loss: 1.7159\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1675 - val_loss: 1.7207\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0701 - val_loss: 1.8163\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9863 - val_loss: 1.7062\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8570 - val_loss: 1.8166\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8627 - val_loss: 1.7149\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8105 - val_loss: 1.7219\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7129 - val_loss: 1.9366\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7639 - val_loss: 1.7472\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6671 - val_loss: 1.6747\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6561 - val_loss: 1.7562\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5410 - val_loss: 1.7368\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5709 - val_loss: 1.6875\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4865 - val_loss: 1.6761\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4298 - val_loss: 1.7436\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4248 - val_loss: 1.6893\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3839 - val_loss: 1.7878\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3312 - val_loss: 1.6753\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3133 - val_loss: 1.6915\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3216 - val_loss: 1.7986\n",
      "6/6 [==============================] - 0s 990us/step - loss: 1.9547\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=4, n_neurons=85; total time=   1.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 10ms/step - loss: 2.7147 - val_loss: 2.0551\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5788 - val_loss: 2.0091\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4956 - val_loss: 1.9853\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4269 - val_loss: 1.9553\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3624 - val_loss: 1.9122\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2509 - val_loss: 1.8773\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1582 - val_loss: 1.8498\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0352 - val_loss: 1.8092\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9133 - val_loss: 1.7646\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7608 - val_loss: 1.7728\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6542 - val_loss: 1.7715\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5209 - val_loss: 1.7717\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4358 - val_loss: 1.7277\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3709 - val_loss: 1.7563\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2897 - val_loss: 1.7597\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2263 - val_loss: 1.7466\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1981 - val_loss: 1.7179\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1383 - val_loss: 1.7493\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0871 - val_loss: 1.7221\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0393 - val_loss: 1.7423\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9890 - val_loss: 1.7188\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9664 - val_loss: 1.7932\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9242 - val_loss: 1.6775\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9069 - val_loss: 1.7365\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8716 - val_loss: 1.7026\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8767 - val_loss: 1.7501\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8140 - val_loss: 1.6751\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7867 - val_loss: 1.6880\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7720 - val_loss: 1.7392\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7425 - val_loss: 1.7276\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7176 - val_loss: 1.7134\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6983 - val_loss: 1.6925\n",
      "Epoch 33/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6699 - val_loss: 1.7104\n",
      "Epoch 34/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6602 - val_loss: 1.6704\n",
      "Epoch 35/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6248 - val_loss: 1.7068\n",
      "Epoch 36/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6442 - val_loss: 1.7219\n",
      "Epoch 37/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6181 - val_loss: 1.7063\n",
      "Epoch 38/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6083 - val_loss: 1.7252\n",
      "Epoch 39/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5912 - val_loss: 1.7348\n",
      "Epoch 40/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5824 - val_loss: 1.6952\n",
      "Epoch 41/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5635 - val_loss: 1.6992\n",
      "Epoch 42/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5381 - val_loss: 1.7413\n",
      "Epoch 43/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5349 - val_loss: 1.7056\n",
      "Epoch 44/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5532 - val_loss: 1.7219\n",
      "6/6 [==============================] - 0s 855us/step - loss: 2.2314\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=3, n_neurons=17; total time=   2.1s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 10ms/step - loss: 2.7273 - val_loss: 1.9922\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5843 - val_loss: 1.9586\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4754 - val_loss: 1.9228\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3699 - val_loss: 1.8832\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2656 - val_loss: 1.8483\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1383 - val_loss: 1.8225\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0365 - val_loss: 1.8013\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9178 - val_loss: 1.7870\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7913 - val_loss: 1.7423\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6795 - val_loss: 1.7410\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5668 - val_loss: 1.7238\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4697 - val_loss: 1.6795\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3910 - val_loss: 1.6738\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3298 - val_loss: 1.6506\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2744 - val_loss: 1.6614\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1959 - val_loss: 1.6390\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1593 - val_loss: 1.6155\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0812 - val_loss: 1.5736\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0403 - val_loss: 1.5942\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0501 - val_loss: 1.6125\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9661 - val_loss: 1.5758\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9414 - val_loss: 1.6004\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9052 - val_loss: 1.5526\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8589 - val_loss: 1.5570\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8215 - val_loss: 1.5963\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8104 - val_loss: 1.5958\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7759 - val_loss: 1.5713\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7231 - val_loss: 1.5587\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6965 - val_loss: 1.5868\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7013 - val_loss: 1.5593\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6720 - val_loss: 1.5689\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6437 - val_loss: 1.5664\n",
      "Epoch 33/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6412 - val_loss: 1.6206\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 2.2008\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=3, n_neurons=17; total time=   1.7s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 10ms/step - loss: 2.6227 - val_loss: 2.0817\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3837 - val_loss: 2.0336\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2653 - val_loss: 1.9729\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1824 - val_loss: 1.9326\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1013 - val_loss: 1.9032\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0115 - val_loss: 1.8558\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9242 - val_loss: 1.8381\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8316 - val_loss: 1.7946\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7418 - val_loss: 1.7743\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6341 - val_loss: 1.7404\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5763 - val_loss: 1.7259\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.4313 - val_loss: 1.6861\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3571 - val_loss: 1.6703\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2781 - val_loss: 1.6735\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1729 - val_loss: 1.6962\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1067 - val_loss: 1.6988\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0493 - val_loss: 1.7236\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0559 - val_loss: 1.8186\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9294 - val_loss: 1.7670\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8817 - val_loss: 1.8052\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8560 - val_loss: 1.8057\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8023 - val_loss: 1.8920\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7852 - val_loss: 1.8512\n",
      "6/6 [==============================] - 0s 799us/step - loss: 1.9126\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=3, n_neurons=17; total time=   1.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 10ms/step - loss: 2.6328 - val_loss: 1.9733\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4921 - val_loss: 1.9426\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4072 - val_loss: 1.9119\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2983 - val_loss: 1.8845\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2145 - val_loss: 1.8462\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0860 - val_loss: 1.8239\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9601 - val_loss: 1.8107\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8285 - val_loss: 1.8054\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.7111 - val_loss: 1.7873\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5743 - val_loss: 1.8158\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4947 - val_loss: 1.8260\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3896 - val_loss: 1.8535\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2904 - val_loss: 1.8095\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1811 - val_loss: 1.8920\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1008 - val_loss: 1.8828\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0226 - val_loss: 1.8994\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9736 - val_loss: 1.8595\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9028 - val_loss: 1.9669\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8512 - val_loss: 1.8947\n",
      "6/6 [==============================] - 0s 905us/step - loss: 1.6133\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=3, n_neurons=20; total time=   1.2s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 10ms/step - loss: 2.7889 - val_loss: 2.0662\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6220 - val_loss: 2.0059\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5281 - val_loss: 1.9614\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4106 - val_loss: 1.9237\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2877 - val_loss: 1.8897\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1228 - val_loss: 1.8350\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9588 - val_loss: 1.8283\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7661 - val_loss: 1.7868\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5994 - val_loss: 1.7510\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4807 - val_loss: 1.8143\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3726 - val_loss: 1.7646\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2986 - val_loss: 1.8043\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2432 - val_loss: 1.7321\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1526 - val_loss: 1.8416\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1487 - val_loss: 1.7695\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0424 - val_loss: 1.7386\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0052 - val_loss: 1.7369\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9454 - val_loss: 1.7141\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9128 - val_loss: 1.8112\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8782 - val_loss: 1.7576\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8219 - val_loss: 1.7548\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8077 - val_loss: 1.8095\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7833 - val_loss: 1.7974\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7634 - val_loss: 1.7923\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6961 - val_loss: 1.8127\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7004 - val_loss: 1.8390\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6456 - val_loss: 1.8028\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6076 - val_loss: 1.8283\n",
      "6/6 [==============================] - 0s 983us/step - loss: 1.9575\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=3, n_neurons=20; total time=   1.5s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 29ms/step - loss: 2.7572 - val_loss: 2.0338\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4266 - val_loss: 1.9697\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3067 - val_loss: 1.9344\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2115 - val_loss: 1.9087\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1104 - val_loss: 1.8678\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0051 - val_loss: 1.8406\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8892 - val_loss: 1.8302\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7625 - val_loss: 1.7922\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6544 - val_loss: 1.8042\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5503 - val_loss: 1.7836\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4947 - val_loss: 1.7679\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3759 - val_loss: 1.7366\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3160 - val_loss: 1.7439\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3004 - val_loss: 1.7429\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2090 - val_loss: 1.8136\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1484 - val_loss: 1.7898\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1020 - val_loss: 1.7547\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0228 - val_loss: 1.7730\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9813 - val_loss: 1.7556\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9353 - val_loss: 1.8055\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9059 - val_loss: 1.7952\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8461 - val_loss: 1.7936\n",
      "6/6 [==============================] - 0s 968us/step - loss: 1.9466\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=3, n_neurons=20; total time=   1.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.6359 - val_loss: 1.9942\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4624 - val_loss: 1.9617\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3407 - val_loss: 1.9084\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1719 - val_loss: 1.8680\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9976 - val_loss: 1.9277\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8009 - val_loss: 1.9052\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5782 - val_loss: 1.8959\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4204 - val_loss: 1.8750\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2497 - val_loss: 2.0249\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1743 - val_loss: 1.8733\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.0335 - val_loss: 1.9351\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9773 - val_loss: 1.8701\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8708 - val_loss: 1.8570\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7263 - val_loss: 1.9309\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6810 - val_loss: 1.9591\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6468 - val_loss: 2.0118\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6076 - val_loss: 1.9159\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5513 - val_loss: 1.9686\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5279 - val_loss: 1.9747\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5136 - val_loss: 1.9889\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5031 - val_loss: 1.9515\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4574 - val_loss: 1.9799\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4786 - val_loss: 1.8948\n",
      "6/6 [==============================] - 0s 954us/step - loss: 1.9450\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=5, n_neurons=48; total time=   1.6s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.7481 - val_loss: 2.0118\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6485 - val_loss: 1.9506\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5216 - val_loss: 1.8818\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3708 - val_loss: 1.7925\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.1474 - val_loss: 1.7057\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8506 - val_loss: 1.6680\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6244 - val_loss: 1.7044\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4222 - val_loss: 1.7069\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2572 - val_loss: 1.6894\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1677 - val_loss: 1.6509\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0539 - val_loss: 1.6430\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9699 - val_loss: 1.6245\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8844 - val_loss: 1.5759\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7807 - val_loss: 1.7806\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7571 - val_loss: 1.6543\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6913 - val_loss: 1.6457\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6346 - val_loss: 1.6821\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6119 - val_loss: 1.6946\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6174 - val_loss: 1.7327\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5371 - val_loss: 1.6832\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4507 - val_loss: 1.6676\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4274 - val_loss: 1.8044\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4089 - val_loss: 1.7377\n",
      "6/6 [==============================] - 0s 997us/step - loss: 2.0052\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=5, n_neurons=48; total time=   1.6s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.5027 - val_loss: 1.9875\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3221 - val_loss: 1.9271\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1713 - val_loss: 1.8705\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0087 - val_loss: 1.8750\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8393 - val_loss: 1.8238\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6304 - val_loss: 1.8053\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4862 - val_loss: 1.8201\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3641 - val_loss: 1.7713\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2460 - val_loss: 1.7553\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1657 - val_loss: 1.7730\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1224 - val_loss: 1.7726\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0039 - val_loss: 1.7525\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8941 - val_loss: 1.9231\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9675 - val_loss: 1.7820\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8234 - val_loss: 1.7828\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7744 - val_loss: 1.8346\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7046 - val_loss: 1.8495\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6652 - val_loss: 1.7656\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6027 - val_loss: 1.8795\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5530 - val_loss: 1.8663\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5705 - val_loss: 1.8777\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4821 - val_loss: 1.8517\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.8654\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=5, n_neurons=48; total time=   1.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.6033 - val_loss: 1.8536\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3187 - val_loss: 1.8036\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9643 - val_loss: 1.7320\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6599 - val_loss: 1.7690\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4134 - val_loss: 1.7461\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3547 - val_loss: 1.7657\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.1189 - val_loss: 1.7990\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.9566 - val_loss: 2.0263\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9028 - val_loss: 1.9580\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8376 - val_loss: 1.7905\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6967 - val_loss: 2.0165\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7959 - val_loss: 1.6746\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6535 - val_loss: 1.8253\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5284 - val_loss: 1.7292\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4999 - val_loss: 1.7568\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5313 - val_loss: 1.8239\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5327 - val_loss: 1.7454\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4323 - val_loss: 1.6399\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3680 - val_loss: 1.6983\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3474 - val_loss: 1.6788\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3248 - val_loss: 1.7708\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3340 - val_loss: 1.6495\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3990 - val_loss: 1.8598\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3585 - val_loss: 1.6811\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2945 - val_loss: 1.7645\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2839 - val_loss: 1.6720\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3154 - val_loss: 1.5991\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2219 - val_loss: 1.7647\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2461 - val_loss: 1.6870\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2191 - val_loss: 1.6922\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2312 - val_loss: 1.7070\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2332 - val_loss: 1.7151\n",
      "Epoch 33/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1950 - val_loss: 1.6635\n",
      "Epoch 34/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2376 - val_loss: 1.7023\n",
      "Epoch 35/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2144 - val_loss: 1.7051\n",
      "Epoch 36/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2451 - val_loss: 1.7860\n",
      "Epoch 37/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2436 - val_loss: 1.7090\n",
      "6/6 [==============================] - 0s 893us/step - loss: 1.6406\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=4, n_neurons=95; total time=   2.1s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.6640 - val_loss: 1.8477\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0625 - val_loss: 1.8462\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6636 - val_loss: 1.8956\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5085 - val_loss: 1.9865\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2927 - val_loss: 1.7671\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0878 - val_loss: 1.6212\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9751 - val_loss: 1.6375\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8789 - val_loss: 1.5896\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8470 - val_loss: 1.5161\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7307 - val_loss: 1.5108\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6686 - val_loss: 1.4639\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5364 - val_loss: 1.5878\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5454 - val_loss: 1.5358\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5230 - val_loss: 1.4522\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5256 - val_loss: 1.6397\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4465 - val_loss: 1.4780\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4376 - val_loss: 1.5926\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3640 - val_loss: 1.6026\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5254 - val_loss: 1.5572\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4031 - val_loss: 1.4552\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4384 - val_loss: 1.6040\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3860 - val_loss: 1.5344\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3698 - val_loss: 1.7062\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3555 - val_loss: 1.7014\n",
      "6/6 [==============================] - 0s 893us/step - loss: 1.7850\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=4, n_neurons=95; total time=   1.6s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.4784 - val_loss: 2.1547\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1573 - val_loss: 1.8661\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7609 - val_loss: 1.8482\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4863 - val_loss: 1.7960\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3600 - val_loss: 1.7535\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.1214 - val_loss: 1.6745\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0036 - val_loss: 1.8333\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9593 - val_loss: 1.9314\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9087 - val_loss: 1.7722\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8765 - val_loss: 1.7676\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7775 - val_loss: 1.6287\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7395 - val_loss: 1.7974\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6550 - val_loss: 1.6909\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6354 - val_loss: 1.6763\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6228 - val_loss: 1.5974\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6626 - val_loss: 1.6912\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4981 - val_loss: 1.6294\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5155 - val_loss: 1.6532\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3813 - val_loss: 1.6876\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3225 - val_loss: 1.6664\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3439 - val_loss: 1.6442\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3385 - val_loss: 1.6317\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2706 - val_loss: 1.5253\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2474 - val_loss: 1.5956\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2742 - val_loss: 1.7022\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2635 - val_loss: 1.5617\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2661 - val_loss: 1.5799\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1976 - val_loss: 1.5989\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2206 - val_loss: 1.6901\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2587 - val_loss: 1.5140\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2382 - val_loss: 1.6904\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1762 - val_loss: 1.4449\n",
      "Epoch 33/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2052 - val_loss: 1.7331\n",
      "Epoch 34/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1804 - val_loss: 1.4832\n",
      "Epoch 35/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2020 - val_loss: 1.6163\n",
      "Epoch 36/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1677 - val_loss: 1.4776\n",
      "Epoch 37/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1312 - val_loss: 1.5542\n",
      "Epoch 38/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1335 - val_loss: 1.6006\n",
      "Epoch 39/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 1.6285\n",
      "Epoch 40/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1191 - val_loss: 1.5204\n",
      "Epoch 41/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1010 - val_loss: 1.5741\n",
      "Epoch 42/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0922 - val_loss: 1.5347\n",
      "6/6 [==============================] - 0s 992us/step - loss: 1.9320\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=4, n_neurons=95; total time=   2.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.6390 - val_loss: 1.9632\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4407 - val_loss: 1.9131\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2306 - val_loss: 1.8286\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9052 - val_loss: 1.7885\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5555 - val_loss: 1.7745\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4388 - val_loss: 1.8399\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.1679 - val_loss: 1.8169\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.0818 - val_loss: 1.8077\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8841 - val_loss: 1.8258\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8069 - val_loss: 1.9160\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6735 - val_loss: 2.0923\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6610 - val_loss: 1.9321\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5779 - val_loss: 2.1976\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6032 - val_loss: 1.8565\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5366 - val_loss: 1.9415\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 2.0285\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=5, n_neurons=88; total time=   1.3s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 12ms/step - loss: 2.6795 - val_loss: 1.9253\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3667 - val_loss: 1.9082\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0567 - val_loss: 1.9608\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8796 - val_loss: 1.8429\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5899 - val_loss: 1.8250\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.3859 - val_loss: 1.7007\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.1875 - val_loss: 1.6806\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0756 - val_loss: 1.7413\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9311 - val_loss: 1.6473\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8468 - val_loss: 1.6661\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6917 - val_loss: 1.6402\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6325 - val_loss: 1.7044\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5763 - val_loss: 1.8548\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5766 - val_loss: 1.6878\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5220 - val_loss: 1.8437\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5115 - val_loss: 1.7906\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5435 - val_loss: 1.8804\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4490 - val_loss: 1.6634\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3945 - val_loss: 1.8477\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3796 - val_loss: 1.7581\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3791 - val_loss: 1.8579\n",
      "6/6 [==============================] - 0s 898us/step - loss: 1.9106\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=5, n_neurons=88; total time=   1.6s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.5122 - val_loss: 2.0657\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3306 - val_loss: 1.9324\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0937 - val_loss: 1.8708\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8498 - val_loss: 1.8381\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6317 - val_loss: 1.6939\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3783 - val_loss: 1.6409\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2062 - val_loss: 1.7529\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1528 - val_loss: 1.6796\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9546 - val_loss: 1.6176\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8240 - val_loss: 1.7329\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7908 - val_loss: 1.7586\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.7858 - val_loss: 1.7735\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7049 - val_loss: 1.7284\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5693 - val_loss: 1.7781\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5615 - val_loss: 1.8747\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5624 - val_loss: 1.9416\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4984 - val_loss: 1.6006\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3704 - val_loss: 1.7340\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3027 - val_loss: 1.7711\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3336 - val_loss: 1.7124\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3460 - val_loss: 1.7393\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3186 - val_loss: 1.7652\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2463 - val_loss: 1.7067\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2038 - val_loss: 1.7298\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2857 - val_loss: 1.8427\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3018 - val_loss: 1.8562\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3149 - val_loss: 1.7619\n",
      "6/6 [==============================] - 0s 992us/step - loss: 1.8605\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=5, n_neurons=88; total time=   1.8s\n",
      "Epoch 1/300\n",
      "18/18 [==============================] - 1s 7ms/step - loss: 2.5564 - val_loss: 1.8864\n",
      "Epoch 2/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.1999 - val_loss: 1.7630\n",
      "Epoch 3/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.8711 - val_loss: 1.6792\n",
      "Epoch 4/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.6430 - val_loss: 1.7340\n",
      "Epoch 5/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.5822 - val_loss: 1.6662\n",
      "Epoch 6/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3973 - val_loss: 1.6236\n",
      "Epoch 7/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.2174 - val_loss: 1.6528\n",
      "Epoch 8/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0433 - val_loss: 1.5566\n",
      "Epoch 9/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9381 - val_loss: 1.6160\n",
      "Epoch 10/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8323 - val_loss: 1.6400\n",
      "Epoch 11/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7687 - val_loss: 1.6333\n",
      "Epoch 12/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7207 - val_loss: 1.5336\n",
      "Epoch 13/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7051 - val_loss: 1.5610\n",
      "Epoch 14/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6341 - val_loss: 1.5433\n",
      "Epoch 15/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6061 - val_loss: 1.5065\n",
      "Epoch 16/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6037 - val_loss: 1.6091\n",
      "Epoch 17/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6091 - val_loss: 1.5823\n",
      "Epoch 18/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5559 - val_loss: 1.4147\n",
      "Epoch 19/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5135 - val_loss: 1.5970\n",
      "Epoch 20/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4911 - val_loss: 1.5228\n",
      "Epoch 21/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - val_loss: 1.6653\n",
      "Epoch 22/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - val_loss: 1.4324\n",
      "Epoch 23/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4175 - val_loss: 1.4768\n",
      "Epoch 24/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4708 - val_loss: 1.4874\n",
      "Epoch 25/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - val_loss: 1.5290\n",
      "Epoch 26/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3939 - val_loss: 1.4125\n",
      "Epoch 27/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3477 - val_loss: 1.6096\n",
      "Epoch 28/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3377 - val_loss: 1.4071\n",
      "Epoch 29/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4002 - val_loss: 1.4426\n",
      "Epoch 30/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3454 - val_loss: 1.7921\n",
      "Epoch 31/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - val_loss: 1.4109\n",
      "Epoch 32/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3443 - val_loss: 1.4040\n",
      "Epoch 33/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2813 - val_loss: 1.4827\n",
      "Epoch 34/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3108 - val_loss: 1.5017\n",
      "Epoch 35/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2852 - val_loss: 1.4754\n",
      "Epoch 36/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2696 - val_loss: 1.4530\n",
      "Epoch 37/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2240 - val_loss: 1.4738\n",
      "Epoch 38/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2514 - val_loss: 1.4616\n",
      "Epoch 39/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2209 - val_loss: 1.4151\n",
      "Epoch 40/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2236 - val_loss: 1.4139\n",
      "Epoch 41/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2296 - val_loss: 1.3876\n",
      "Epoch 42/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2175 - val_loss: 1.5372\n",
      "Epoch 43/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2674 - val_loss: 1.4253\n",
      "Epoch 44/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2529 - val_loss: 1.4428\n",
      "Epoch 45/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2619 - val_loss: 1.5217\n",
      "Epoch 46/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2411 - val_loss: 1.3753\n",
      "Epoch 47/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2232 - val_loss: 1.5770\n",
      "Epoch 48/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1952 - val_loss: 1.4507\n",
      "Epoch 49/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1867 - val_loss: 1.3758\n",
      "Epoch 50/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2224 - val_loss: 1.5017\n",
      "Epoch 51/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1973 - val_loss: 1.4060\n",
      "Epoch 52/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1819 - val_loss: 1.4380\n",
      "Epoch 53/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1801 - val_loss: 1.4838\n",
      "Epoch 54/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1662 - val_loss: 1.4268\n",
      "Epoch 55/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1799 - val_loss: 1.5533\n",
      "Epoch 56/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2067 - val_loss: 1.4604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=3,\n",
       "              estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x00000273DFE71160>,\n",
       "              n_iter=10,\n",
       "              search_spaces={'learning_rate': array([0.0001, 0.0011, 0.0021]),\n",
       "                             'n_hidden': [2, 3, 4, 5, 6],\n",
       "                             'n_neurons': array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,\n",
       "       27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43,\n",
       "       44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n",
       "       61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77,\n",
       "       78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94,\n",
       "       95, 96, 97, 98, 99])},\n",
       "              verbose=2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import skopt\n",
    "\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [2,3, 4, 5, 6],\n",
    "    \"n_neurons\": np.arange(10,100),\n",
    "    \"learning_rate\": np.arange(0.0001, 0.003, 0.001),\n",
    "}\n",
    "\n",
    "bayes_search_cv = skopt.BayesSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "bayes_search_cv.fit(X_train3, y_train3, epochs=300,\n",
    "                  validation_data=(X_test3, y_test3),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('learning_rate', 0.0011), ('n_hidden', 4), ('n_neurons', 87)])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.7787501017252605"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 933us/step - loss: 1.4604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.4603556394577026"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_search_cv.score(X_test3, y_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_127\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_684 (Dense)           (None, 87)                6090      \n",
      "                                                                 \n",
      " dense_685 (Dense)           (None, 87)                7656      \n",
      "                                                                 \n",
      " dense_686 (Dense)           (None, 87)                7656      \n",
      "                                                                 \n",
      " dense_687 (Dense)           (None, 87)                7656      \n",
      "                                                                 \n",
      " dense_688 (Dense)           (None, 1)                 88        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,146\n",
      "Trainable params: 29,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = bayes_search_cv.best_estimator_.model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 868us/step - loss: 1.4604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.4603556394577026"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test3, y_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.224744871391589"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(1.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb7b73d107179de93e518a613ce6d462bfe492e7a25dfa42dc5e63cc08cf43c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
