{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# For Prediction:\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib as mpl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# For nice Plots\n",
    "%matplotlib inline\n",
    "plt.style.use('default')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.abspath(\"\")\n",
    "fname = dir_path+'\\countrydf.csv'\n",
    "countrydf = pd.read_csv(fname, encoding='latin-1')\n",
    "countrydf = countrydf.loc[:, ~countrydf.columns.str.contains('^Unnamed')]\n",
    "countrydf = countrydf.drop([\"Country\", \"Year\"],axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Average dietary energy supply adequacy (percent) (3-year average)  \\\n",
      "0                                              1.031639                   \n",
      "1                                              1.169786                   \n",
      "2                                              1.238859                   \n",
      "3                                              1.238859                   \n",
      "4                                              1.307932                   \n",
      "...                                                 ...                   \n",
      "1075                                           0.202758                   \n",
      "1076                                           0.202758                   \n",
      "1077                                           0.202758                   \n",
      "1078                                           0.202758                   \n",
      "1079                                                NaN                   \n",
      "\n",
      "      Dietary energy supply used in the estimation of prevalence of undernourishment (kcal/cap/day) (3-year average)  \\\n",
      "0                                              1.101521                                                                \n",
      "1                                              1.244594                                                                \n",
      "2                                              1.338241                                                                \n",
      "3                                              1.372058                                                                \n",
      "4                                              1.447497                                                                \n",
      "...                                                 ...                                                                \n",
      "1075                                           0.196263                                                                \n",
      "1076                                           0.191060                                                                \n",
      "1077                                           0.193661                                                                \n",
      "1078                                           0.193661                                                                \n",
      "1079                                                NaN                                                                \n",
      "\n",
      "      Share of dietary energy supply derived from cereals, roots and tubers (kcal/cap/day) (3-year average)  \\\n",
      "0                                             -0.153666                                                       \n",
      "1                                             -0.153666                                                       \n",
      "2                                             -0.153666                                                       \n",
      "3                                             -0.153666                                                       \n",
      "4                                             -0.153666                                                       \n",
      "...                                                 ...                                                       \n",
      "1075                                           0.069055                                                       \n",
      "1076                                           0.180416                                                       \n",
      "1077                                           0.180416                                                       \n",
      "1078                                                NaN                                                       \n",
      "1079                                                NaN                                                       \n",
      "\n",
      "      Average protein supply (g/cap/day) (3-year average)  \\\n",
      "0                                              0.851812     \n",
      "1                                              1.006831     \n",
      "2                                              1.136014     \n",
      "3                                              1.239360     \n",
      "4                                              1.258737     \n",
      "...                                                 ...     \n",
      "1075                                          -0.013711     \n",
      "1076                                          -0.007252     \n",
      "1077                                          -0.033088     \n",
      "1078                                                NaN     \n",
      "1079                                                NaN     \n",
      "\n",
      "      Average supply of protein of animal origin (g/cap/day) (3-year average)  \\\n",
      "0                                              0.286648                         \n",
      "1                                              0.321965                         \n",
      "2                                              0.404369                         \n",
      "3                                              0.439685                         \n",
      "4                                              0.522090                         \n",
      "...                                                 ...                         \n",
      "1075                                          -0.349043                         \n",
      "1076                                          -0.360816                         \n",
      "1077                                          -0.372588                         \n",
      "1078                                                NaN                         \n",
      "1079                                                NaN                         \n",
      "\n",
      "      Rail lines density (total route in km per 100 square km of land area)  \\\n",
      "0                                             -0.709593                       \n",
      "1                                             -0.709593                       \n",
      "2                                             -0.709593                       \n",
      "3                                             -0.709593                       \n",
      "4                                             -0.709593                       \n",
      "...                                                 ...                       \n",
      "1075                                                NaN                       \n",
      "1076                                                NaN                       \n",
      "1077                                                NaN                       \n",
      "1078                                                NaN                       \n",
      "1079                                                NaN                       \n",
      "\n",
      "      Gross domestic product per capita, PPP, (constant 2017 international $)  \\\n",
      "0                                                   NaN                         \n",
      "1                                                   NaN                         \n",
      "2                                                   NaN                         \n",
      "3                                                   NaN                         \n",
      "4                                                   NaN                         \n",
      "...                                                 ...                         \n",
      "1075                                          -0.101883                         \n",
      "1076                                          -0.095549                         \n",
      "1077                                          -0.094331                         \n",
      "1078                                          -0.132666                         \n",
      "1079                                                NaN                         \n",
      "\n",
      "      Prevalence of undernourishment (percent) (3-year average)  \\\n",
      "0                                             -0.926249           \n",
      "1                                             -0.983745           \n",
      "2                                             -1.008386           \n",
      "3                                             -1.008386           \n",
      "4                                             -1.033027           \n",
      "...                                                 ...           \n",
      "1075                                          -0.252720           \n",
      "1076                                          -0.219865           \n",
      "1077                                          -0.195224           \n",
      "1078                                          -0.104873           \n",
      "1079                                                NaN           \n",
      "\n",
      "      Number of people undernourished (million) (3-year average)  \\\n",
      "0                                             -0.188680            \n",
      "1                                             -0.195602            \n",
      "2                                             -0.195602            \n",
      "3                                             -0.195602            \n",
      "4                                             -0.199063            \n",
      "...                                                 ...            \n",
      "1075                                           6.518703            \n",
      "1076                                           6.857879            \n",
      "1077                                           7.197055            \n",
      "1078                                           7.882330            \n",
      "1079                                                NaN            \n",
      "\n",
      "      Prevalence of severe food insecurity in the total population (percent) (3-year average)  \\\n",
      "0                                                   NaN                                         \n",
      "1                                                   NaN                                         \n",
      "2                                                   NaN                                         \n",
      "3                                                   NaN                                         \n",
      "4                                                   NaN                                         \n",
      "...                                                 ...                                         \n",
      "1075                                          -0.145021                                         \n",
      "1076                                          -0.095448                                         \n",
      "1077                                          -0.074203                                         \n",
      "1078                                          -0.010467                                         \n",
      "1079                                                NaN                                         \n",
      "\n",
      "      ...  Number of severely food insecure people (million) (annual value)  \\\n",
      "0     ...                                                NaN                  \n",
      "1     ...                                                NaN                  \n",
      "2     ...                                                NaN                  \n",
      "3     ...                                                NaN                  \n",
      "4     ...                                                NaN                  \n",
      "...   ...                                                ...                  \n",
      "1075  ...                                           0.208498                  \n",
      "1076  ...                                           0.173330                  \n",
      "1077  ...                                           0.683272                  \n",
      "1078  ...                                           1.747117                  \n",
      "1079  ...                                                NaN                  \n",
      "\n",
      "      Number of severely food insecure male adults (million) (annual value)  \\\n",
      "0                                                   NaN                       \n",
      "1                                                   NaN                       \n",
      "2                                                   NaN                       \n",
      "3                                                   NaN                       \n",
      "4                                                   NaN                       \n",
      "...                                                 ...                       \n",
      "1075                                           0.817332                       \n",
      "1076                                           0.289449                       \n",
      "1077                                           0.553391                       \n",
      "1078                                           1.399557                       \n",
      "1079                                                NaN                       \n",
      "\n",
      "      Number of severely food insecure female adults (million) (annual value)  \\\n",
      "0                                                   NaN                         \n",
      "1                                                   NaN                         \n",
      "2                                                   NaN                         \n",
      "3                                                   NaN                         \n",
      "4                                                   NaN                         \n",
      "...                                                 ...                         \n",
      "1075                                           0.456586                         \n",
      "1076                                           0.341618                         \n",
      "1077                                           0.694185                         \n",
      "1078                                           1.537281                         \n",
      "1079                                                NaN                         \n",
      "\n",
      "      Number of moderately or severely food insecure people (million) (annual value)  \\\n",
      "0                                                   NaN                                \n",
      "1                                                   NaN                                \n",
      "2                                                   NaN                                \n",
      "3                                                   NaN                                \n",
      "4                                                   NaN                                \n",
      "...                                                 ...                                \n",
      "1075                                           0.189034                                \n",
      "1076                                           0.366241                                \n",
      "1077                                           0.765928                                \n",
      "1078                                           1.618335                                \n",
      "1079                                                NaN                                \n",
      "\n",
      "      Number of moderately or severely food insecure male adults (million) (annual value)  \\\n",
      "0                                                   NaN                                     \n",
      "1                                                   NaN                                     \n",
      "2                                                   NaN                                     \n",
      "3                                                   NaN                                     \n",
      "4                                                   NaN                                     \n",
      "...                                                 ...                                     \n",
      "1075                                           0.408950                                     \n",
      "1076                                           0.510033                                     \n",
      "1077                                           0.683894                                     \n",
      "1078                                           1.460207                                     \n",
      "1079                                                NaN                                     \n",
      "\n",
      "      Number of moderately or severely food insecure female adults (million) (annual value)  \\\n",
      "0                                                   NaN                                       \n",
      "1                                                   NaN                                       \n",
      "2                                                   NaN                                       \n",
      "3                                                   NaN                                       \n",
      "4                                                   NaN                                       \n",
      "...                                                 ...                                       \n",
      "1075                                           0.407193                                       \n",
      "1076                                           0.329493                                       \n",
      "1077                                           0.812048                                       \n",
      "1078                                           1.478629                                       \n",
      "1079                                                NaN                                       \n",
      "\n",
      "          Port  Resiliency  MODIS NDVI Annual Average  Future Undernourishment  \n",
      "0     1.187051    3.529440                  -1.602383                     -0.7  \n",
      "1     1.187051    3.529440                  -1.602383                     -0.3  \n",
      "2     1.187051    3.529440                  -1.602966                      0.0  \n",
      "3     1.187051    3.529440                  -1.602383                     -0.3  \n",
      "4     1.187051    3.529440                  -1.602383                     -0.3  \n",
      "...        ...         ...                        ...                      ...  \n",
      "1075 -0.842424   -0.031036                   0.013426                      0.4  \n",
      "1076 -0.842424   -0.031036                   0.013426                      0.3  \n",
      "1077 -0.842424   -0.031036                   0.013426                      1.1  \n",
      "1078 -0.842424   -0.031036                   0.013205                      1.1  \n",
      "1079 -0.842424   -0.031036                   0.013426                      NaN  \n",
      "\n",
      "[1080 rows x 67 columns]\n"
     ]
    }
   ],
   "source": [
    "# Build a test set and training set\n",
    "\n",
    "cols_to_standardize = countrydf.columns.drop(['Future Undernourishment'])\n",
    "scaler = StandardScaler()\n",
    "countrydf[cols_to_standardize] = scaler.fit_transform(countrydf[cols_to_standardize])\n",
    "\n",
    "# Print the standardized dataframe\n",
    "print(countrydf)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  countrydf.drop([\"Future Undernourishment\"], axis=1), countrydf[\"Future Undernourishment\"], test_size=1/3, random_state = 42)\n",
    "\n",
    "# Replace all the NaNs with the column mean, \n",
    "# and build the test set and training set using the indicies from the first set\n",
    "countrydf2 = countrydf.fillna(countrydf.mean())\n",
    "# Build a test set and training set\n",
    "X_train2 = countrydf2.drop([\"Future Undernourishment\"], axis=1).iloc[X_train.index]\n",
    "X_test2 = countrydf2.drop([\"Future Undernourishment\"], axis=1).iloc[X_test.index]\n",
    "y_train2 = countrydf2[\"Future Undernourishment\"].iloc[y_train.index]\n",
    "y_test2 = countrydf2[\"Future Undernourishment\"].iloc[y_test.index]\n",
    "\n",
    "# Use only rows with non-NaN response variable, then replace all the NaNs with the column mean \n",
    "# and build the test set and training set using the indicies from the first set\n",
    "keep_indices_test = np.where(y_test.notna())\n",
    "keep_indices_train = np.where(y_train.notna())\n",
    "# Build a test set and training set\n",
    "X_train3 = X_train2.iloc[keep_indices_train]\n",
    "X_test3 = X_test2.iloc[keep_indices_test]\n",
    "y_train3 = y_train2.iloc[keep_indices_train]\n",
    "y_test3 = y_test2.iloc[keep_indices_test]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(loss, val_loss):\n",
    "    plt.plot(np.arange(len(loss)) + 0.5, loss, \"b.-\", label=\"Training loss\")\n",
    "    plt.plot(np.arange(len(val_loss)) + 1, val_loss, \"r.-\", label=\"Validation loss\")\n",
    "    plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
    "    #plt.axis([1, 20, 0, 0.05])\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN for Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def build_model2(n_hidden=1, n_neurons=60, learning_rate=1e-3, input_shape=X_train2.shape[1]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stvp2\\AppData\\Local\\Temp\\ipykernel_38324\\3141062689.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model2)\n"
     ]
    }
   ],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "Epoch 1/160\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 2.0847 - val_loss: 1.5143\n",
      "Epoch 2/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.8691 - val_loss: 1.4258\n",
      "Epoch 3/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6970 - val_loss: 1.3678\n",
      "Epoch 4/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.5187 - val_loss: 1.3524\n",
      "Epoch 5/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.3542 - val_loss: 1.3250\n",
      "Epoch 6/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.1899 - val_loss: 1.3031\n",
      "Epoch 7/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.1100 - val_loss: 1.2670\n",
      "Epoch 8/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.0513 - val_loss: 1.4066\n",
      "Epoch 9/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.9325 - val_loss: 1.2920\n",
      "Epoch 10/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.8946 - val_loss: 1.2528\n",
      "Epoch 11/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.8392 - val_loss: 1.3563\n",
      "Epoch 12/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.7715 - val_loss: 1.2497\n",
      "Epoch 13/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6790 - val_loss: 1.2704\n",
      "Epoch 14/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6098 - val_loss: 1.2159\n",
      "Epoch 15/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5880 - val_loss: 1.2995\n",
      "Epoch 16/160\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5749 - val_loss: 1.2930\n",
      "Epoch 17/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5490 - val_loss: 1.2274\n",
      "Epoch 18/160\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5306 - val_loss: 1.2674\n",
      "Epoch 19/160\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4268 - val_loss: 1.1695\n",
      "Epoch 20/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4345 - val_loss: 1.2648\n",
      "Epoch 21/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4640 - val_loss: 1.2234\n",
      "Epoch 22/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5023 - val_loss: 1.1713\n",
      "Epoch 23/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3971 - val_loss: 1.2128\n",
      "Epoch 24/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3761 - val_loss: 1.1866\n",
      "Epoch 25/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3589 - val_loss: 1.1930\n",
      "Epoch 26/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3393 - val_loss: 1.2517\n",
      "Epoch 27/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3462 - val_loss: 1.1959\n",
      "Epoch 28/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3275 - val_loss: 1.2018\n",
      "Epoch 29/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3370 - val_loss: 1.2054\n",
      "Epoch 30/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2719 - val_loss: 1.1610\n",
      "Epoch 31/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2777 - val_loss: 1.1438\n",
      "Epoch 32/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3116 - val_loss: 1.2486\n",
      "Epoch 33/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3215 - val_loss: 1.2357\n",
      "Epoch 34/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2828 - val_loss: 1.2148\n",
      "Epoch 35/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2534 - val_loss: 1.1847\n",
      "Epoch 36/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2868 - val_loss: 1.2018\n",
      "Epoch 37/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2501 - val_loss: 1.2335\n",
      "Epoch 38/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2292 - val_loss: 1.1650\n",
      "Epoch 39/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2346 - val_loss: 1.1195\n",
      "Epoch 40/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2131 - val_loss: 1.1489\n",
      "Epoch 41/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2085 - val_loss: 1.1670\n",
      "Epoch 42/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2012 - val_loss: 1.2279\n",
      "Epoch 43/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2536 - val_loss: 1.1521\n",
      "Epoch 44/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2266 - val_loss: 1.1695\n",
      "Epoch 45/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2252 - val_loss: 1.1052\n",
      "Epoch 46/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2425 - val_loss: 1.1106\n",
      "Epoch 47/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2092 - val_loss: 1.1793\n",
      "Epoch 48/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1916 - val_loss: 1.1330\n",
      "Epoch 49/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1617 - val_loss: 1.1209\n",
      "Epoch 50/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1671 - val_loss: 1.1285\n",
      "Epoch 51/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1873 - val_loss: 1.1315\n",
      "Epoch 52/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2073 - val_loss: 1.0934\n",
      "Epoch 53/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1954 - val_loss: 1.1634\n",
      "Epoch 54/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1733 - val_loss: 1.1045\n",
      "Epoch 55/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1567 - val_loss: 1.1795\n",
      "Epoch 56/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1433 - val_loss: 1.0710\n",
      "Epoch 57/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1388 - val_loss: 1.1405\n",
      "Epoch 58/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1259 - val_loss: 1.1444\n",
      "Epoch 59/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1467 - val_loss: 1.1047\n",
      "Epoch 60/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1316 - val_loss: 1.1348\n",
      "Epoch 61/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1350 - val_loss: 1.0885\n",
      "Epoch 62/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1546 - val_loss: 1.0853\n",
      "Epoch 63/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1240 - val_loss: 1.0381\n",
      "Epoch 64/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1420 - val_loss: 1.0595\n",
      "Epoch 65/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1191 - val_loss: 1.0716\n",
      "Epoch 66/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1481 - val_loss: 1.1654\n",
      "Epoch 67/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1323 - val_loss: 1.2039\n",
      "Epoch 68/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1504 - val_loss: 1.0503\n",
      "Epoch 69/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1655 - val_loss: 1.1548\n",
      "Epoch 70/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1161 - val_loss: 1.0596\n",
      "Epoch 71/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1269 - val_loss: 1.1020\n",
      "Epoch 72/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1054 - val_loss: 1.1175\n",
      "Epoch 73/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1073 - val_loss: 1.0496\n",
      "Epoch 74/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1295 - val_loss: 1.1158\n",
      "Epoch 75/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1139 - val_loss: 1.1142\n",
      "Epoch 76/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1056 - val_loss: 1.1398\n",
      "Epoch 77/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1214 - val_loss: 1.2051\n",
      "Epoch 78/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1097 - val_loss: 1.0727\n",
      "Epoch 79/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1149 - val_loss: 1.0750\n",
      "Epoch 80/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0878 - val_loss: 1.1035\n",
      "Epoch 81/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0785 - val_loss: 1.0967\n",
      "Epoch 82/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1050 - val_loss: 1.0715\n",
      "Epoch 83/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 1.1499\n",
      "Epoch 84/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0924 - val_loss: 1.1470\n",
      "Epoch 85/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0878 - val_loss: 1.1194\n",
      "Epoch 86/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0951 - val_loss: 1.0734\n",
      "Epoch 87/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1213 - val_loss: 1.0535\n",
      "Epoch 88/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1407 - val_loss: 1.1269\n",
      "Epoch 89/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0943 - val_loss: 1.1056\n",
      "Epoch 90/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0964 - val_loss: 1.0991\n",
      "Epoch 91/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1212 - val_loss: 1.1284\n",
      "Epoch 92/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0956 - val_loss: 1.1169\n",
      "Epoch 93/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1041 - val_loss: 1.1329\n",
      "Epoch 94/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0908 - val_loss: 1.1844\n",
      "Epoch 95/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0995 - val_loss: 1.1364\n",
      "Epoch 96/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0937 - val_loss: 1.0938\n",
      "Epoch 97/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0725 - val_loss: 1.2037\n",
      "Epoch 98/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0852 - val_loss: 1.0896\n",
      "Epoch 99/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0920 - val_loss: 1.1030\n",
      "Epoch 100/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0774 - val_loss: 1.0727\n",
      "Epoch 101/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0810 - val_loss: 1.1028\n",
      "Epoch 102/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1021 - val_loss: 1.0847\n",
      "Epoch 103/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 1.1055\n",
      "Epoch 104/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0671 - val_loss: 1.0920\n",
      "Epoch 105/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0916 - val_loss: 1.1491\n",
      "Epoch 106/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 1.1067\n",
      "Epoch 107/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 1.1360\n",
      "Epoch 108/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0749 - val_loss: 1.1021\n",
      "Epoch 109/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 1.0797\n",
      "Epoch 110/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 1.0748\n",
      "Epoch 111/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1288 - val_loss: 1.1197\n",
      "Epoch 112/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1090 - val_loss: 1.1323\n",
      "Epoch 113/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 1.1487\n",
      "Epoch 114/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0996 - val_loss: 1.1423\n",
      "Epoch 115/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2141 - val_loss: 1.2439\n",
      "Epoch 116/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1567 - val_loss: 1.1450\n",
      "Epoch 117/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1068 - val_loss: 1.1707\n",
      "Epoch 118/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0893 - val_loss: 1.0714\n",
      "Epoch 119/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0898 - val_loss: 1.1143\n",
      "Epoch 120/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1013 - val_loss: 1.1004\n",
      "Epoch 121/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0973 - val_loss: 1.2027\n",
      "Epoch 122/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1042 - val_loss: 1.1414\n",
      "Epoch 123/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0829 - val_loss: 1.1516\n",
      "Epoch 124/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0526 - val_loss: 1.0760\n",
      "Epoch 125/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 1.1176\n",
      "Epoch 126/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0785 - val_loss: 1.1298\n",
      "Epoch 127/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0720 - val_loss: 1.0945\n",
      "Epoch 128/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 1.0810\n",
      "Epoch 129/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0344 - val_loss: 1.1132\n",
      "Epoch 130/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0313 - val_loss: 1.1150\n",
      "Epoch 131/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 1.1287\n",
      "Epoch 132/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0438 - val_loss: 1.0555\n",
      "Epoch 133/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0652 - val_loss: 1.1823\n",
      "Epoch 134/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0696 - val_loss: 1.1461\n",
      "Epoch 135/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0546 - val_loss: 1.1511\n",
      "Epoch 136/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0642 - val_loss: 1.1272\n",
      "Epoch 137/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 1.0981\n",
      "Epoch 138/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0453 - val_loss: 1.0996\n",
      "Epoch 139/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 1.0971\n",
      "Epoch 140/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 1.1276\n",
      "Epoch 141/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0551 - val_loss: 1.1208\n",
      "Epoch 142/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 1.0931\n",
      "Epoch 143/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 1.0837\n",
      "Epoch 144/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0537 - val_loss: 1.2064\n",
      "Epoch 145/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0525 - val_loss: 1.1149\n",
      "Epoch 146/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 1.1653\n",
      "Epoch 147/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 1.1287\n",
      "Epoch 148/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0396 - val_loss: 1.1175\n",
      "Epoch 149/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 1.0986\n",
      "Epoch 150/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0571 - val_loss: 1.2200\n",
      "Epoch 151/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0831 - val_loss: 1.1238\n",
      "Epoch 152/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1853 - val_loss: 1.1643\n",
      "Epoch 153/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1497 - val_loss: 1.1707\n",
      "Epoch 154/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1769 - val_loss: 1.2877\n",
      "Epoch 155/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2288 - val_loss: 1.3088\n",
      "Epoch 156/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1308 - val_loss: 1.2031\n",
      "Epoch 157/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1470 - val_loss: 1.2139\n",
      "Epoch 158/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0967 - val_loss: 1.1337\n",
      "Epoch 159/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0763 - val_loss: 1.2067\n",
      "Epoch 160/160\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 1.0896\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.random.set_seed(42)\n",
    "# define the input shape and number of classes\n",
    "input_shape = X_train2.shape[1]\n",
    "num_classes = 1\n",
    "\n",
    "# define the model architecture\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(70, activation='relu', input_shape=(input_shape,)))\n",
    "for i in range(3):\n",
    "    model.add(layers.Dense(70, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='linear'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "# compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "#print(model.summary())\n",
    "print(input_shape)\n",
    "\n",
    "# train the model\n",
    "history2 = model.fit(X_train2, y_train2, epochs=160, validation_data=(X_test2, y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.08471941947937, 1.8690911531448364, 1.697014331817627, 1.5186933279037476, 1.354235291481018, 1.189934253692627, 1.109982967376709, 1.0513075590133667, 0.9325456619262695, 0.8945663571357727, 0.8391664028167725, 0.7714693546295166, 0.6790159344673157, 0.6098228693008423, 0.5880258083343506, 0.5749223828315735, 0.5489974617958069, 0.5306382179260254, 0.42679986357688904, 0.4345107674598694, 0.46403491497039795, 0.5022796392440796, 0.39706167578697205, 0.3761407136917114, 0.35889366269111633, 0.339336097240448, 0.34615519642829895, 0.32754963636398315, 0.3370179235935211, 0.2718764543533325, 0.2777446508407593, 0.311638206243515, 0.3214733898639679, 0.28283068537712097, 0.25337955355644226, 0.28678828477859497, 0.25013846158981323, 0.2292456328868866, 0.2345980703830719, 0.21314169466495514, 0.20852775871753693, 0.20121151208877563, 0.25359246134757996, 0.22664031386375427, 0.22518499195575714, 0.24251902103424072, 0.20915722846984863, 0.1916077882051468, 0.16172407567501068, 0.1670907586812973, 0.18725988268852234, 0.2073352187871933, 0.19544723629951477, 0.17330394685268402, 0.1567295640707016, 0.14332014322280884, 0.13876359164714813, 0.12586712837219238, 0.1467042863368988, 0.13158081471920013, 0.1349601149559021, 0.15462446212768555, 0.12400644272565842, 0.1419723778963089, 0.11914635449647903, 0.14810961484909058, 0.13234975934028625, 0.15040037035942078, 0.1654811054468155, 0.11610691249370575, 0.12691742181777954, 0.10536296665668488, 0.10727927833795547, 0.1295400857925415, 0.1138572171330452, 0.10558487474918365, 0.12142105400562286, 0.10974738746881485, 0.11489836126565933, 0.08781234174966812, 0.07852049916982651, 0.10497032105922699, 0.11077504605054855, 0.0923943817615509, 0.08780794590711594, 0.09505126625299454, 0.12130220979452133, 0.14065302908420563, 0.09433673322200775, 0.0963716059923172, 0.12115404009819031, 0.09560191631317139, 0.10406333208084106, 0.09078630805015564, 0.09948452562093735, 0.09371756762266159, 0.07245207577943802, 0.08524104952812195, 0.0920180231332779, 0.07738154381513596, 0.08101861923933029, 0.10208950936794281, 0.07638315856456757, 0.06712508946657181, 0.09161790460348129, 0.07828449457883835, 0.0807618498802185, 0.0749327540397644, 0.07639408856630325, 0.078952856361866, 0.12876927852630615, 0.10895159840583801, 0.09679287672042847, 0.0996207743883133, 0.21409592032432556, 0.15670616924762726, 0.10681255906820297, 0.08925854414701462, 0.08981207758188248, 0.10132603347301483, 0.0973057821393013, 0.10417699813842773, 0.08287672698497772, 0.05260798707604408, 0.06804896891117096, 0.07852395623922348, 0.07199469208717346, 0.04169073328375816, 0.034399423748254776, 0.03126557916402817, 0.04407315328717232, 0.043810538947582245, 0.06519555300474167, 0.06959521025419235, 0.05463096871972084, 0.06418135017156601, 0.0477469339966774, 0.045268457382917404, 0.05274325609207153, 0.05041789636015892, 0.05510757863521576, 0.04167882725596428, 0.039914291352033615, 0.0536552257835865, 0.05247065797448158, 0.04069327563047409, 0.05036415532231331, 0.03960718214511871, 0.05041239410638809, 0.057140953838825226, 0.0830952525138855, 0.18529853224754333, 0.14972832798957825, 0.17694027721881866, 0.22878876328468323, 0.13082699477672577, 0.14703430235385895, 0.0967257097363472, 0.0762542337179184, 0.08059246093034744]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history2.history[\"loss\"])\n",
    "plot_learning_curves(np.sqrt(history2.history[\"loss\"]), np.sqrt(history2.history[\"val_loss\"]))\n",
    "plt.ylim(0,2)\n",
    "plt.show()\n",
    "#plt.savefig(\"deepfoodsecurity.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 10ms/step - loss: 2.0890 - val_loss: 1.5904\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0725 - val_loss: 1.5799\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0606 - val_loss: 1.5701\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0483 - val_loss: 1.5619\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0392 - val_loss: 1.5538\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0274 - val_loss: 1.5476\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0192 - val_loss: 1.5388\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0083 - val_loss: 1.5335\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9991 - val_loss: 1.5283\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9905 - val_loss: 1.5223\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9806 - val_loss: 1.5203\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9722 - val_loss: 1.5146\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9625 - val_loss: 1.5112\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9544 - val_loss: 1.5074\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9460 - val_loss: 1.5038\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9382 - val_loss: 1.5023\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9300 - val_loss: 1.4991\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9218 - val_loss: 1.4945\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9126 - val_loss: 1.4918\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9047 - val_loss: 1.4901\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8978 - val_loss: 1.4857\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8886 - val_loss: 1.4841\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8802 - val_loss: 1.4807\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8714 - val_loss: 1.4775\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8626 - val_loss: 1.4748\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8541 - val_loss: 1.4712\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8448 - val_loss: 1.4683\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8362 - val_loss: 1.4659\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8265 - val_loss: 1.4623\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8168 - val_loss: 1.4602\n",
      "Epoch 31/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8068 - val_loss: 1.4556\n",
      "Epoch 32/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7969 - val_loss: 1.4536\n",
      "Epoch 33/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7843 - val_loss: 1.4500\n",
      "Epoch 34/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7741 - val_loss: 1.4469\n",
      "Epoch 35/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7632 - val_loss: 1.4442\n",
      "Epoch 36/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7516 - val_loss: 1.4410\n",
      "Epoch 37/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7390 - val_loss: 1.4387\n",
      "Epoch 38/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7282 - val_loss: 1.4354\n",
      "Epoch 39/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7164 - val_loss: 1.4326\n",
      "Epoch 40/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7025 - val_loss: 1.4297\n",
      "Epoch 41/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6898 - val_loss: 1.4263\n",
      "Epoch 42/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6755 - val_loss: 1.4244\n",
      "Epoch 43/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6636 - val_loss: 1.4217\n",
      "Epoch 44/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6492 - val_loss: 1.4192\n",
      "Epoch 45/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6375 - val_loss: 1.4164\n",
      "Epoch 46/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6219 - val_loss: 1.4125\n",
      "Epoch 47/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6064 - val_loss: 1.4094\n",
      "Epoch 48/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5929 - val_loss: 1.4064\n",
      "Epoch 49/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5799 - val_loss: 1.4057\n",
      "Epoch 50/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5611 - val_loss: 1.4010\n",
      "Epoch 51/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5459 - val_loss: 1.3967\n",
      "Epoch 52/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5348 - val_loss: 1.3966\n",
      "Epoch 53/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5186 - val_loss: 1.3919\n",
      "Epoch 54/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4966 - val_loss: 1.3874\n",
      "Epoch 55/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4817 - val_loss: 1.3851\n",
      "Epoch 56/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4670 - val_loss: 1.3849\n",
      "Epoch 57/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4480 - val_loss: 1.3814\n",
      "Epoch 58/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4326 - val_loss: 1.3803\n",
      "Epoch 59/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4155 - val_loss: 1.3786\n",
      "Epoch 60/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4026 - val_loss: 1.3775\n",
      "Epoch 61/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3890 - val_loss: 1.3761\n",
      "Epoch 62/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3711 - val_loss: 1.3757\n",
      "Epoch 63/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3525 - val_loss: 1.3743\n",
      "Epoch 64/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3368 - val_loss: 1.3754\n",
      "Epoch 65/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3235 - val_loss: 1.3757\n",
      "Epoch 66/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3075 - val_loss: 1.3787\n",
      "Epoch 67/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2914 - val_loss: 1.3769\n",
      "Epoch 68/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2808 - val_loss: 1.3783\n",
      "Epoch 69/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2625 - val_loss: 1.3816\n",
      "Epoch 70/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2458 - val_loss: 1.3782\n",
      "Epoch 71/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2334 - val_loss: 1.3841\n",
      "Epoch 72/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2213 - val_loss: 1.3826\n",
      "Epoch 73/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2038 - val_loss: 1.3883\n",
      "8/8 [==============================] - 0s 852us/step - loss: 1.7725\n",
      "[CV] END .....learning_rate=0.0001, n_hidden=6, n_neurons=34; total time=   3.8s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 2.2680 - val_loss: 1.6771\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.2313 - val_loss: 1.6444\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.2034 - val_loss: 1.6218\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.1836 - val_loss: 1.6032\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.1678 - val_loss: 1.5874\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.1543 - val_loss: 1.5733\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.1401 - val_loss: 1.5628\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.1279 - val_loss: 1.5531\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.1167 - val_loss: 1.5432\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.1051 - val_loss: 1.5344\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0926 - val_loss: 1.5263\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0818 - val_loss: 1.5172\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0684 - val_loss: 1.5126\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0559 - val_loss: 1.5040\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0411 - val_loss: 1.4971\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0267 - val_loss: 1.4914\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0125 - val_loss: 1.4848\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9974 - val_loss: 1.4780\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9805 - val_loss: 1.4737\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9660 - val_loss: 1.4690\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9514 - val_loss: 1.4617\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9306 - val_loss: 1.4559\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9132 - val_loss: 1.4503\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8968 - val_loss: 1.4437\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8742 - val_loss: 1.4378\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8558 - val_loss: 1.4321\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8316 - val_loss: 1.4259\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8125 - val_loss: 1.4206\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7905 - val_loss: 1.4146\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7710 - val_loss: 1.4074\n",
      "Epoch 31/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7483 - val_loss: 1.4066\n",
      "Epoch 32/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7240 - val_loss: 1.3984\n",
      "Epoch 33/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7043 - val_loss: 1.3939\n",
      "Epoch 34/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6782 - val_loss: 1.3889\n",
      "Epoch 35/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6580 - val_loss: 1.3854\n",
      "Epoch 36/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6327 - val_loss: 1.3829\n",
      "Epoch 37/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6080 - val_loss: 1.3771\n",
      "Epoch 38/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5860 - val_loss: 1.3718\n",
      "Epoch 39/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5607 - val_loss: 1.3703\n",
      "Epoch 40/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5355 - val_loss: 1.3657\n",
      "Epoch 41/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5196 - val_loss: 1.3677\n",
      "Epoch 42/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4866 - val_loss: 1.3612\n",
      "Epoch 43/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4677 - val_loss: 1.3621\n",
      "Epoch 44/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4451 - val_loss: 1.3539\n",
      "Epoch 45/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4217 - val_loss: 1.3585\n",
      "Epoch 46/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3994 - val_loss: 1.3524\n",
      "Epoch 47/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3817 - val_loss: 1.3518\n",
      "Epoch 48/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3554 - val_loss: 1.3564\n",
      "Epoch 49/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3364 - val_loss: 1.3499\n",
      "Epoch 50/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3153 - val_loss: 1.3484\n",
      "Epoch 51/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2970 - val_loss: 1.3537\n",
      "Epoch 52/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2775 - val_loss: 1.3529\n",
      "Epoch 53/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2570 - val_loss: 1.3501\n",
      "Epoch 54/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2351 - val_loss: 1.3526\n",
      "Epoch 55/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2170 - val_loss: 1.3522\n",
      "Epoch 56/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2037 - val_loss: 1.3593\n",
      "Epoch 57/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1799 - val_loss: 1.3554\n",
      "Epoch 58/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1656 - val_loss: 1.3531\n",
      "Epoch 59/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1486 - val_loss: 1.3593\n",
      "Epoch 60/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1280 - val_loss: 1.3618\n",
      "8/8 [==============================] - 0s 780us/step - loss: 1.6260\n",
      "[CV] END .....learning_rate=0.0001, n_hidden=6, n_neurons=34; total time=   3.3s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 1.9489 - val_loss: 1.5527\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9338 - val_loss: 1.5526\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9225 - val_loss: 1.5520\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9144 - val_loss: 1.5527\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9063 - val_loss: 1.5514\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8984 - val_loss: 1.5503\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8915 - val_loss: 1.5483\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8844 - val_loss: 1.5479\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8768 - val_loss: 1.5452\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8696 - val_loss: 1.5405\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8607 - val_loss: 1.5367\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8516 - val_loss: 1.5349\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8437 - val_loss: 1.5325\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8335 - val_loss: 1.5273\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8247 - val_loss: 1.5233\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8140 - val_loss: 1.5211\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8038 - val_loss: 1.5199\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7930 - val_loss: 1.5165\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7805 - val_loss: 1.5134\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7705 - val_loss: 1.5136\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7571 - val_loss: 1.5070\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7441 - val_loss: 1.5019\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7289 - val_loss: 1.5037\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7155 - val_loss: 1.4975\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6989 - val_loss: 1.4931\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6852 - val_loss: 1.4935\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.6667 - val_loss: 1.4858\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6515 - val_loss: 1.4844\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6333 - val_loss: 1.4799\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6174 - val_loss: 1.4810\n",
      "Epoch 31/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5970 - val_loss: 1.4746\n",
      "Epoch 32/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5781 - val_loss: 1.4705\n",
      "Epoch 33/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5630 - val_loss: 1.4726\n",
      "Epoch 34/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5443 - val_loss: 1.4619\n",
      "Epoch 35/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5251 - val_loss: 1.4676\n",
      "Epoch 36/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5045 - val_loss: 1.4657\n",
      "Epoch 37/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4843 - val_loss: 1.4610\n",
      "Epoch 38/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4665 - val_loss: 1.4606\n",
      "Epoch 39/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4461 - val_loss: 1.4584\n",
      "Epoch 40/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4311 - val_loss: 1.4662\n",
      "Epoch 41/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4230 - val_loss: 1.4534\n",
      "Epoch 42/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3889 - val_loss: 1.4602\n",
      "Epoch 43/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3706 - val_loss: 1.4526\n",
      "Epoch 44/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3505 - val_loss: 1.4477\n",
      "Epoch 45/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3338 - val_loss: 1.4524\n",
      "Epoch 46/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3131 - val_loss: 1.4476\n",
      "Epoch 47/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2972 - val_loss: 1.4464\n",
      "Epoch 48/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2740 - val_loss: 1.4441\n",
      "Epoch 49/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2559 - val_loss: 1.4416\n",
      "Epoch 50/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2387 - val_loss: 1.4454\n",
      "Epoch 51/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2247 - val_loss: 1.4502\n",
      "Epoch 52/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2032 - val_loss: 1.4373\n",
      "Epoch 53/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1925 - val_loss: 1.4454\n",
      "Epoch 54/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1704 - val_loss: 1.4332\n",
      "Epoch 55/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1547 - val_loss: 1.4383\n",
      "Epoch 56/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1403 - val_loss: 1.4336\n",
      "Epoch 57/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1281 - val_loss: 1.4401\n",
      "Epoch 58/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1076 - val_loss: 1.4303\n",
      "Epoch 59/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0959 - val_loss: 1.4376\n",
      "Epoch 60/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0806 - val_loss: 1.4357\n",
      "Epoch 61/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0667 - val_loss: 1.4339\n",
      "Epoch 62/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0519 - val_loss: 1.4363\n",
      "Epoch 63/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0414 - val_loss: 1.4343\n",
      "Epoch 64/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0254 - val_loss: 1.4339\n",
      "Epoch 65/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0125 - val_loss: 1.4358\n",
      "Epoch 66/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9990 - val_loss: 1.4345\n",
      "Epoch 67/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9878 - val_loss: 1.4346\n",
      "Epoch 68/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9782 - val_loss: 1.4418\n",
      "8/8 [==============================] - 0s 850us/step - loss: 1.6918\n",
      "[CV] END .....learning_rate=0.0001, n_hidden=6, n_neurons=34; total time=   3.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 8ms/step - loss: 2.1131 - val_loss: 1.4704\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8133 - val_loss: 1.3946\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6279 - val_loss: 1.3587\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.4784 - val_loss: 1.3628\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3845 - val_loss: 1.3306\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2006 - val_loss: 1.3327\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1309 - val_loss: 1.3531\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0337 - val_loss: 1.3122\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9406 - val_loss: 1.3245\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8560 - val_loss: 1.3344\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.7777 - val_loss: 1.3230\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7375 - val_loss: 1.3658\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6984 - val_loss: 1.3838\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6404 - val_loss: 1.4063\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5936 - val_loss: 1.3868\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5784 - val_loss: 1.3864\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5291 - val_loss: 1.4342\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5306 - val_loss: 1.4050\n",
      "8/8 [==============================] - 0s 830us/step - loss: 1.6342\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=2, n_neurons=74; total time=   1.3s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 2.0662 - val_loss: 1.4496\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7313 - val_loss: 1.3768\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4791 - val_loss: 1.3017\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3440 - val_loss: 1.2989\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2909 - val_loss: 1.2830\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1942 - val_loss: 1.3280\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0964 - val_loss: 1.2570\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9931 - val_loss: 1.3257\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.9097 - val_loss: 1.2451\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9001 - val_loss: 1.3748\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8380 - val_loss: 1.2830\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7874 - val_loss: 1.2274\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7301 - val_loss: 1.3724\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6862 - val_loss: 1.2583\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6130 - val_loss: 1.2356\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5977 - val_loss: 1.2758\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6088 - val_loss: 1.2826\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5221 - val_loss: 1.2862\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4802 - val_loss: 1.3315\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4592 - val_loss: 1.3483\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.5397 - val_loss: 1.3028\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.4757 - val_loss: 1.3022\n",
      "8/8 [==============================] - 0s 848us/step - loss: 1.4026\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=2, n_neurons=74; total time=   1.3s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.9143 - val_loss: 1.4673\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6062 - val_loss: 1.4694\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4116 - val_loss: 1.3987\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2462 - val_loss: 1.3590\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1296 - val_loss: 1.3661\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0111 - val_loss: 1.4003\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9978 - val_loss: 1.4500\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8664 - val_loss: 1.3850\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8256 - val_loss: 1.3679\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7920 - val_loss: 1.4503\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7047 - val_loss: 1.3853\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7148 - val_loss: 1.4059\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7008 - val_loss: 1.3886\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6668 - val_loss: 1.3957\n",
      "8/8 [==============================] - 0s 780us/step - loss: 1.5804\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=2, n_neurons=74; total time=   1.0s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 8ms/step - loss: 2.0839 - val_loss: 1.4804\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8753 - val_loss: 1.4301\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7372 - val_loss: 1.3931\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5999 - val_loss: 1.3824\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4949 - val_loss: 1.3308\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3313 - val_loss: 1.3627\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2237 - val_loss: 1.3309\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0996 - val_loss: 1.2925\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9675 - val_loss: 1.3183\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8691 - val_loss: 1.3223\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7934 - val_loss: 1.3377\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7354 - val_loss: 1.3474\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6645 - val_loss: 1.3980\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6069 - val_loss: 1.4243\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5478 - val_loss: 1.3768\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5037 - val_loss: 1.3805\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4668 - val_loss: 1.4181\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4389 - val_loss: 1.4221\n",
      "8/8 [==============================] - 0s 863us/step - loss: 1.4485\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=3, n_neurons=74; total time=   1.3s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 8ms/step - loss: 2.0865 - val_loss: 1.4856\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8697 - val_loss: 1.4487\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6761 - val_loss: 1.4243\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5384 - val_loss: 1.4207\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4447 - val_loss: 1.3778\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3220 - val_loss: 1.4155\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2095 - val_loss: 1.3404\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0824 - val_loss: 1.3728\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0088 - val_loss: 1.3272\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9376 - val_loss: 1.4094\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8725 - val_loss: 1.3119\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8402 - val_loss: 1.2834\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7519 - val_loss: 1.3417\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6885 - val_loss: 1.3004\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6310 - val_loss: 1.3118\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5734 - val_loss: 1.3313\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5468 - val_loss: 1.2992\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5029 - val_loss: 1.3717\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4740 - val_loss: 1.3501\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4359 - val_loss: 1.3619\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4581 - val_loss: 1.3741\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4174 - val_loss: 1.3619\n",
      "8/8 [==============================] - 0s 921us/step - loss: 1.4254\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=3, n_neurons=74; total time=   1.4s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 8ms/step - loss: 1.9579 - val_loss: 1.5091\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7373 - val_loss: 1.4491\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5977 - val_loss: 1.4108\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4731 - val_loss: 1.3707\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3484 - val_loss: 1.3324\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2344 - val_loss: 1.3136\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1711 - val_loss: 1.2991\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0317 - val_loss: 1.2540\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9596 - val_loss: 1.2048\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8823 - val_loss: 1.2945\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7711 - val_loss: 1.2509\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7297 - val_loss: 1.2071\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6887 - val_loss: 1.2607\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6429 - val_loss: 1.2348\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6179 - val_loss: 1.3088\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5976 - val_loss: 1.2786\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5142 - val_loss: 1.2398\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4794 - val_loss: 1.3192\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4314 - val_loss: 1.2741\n",
      "8/8 [==============================] - 0s 853us/step - loss: 1.5353\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=3, n_neurons=74; total time=   1.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 2.0643 - val_loss: 1.4829\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9030 - val_loss: 1.4273\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7746 - val_loss: 1.3794\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5933 - val_loss: 1.3955\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4704 - val_loss: 1.4076\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2768 - val_loss: 1.3870\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1253 - val_loss: 1.3004\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9714 - val_loss: 1.3685\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8391 - val_loss: 1.4083\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7650 - val_loss: 1.3700\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6610 - val_loss: 1.4314\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6045 - val_loss: 1.5270\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5781 - val_loss: 1.6015\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5027 - val_loss: 1.4136\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4386 - val_loss: 1.4867\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3839 - val_loss: 1.3584\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3960 - val_loss: 1.4322\n",
      "8/8 [==============================] - 0s 850us/step - loss: 1.2856\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=5, n_neurons=63; total time=   1.4s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 2.1221 - val_loss: 1.4871\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9445 - val_loss: 1.4287\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7413 - val_loss: 1.3972\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5099 - val_loss: 1.3801\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3925 - val_loss: 1.4985\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2623 - val_loss: 1.3412\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0971 - val_loss: 1.4783\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9407 - val_loss: 1.3662\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8214 - val_loss: 1.3305\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6990 - val_loss: 1.4700\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6280 - val_loss: 1.4112\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6268 - val_loss: 1.4845\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5295 - val_loss: 1.4323\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5408 - val_loss: 1.5795\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5070 - val_loss: 1.4074\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3972 - val_loss: 1.4301\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4308 - val_loss: 1.4802\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4328 - val_loss: 1.5172\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3700 - val_loss: 1.4890\n",
      "8/8 [==============================] - 0s 783us/step - loss: 1.3438\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=5, n_neurons=63; total time=   1.5s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 1.9184 - val_loss: 1.4980\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7722 - val_loss: 1.4220\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6139 - val_loss: 1.3904\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4257 - val_loss: 1.2873\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2508 - val_loss: 1.2701\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0578 - val_loss: 1.2107\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9848 - val_loss: 1.2395\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8644 - val_loss: 1.2193\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7816 - val_loss: 1.2232\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6783 - val_loss: 1.3395\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6415 - val_loss: 1.2225\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5874 - val_loss: 1.3106\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5145 - val_loss: 1.1742\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4316 - val_loss: 1.2478\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4220 - val_loss: 1.2583\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4284 - val_loss: 1.2893\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3737 - val_loss: 1.2356\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3187 - val_loss: 1.2049\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3208 - val_loss: 1.2586\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3109 - val_loss: 1.1622\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2442 - val_loss: 1.2145\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2388 - val_loss: 1.2061\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1859 - val_loss: 1.2158\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 1.2579\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1801 - val_loss: 1.2038\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1957 - val_loss: 1.1898\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2311 - val_loss: 1.1537\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2842 - val_loss: 1.1165\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1778 - val_loss: 1.2346\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1720 - val_loss: 1.2032\n",
      "Epoch 31/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1526 - val_loss: 1.1805\n",
      "Epoch 32/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1385 - val_loss: 1.2125\n",
      "Epoch 33/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1429 - val_loss: 1.2695\n",
      "Epoch 34/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1344 - val_loss: 1.2161\n",
      "Epoch 35/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1416 - val_loss: 1.1543\n",
      "Epoch 36/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1286 - val_loss: 1.2132\n",
      "Epoch 37/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1054 - val_loss: 1.2149\n",
      "Epoch 38/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1022 - val_loss: 1.1911\n",
      "8/8 [==============================] - 0s 864us/step - loss: 1.4329\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=5, n_neurons=63; total time=   2.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 8ms/step - loss: 2.3482 - val_loss: 1.5780\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0137 - val_loss: 1.4749\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9424 - val_loss: 1.4478\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8822 - val_loss: 1.4395\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8355 - val_loss: 1.4201\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7745 - val_loss: 1.4027\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7334 - val_loss: 1.3772\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6751 - val_loss: 1.3599\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6340 - val_loss: 1.3502\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5904 - val_loss: 1.3394\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5313 - val_loss: 1.3206\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4922 - val_loss: 1.3097\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4321 - val_loss: 1.3009\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3977 - val_loss: 1.2967\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3401 - val_loss: 1.2917\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2983 - val_loss: 1.2847\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2407 - val_loss: 1.2790\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1964 - val_loss: 1.2751\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1502 - val_loss: 1.2632\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1057 - val_loss: 1.2795\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0666 - val_loss: 1.2750\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0309 - val_loss: 1.2636\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9922 - val_loss: 1.2799\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9426 - val_loss: 1.2714\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9019 - val_loss: 1.2709\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8651 - val_loss: 1.2811\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8365 - val_loss: 1.2877\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8078 - val_loss: 1.3259\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7824 - val_loss: 1.3100\n",
      "8/8 [==============================] - 0s 854us/step - loss: 1.4758\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=3, n_neurons=20; total time=   1.7s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 2.1565 - val_loss: 1.5579\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0657 - val_loss: 1.5282\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9966 - val_loss: 1.5073\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9411 - val_loss: 1.4956\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8924 - val_loss: 1.4895\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1.8364 - val_loss: 1.4854\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7866 - val_loss: 1.4769\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7382 - val_loss: 1.4696\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6883 - val_loss: 1.4572\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6457 - val_loss: 1.4544\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5839 - val_loss: 1.4453\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5366 - val_loss: 1.4280\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4788 - val_loss: 1.4197\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4212 - val_loss: 1.4211\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3577 - val_loss: 1.3969\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3070 - val_loss: 1.3891\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2610 - val_loss: 1.4052\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2021 - val_loss: 1.3868\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1722 - val_loss: 1.3577\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1272 - val_loss: 1.3597\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0832 - val_loss: 1.3656\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0273 - val_loss: 1.3342\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9948 - val_loss: 1.3440\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9527 - val_loss: 1.3346\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9136 - val_loss: 1.3231\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9094 - val_loss: 1.3229\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8625 - val_loss: 1.3357\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8374 - val_loss: 1.3342\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8054 - val_loss: 1.3255\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8022 - val_loss: 1.3232\n",
      "Epoch 31/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7639 - val_loss: 1.3372\n",
      "Epoch 32/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7404 - val_loss: 1.3324\n",
      "Epoch 33/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7139 - val_loss: 1.3695\n",
      "Epoch 34/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6990 - val_loss: 1.3352\n",
      "Epoch 35/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6687 - val_loss: 1.3889\n",
      "Epoch 36/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6675 - val_loss: 1.3574\n",
      "8/8 [==============================] - 0s 780us/step - loss: 1.5540\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=3, n_neurons=20; total time=   2.1s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 8ms/step - loss: 1.9707 - val_loss: 1.6064\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8798 - val_loss: 1.5744\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8169 - val_loss: 1.5473\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7674 - val_loss: 1.5307\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7253 - val_loss: 1.5178\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6849 - val_loss: 1.5026\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6578 - val_loss: 1.4894\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6037 - val_loss: 1.4809\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5585 - val_loss: 1.4743\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5188 - val_loss: 1.4597\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4609 - val_loss: 1.4454\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4129 - val_loss: 1.4323\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3655 - val_loss: 1.4281\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3072 - val_loss: 1.4223\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2638 - val_loss: 1.4057\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2075 - val_loss: 1.4069\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1636 - val_loss: 1.4076\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1174 - val_loss: 1.4033\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0702 - val_loss: 1.3956\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0507 - val_loss: 1.3868\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0026 - val_loss: 1.3909\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9636 - val_loss: 1.3745\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9255 - val_loss: 1.3791\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9004 - val_loss: 1.3834\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8773 - val_loss: 1.3776\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8523 - val_loss: 1.3800\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8525 - val_loss: 1.3968\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8025 - val_loss: 1.3620\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7657 - val_loss: 1.3688\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7306 - val_loss: 1.3727\n",
      "Epoch 31/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7143 - val_loss: 1.3689\n",
      "Epoch 32/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7062 - val_loss: 1.3782\n",
      "Epoch 33/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6989 - val_loss: 1.3624\n",
      "Epoch 34/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6781 - val_loss: 1.3769\n",
      "Epoch 35/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6659 - val_loss: 1.3845\n",
      "Epoch 36/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6504 - val_loss: 1.3817\n",
      "Epoch 37/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6544 - val_loss: 1.3545\n",
      "Epoch 38/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6181 - val_loss: 1.3681\n",
      "Epoch 39/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5882 - val_loss: 1.3425\n",
      "Epoch 40/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5698 - val_loss: 1.3452\n",
      "Epoch 41/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5637 - val_loss: 1.3620\n",
      "Epoch 42/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5551 - val_loss: 1.3793\n",
      "Epoch 43/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5438 - val_loss: 1.3548\n",
      "Epoch 44/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5347 - val_loss: 1.3693\n",
      "Epoch 45/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5394 - val_loss: 1.3663\n",
      "Epoch 46/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5149 - val_loss: 1.3626\n",
      "Epoch 47/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5438 - val_loss: 1.3820\n",
      "Epoch 48/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4956 - val_loss: 1.3621\n",
      "Epoch 49/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4759 - val_loss: 1.3627\n",
      "8/8 [==============================] - 0s 709us/step - loss: 1.9016\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=3, n_neurons=20; total time=   2.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 2.0124 - val_loss: 1.4816\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7852 - val_loss: 1.4339\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5621 - val_loss: 1.4033\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5010 - val_loss: 1.3366\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3298 - val_loss: 1.4252\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0190 - val_loss: 1.4895\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9832 - val_loss: 1.3380\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7423 - val_loss: 1.4231\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6625 - val_loss: 1.5207\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5969 - val_loss: 1.4113\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6454 - val_loss: 1.5317\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6894 - val_loss: 1.7745\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5769 - val_loss: 1.5488\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4350 - val_loss: 1.5150\n",
      "8/8 [==============================] - 0s 881us/step - loss: 1.3294\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=6, n_neurons=86; total time=   1.5s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 10ms/step - loss: 2.1776 - val_loss: 1.4546\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9737 - val_loss: 1.4448\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7522 - val_loss: 1.2845\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4777 - val_loss: 1.3703\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3910 - val_loss: 1.3017\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1689 - val_loss: 1.3305\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9403 - val_loss: 1.2278\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8149 - val_loss: 1.2283\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6387 - val_loss: 1.3942\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5726 - val_loss: 1.2819\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6276 - val_loss: 1.3167\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5836 - val_loss: 1.1872\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5656 - val_loss: 1.3774\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5015 - val_loss: 1.3079\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4518 - val_loss: 1.1963\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3799 - val_loss: 1.3139\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3384 - val_loss: 1.1953\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3746 - val_loss: 1.2856\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4544 - val_loss: 1.4242\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3075 - val_loss: 1.2225\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3676 - val_loss: 1.1792\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3328 - val_loss: 1.2507\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3487 - val_loss: 1.2590\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2852 - val_loss: 1.3604\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2214 - val_loss: 1.2140\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1780 - val_loss: 1.1723\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1685 - val_loss: 1.2920\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1873 - val_loss: 1.1986\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1555 - val_loss: 1.3023\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1746 - val_loss: 1.2411\n",
      "Epoch 31/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1676 - val_loss: 1.2837\n",
      "Epoch 32/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1713 - val_loss: 1.1543\n",
      "Epoch 33/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1310 - val_loss: 1.2056\n",
      "Epoch 34/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1207 - val_loss: 1.2687\n",
      "Epoch 35/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1009 - val_loss: 1.2205\n",
      "Epoch 36/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0996 - val_loss: 1.1535\n",
      "Epoch 37/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2144 - val_loss: 1.2405\n",
      "Epoch 38/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1416 - val_loss: 1.2253\n",
      "Epoch 39/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1275 - val_loss: 1.2435\n",
      "Epoch 40/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1351 - val_loss: 1.2340\n",
      "Epoch 41/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0992 - val_loss: 1.1370\n",
      "Epoch 42/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1148 - val_loss: 1.1654\n",
      "Epoch 43/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0861 - val_loss: 1.2121\n",
      "Epoch 44/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0649 - val_loss: 1.2076\n",
      "Epoch 45/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0971 - val_loss: 1.1832\n",
      "Epoch 46/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0659 - val_loss: 1.1566\n",
      "Epoch 47/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0541 - val_loss: 1.2134\n",
      "Epoch 48/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0491 - val_loss: 1.2617\n",
      "Epoch 49/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0367 - val_loss: 1.1614\n",
      "Epoch 50/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0379 - val_loss: 1.2170\n",
      "Epoch 51/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0401 - val_loss: 1.2848\n",
      "8/8 [==============================] - 0s 783us/step - loss: 1.4413\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=6, n_neurons=86; total time=   3.0s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 10ms/step - loss: 1.9437 - val_loss: 1.5017\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7787 - val_loss: 1.3812\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.5571 - val_loss: 1.3531\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3251 - val_loss: 1.2777\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1874 - val_loss: 1.5930\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1046 - val_loss: 1.4722\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0062 - val_loss: 1.1910\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0898 - val_loss: 1.4087\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7484 - val_loss: 1.2823\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6657 - val_loss: 1.3590\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6113 - val_loss: 1.2643\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5411 - val_loss: 1.3841\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4947 - val_loss: 1.1854\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4581 - val_loss: 1.2484\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3429 - val_loss: 1.3940\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5300 - val_loss: 1.6000\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5171 - val_loss: 1.3197\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3538 - val_loss: 1.2555\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3271 - val_loss: 1.3150\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2502 - val_loss: 1.3578\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2425 - val_loss: 1.1979\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2429 - val_loss: 1.2624\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2093 - val_loss: 1.3399\n",
      "8/8 [==============================] - 0s 859us/step - loss: 1.5393\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=6, n_neurons=86; total time=   1.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 2.0886 - val_loss: 1.4935\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7757 - val_loss: 1.4311\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6283 - val_loss: 1.3943\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4974 - val_loss: 1.3814\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4184 - val_loss: 1.3692\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2967 - val_loss: 1.3566\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2268 - val_loss: 1.3479\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1304 - val_loss: 1.3624\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0634 - val_loss: 1.3656\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9959 - val_loss: 1.3654\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9347 - val_loss: 1.3554\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8917 - val_loss: 1.3817\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8525 - val_loss: 1.4144\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8110 - val_loss: 1.3829\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7455 - val_loss: 1.4065\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7475 - val_loss: 1.3993\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6826 - val_loss: 1.3966\n",
      "8/8 [==============================] - 0s 992us/step - loss: 1.5389\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=2, n_neurons=91; total time=   1.1s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 2.1587 - val_loss: 1.4472\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8912 - val_loss: 1.4374\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6787 - val_loss: 1.3755\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5358 - val_loss: 1.3853\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4502 - val_loss: 1.3528\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3445 - val_loss: 1.3745\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2387 - val_loss: 1.3441\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1544 - val_loss: 1.3806\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1337 - val_loss: 1.4140\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0778 - val_loss: 1.3738\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9694 - val_loss: 1.3084\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9290 - val_loss: 1.2836\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8613 - val_loss: 1.3558\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8176 - val_loss: 1.2666\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7610 - val_loss: 1.2925\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7321 - val_loss: 1.3112\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7211 - val_loss: 1.3032\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6503 - val_loss: 1.2761\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6250 - val_loss: 1.3550\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6084 - val_loss: 1.3106\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6575 - val_loss: 1.3376\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6002 - val_loss: 1.2979\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5402 - val_loss: 1.4050\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5011 - val_loss: 1.2916\n",
      "8/8 [==============================] - 0s 779us/step - loss: 1.2684\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=2, n_neurons=91; total time=   1.4s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 2.0430 - val_loss: 1.5509\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7477 - val_loss: 1.4472\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5978 - val_loss: 1.4273\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4900 - val_loss: 1.4013\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4013 - val_loss: 1.3722\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3012 - val_loss: 1.3575\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2523 - val_loss: 1.3509\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1560 - val_loss: 1.3336\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0885 - val_loss: 1.2976\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0301 - val_loss: 1.3371\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9549 - val_loss: 1.3209\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8992 - val_loss: 1.2677\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8575 - val_loss: 1.3274\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8070 - val_loss: 1.3066\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7805 - val_loss: 1.3187\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7086 - val_loss: 1.3154\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6673 - val_loss: 1.3101\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6279 - val_loss: 1.3452\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5902 - val_loss: 1.3543\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6002 - val_loss: 1.3323\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5637 - val_loss: 1.3763\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5321 - val_loss: 1.3180\n",
      "8/8 [==============================] - 0s 850us/step - loss: 1.5641\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=2, n_neurons=91; total time=   1.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 2.0995 - val_loss: 1.5485\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0714 - val_loss: 1.5371\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0481 - val_loss: 1.5274\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0285 - val_loss: 1.5198\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0132 - val_loss: 1.5125\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9950 - val_loss: 1.5056\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9815 - val_loss: 1.4974\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9667 - val_loss: 1.4910\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9525 - val_loss: 1.4855\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9404 - val_loss: 1.4787\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9262 - val_loss: 1.4735\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9142 - val_loss: 1.4672\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9001 - val_loss: 1.4618\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8874 - val_loss: 1.4563\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8738 - val_loss: 1.4516\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8619 - val_loss: 1.4467\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8485 - val_loss: 1.4419\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8343 - val_loss: 1.4359\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8207 - val_loss: 1.4321\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8074 - val_loss: 1.4276\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7966 - val_loss: 1.4223\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7815 - val_loss: 1.4191\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7692 - val_loss: 1.4135\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7559 - val_loss: 1.4090\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7426 - val_loss: 1.4043\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7290 - val_loss: 1.3997\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7146 - val_loss: 1.3953\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7025 - val_loss: 1.3904\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6876 - val_loss: 1.3855\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6732 - val_loss: 1.3809\n",
      "Epoch 31/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6593 - val_loss: 1.3763\n",
      "Epoch 32/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6449 - val_loss: 1.3723\n",
      "Epoch 33/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6293 - val_loss: 1.3687\n",
      "Epoch 34/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6156 - val_loss: 1.3638\n",
      "Epoch 35/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6009 - val_loss: 1.3594\n",
      "Epoch 36/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5877 - val_loss: 1.3576\n",
      "Epoch 37/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5724 - val_loss: 1.3524\n",
      "Epoch 38/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5583 - val_loss: 1.3499\n",
      "Epoch 39/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5454 - val_loss: 1.3454\n",
      "Epoch 40/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5295 - val_loss: 1.3415\n",
      "Epoch 41/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5163 - val_loss: 1.3387\n",
      "Epoch 42/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5012 - val_loss: 1.3360\n",
      "Epoch 43/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4882 - val_loss: 1.3338\n",
      "Epoch 44/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4756 - val_loss: 1.3310\n",
      "Epoch 45/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4621 - val_loss: 1.3281\n",
      "Epoch 46/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4473 - val_loss: 1.3250\n",
      "Epoch 47/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4338 - val_loss: 1.3223\n",
      "Epoch 48/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4225 - val_loss: 1.3201\n",
      "Epoch 49/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4103 - val_loss: 1.3199\n",
      "Epoch 50/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3940 - val_loss: 1.3167\n",
      "Epoch 51/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3829 - val_loss: 1.3149\n",
      "Epoch 52/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3712 - val_loss: 1.3148\n",
      "Epoch 53/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3561 - val_loss: 1.3115\n",
      "Epoch 54/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3405 - val_loss: 1.3103\n",
      "Epoch 55/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3279 - val_loss: 1.3081\n",
      "Epoch 56/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3149 - val_loss: 1.3079\n",
      "Epoch 57/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2989 - val_loss: 1.3061\n",
      "Epoch 58/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2862 - val_loss: 1.3041\n",
      "Epoch 59/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2753 - val_loss: 1.3046\n",
      "Epoch 60/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2615 - val_loss: 1.3042\n",
      "Epoch 61/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2510 - val_loss: 1.3021\n",
      "Epoch 62/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2377 - val_loss: 1.3025\n",
      "Epoch 63/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2240 - val_loss: 1.3004\n",
      "Epoch 64/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2128 - val_loss: 1.3013\n",
      "Epoch 65/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2014 - val_loss: 1.2992\n",
      "Epoch 66/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1873 - val_loss: 1.2983\n",
      "Epoch 67/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1765 - val_loss: 1.2989\n",
      "Epoch 68/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1646 - val_loss: 1.2978\n",
      "Epoch 69/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1527 - val_loss: 1.2971\n",
      "Epoch 70/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1399 - val_loss: 1.2945\n",
      "Epoch 71/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1297 - val_loss: 1.2996\n",
      "Epoch 72/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1180 - val_loss: 1.2968\n",
      "Epoch 73/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1055 - val_loss: 1.2970\n",
      "Epoch 74/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0958 - val_loss: 1.2949\n",
      "Epoch 75/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0831 - val_loss: 1.2965\n",
      "Epoch 76/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0749 - val_loss: 1.2963\n",
      "Epoch 77/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0600 - val_loss: 1.2957\n",
      "Epoch 78/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0511 - val_loss: 1.2988\n",
      "Epoch 79/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0388 - val_loss: 1.2949\n",
      "Epoch 80/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0277 - val_loss: 1.2959\n",
      "8/8 [==============================] - 0s 783us/step - loss: 1.5540\n",
      "[CV] END .....learning_rate=0.0001, n_hidden=4, n_neurons=42; total time=   3.9s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 2.2879 - val_loss: 1.7288\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.2349 - val_loss: 1.6796\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.1952 - val_loss: 1.6446\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.1669 - val_loss: 1.6181\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.1439 - val_loss: 1.5995\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.1264 - val_loss: 1.5827\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.1077 - val_loss: 1.5712\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0915 - val_loss: 1.5616\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0754 - val_loss: 1.5534\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0625 - val_loss: 1.5449\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0471 - val_loss: 1.5389\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0332 - val_loss: 1.5338\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0193 - val_loss: 1.5312\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 2.0054 - val_loss: 1.5254\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9901 - val_loss: 1.5218\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.9759 - val_loss: 1.5190\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9625 - val_loss: 1.5166\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9490 - val_loss: 1.5134\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9349 - val_loss: 1.5100\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9221 - val_loss: 1.5086\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9109 - val_loss: 1.5050\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8955 - val_loss: 1.5019\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8822 - val_loss: 1.4991\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8707 - val_loss: 1.4960\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8554 - val_loss: 1.4936\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8439 - val_loss: 1.4915\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8280 - val_loss: 1.4878\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8143 - val_loss: 1.4851\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7997 - val_loss: 1.4832\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7845 - val_loss: 1.4801\n",
      "Epoch 31/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7684 - val_loss: 1.4780\n",
      "Epoch 32/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7513 - val_loss: 1.4747\n",
      "Epoch 33/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7375 - val_loss: 1.4710\n",
      "Epoch 34/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7187 - val_loss: 1.4679\n",
      "Epoch 35/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7025 - val_loss: 1.4632\n",
      "Epoch 36/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6828 - val_loss: 1.4605\n",
      "Epoch 37/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6624 - val_loss: 1.4561\n",
      "Epoch 38/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6457 - val_loss: 1.4520\n",
      "Epoch 39/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6260 - val_loss: 1.4495\n",
      "Epoch 40/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6080 - val_loss: 1.4434\n",
      "Epoch 41/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5939 - val_loss: 1.4437\n",
      "Epoch 42/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5695 - val_loss: 1.4389\n",
      "Epoch 43/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5532 - val_loss: 1.4370\n",
      "Epoch 44/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5379 - val_loss: 1.4325\n",
      "Epoch 45/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5200 - val_loss: 1.4329\n",
      "Epoch 46/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5043 - val_loss: 1.4298\n",
      "Epoch 47/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4904 - val_loss: 1.4288\n",
      "Epoch 48/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4705 - val_loss: 1.4269\n",
      "Epoch 49/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4561 - val_loss: 1.4245\n",
      "Epoch 50/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4399 - val_loss: 1.4222\n",
      "Epoch 51/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4265 - val_loss: 1.4227\n",
      "Epoch 52/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4116 - val_loss: 1.4215\n",
      "Epoch 53/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3974 - val_loss: 1.4186\n",
      "Epoch 54/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3792 - val_loss: 1.4156\n",
      "Epoch 55/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3683 - val_loss: 1.4141\n",
      "Epoch 56/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3542 - val_loss: 1.4129\n",
      "Epoch 57/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3386 - val_loss: 1.4116\n",
      "Epoch 58/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3270 - val_loss: 1.4056\n",
      "Epoch 59/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3157 - val_loss: 1.4074\n",
      "Epoch 60/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3013 - val_loss: 1.4069\n",
      "Epoch 61/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2889 - val_loss: 1.4044\n",
      "Epoch 62/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2773 - val_loss: 1.4069\n",
      "Epoch 63/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2662 - val_loss: 1.3984\n",
      "Epoch 64/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2549 - val_loss: 1.4034\n",
      "Epoch 65/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2411 - val_loss: 1.3948\n",
      "Epoch 66/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2300 - val_loss: 1.3936\n",
      "Epoch 67/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2247 - val_loss: 1.3970\n",
      "Epoch 68/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2125 - val_loss: 1.3922\n",
      "Epoch 69/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2037 - val_loss: 1.4000\n",
      "Epoch 70/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1850 - val_loss: 1.3898\n",
      "Epoch 71/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1766 - val_loss: 1.3953\n",
      "Epoch 72/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1686 - val_loss: 1.3909\n",
      "Epoch 73/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1577 - val_loss: 1.3876\n",
      "Epoch 74/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1454 - val_loss: 1.3821\n",
      "Epoch 75/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1353 - val_loss: 1.3857\n",
      "Epoch 76/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1257 - val_loss: 1.3864\n",
      "Epoch 77/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1159 - val_loss: 1.3843\n",
      "Epoch 78/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1068 - val_loss: 1.3855\n",
      "Epoch 79/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0942 - val_loss: 1.3783\n",
      "Epoch 80/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0850 - val_loss: 1.3744\n",
      "Epoch 81/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0760 - val_loss: 1.3745\n",
      "Epoch 82/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0669 - val_loss: 1.3736\n",
      "Epoch 83/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0593 - val_loss: 1.3707\n",
      "Epoch 84/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0496 - val_loss: 1.3727\n",
      "Epoch 85/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0384 - val_loss: 1.3747\n",
      "Epoch 86/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0291 - val_loss: 1.3700\n",
      "Epoch 87/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0210 - val_loss: 1.3646\n",
      "Epoch 88/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0108 - val_loss: 1.3706\n",
      "Epoch 89/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0037 - val_loss: 1.3615\n",
      "Epoch 90/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9949 - val_loss: 1.3631\n",
      "Epoch 91/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9836 - val_loss: 1.3637\n",
      "Epoch 92/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9754 - val_loss: 1.3629\n",
      "Epoch 93/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9646 - val_loss: 1.3610\n",
      "Epoch 94/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9572 - val_loss: 1.3584\n",
      "Epoch 95/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9498 - val_loss: 1.3632\n",
      "Epoch 96/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9404 - val_loss: 1.3639\n",
      "Epoch 97/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9334 - val_loss: 1.3586\n",
      "Epoch 98/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9242 - val_loss: 1.3600\n",
      "Epoch 99/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9180 - val_loss: 1.3478\n",
      "Epoch 100/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9093 - val_loss: 1.3605\n",
      "Epoch 101/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9008 - val_loss: 1.3564\n",
      "Epoch 102/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8919 - val_loss: 1.3569\n",
      "Epoch 103/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8873 - val_loss: 1.3624\n",
      "Epoch 104/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8813 - val_loss: 1.3566\n",
      "Epoch 105/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8724 - val_loss: 1.3554\n",
      "Epoch 106/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8635 - val_loss: 1.3545\n",
      "Epoch 107/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8569 - val_loss: 1.3553\n",
      "Epoch 108/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8489 - val_loss: 1.3554\n",
      "Epoch 109/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8431 - val_loss: 1.3557\n",
      "8/8 [==============================] - 0s 937us/step - loss: 1.5455\n",
      "[CV] END .....learning_rate=0.0001, n_hidden=4, n_neurons=42; total time=   5.1s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 1.9417 - val_loss: 1.5550\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9280 - val_loss: 1.5508\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9156 - val_loss: 1.5454\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9052 - val_loss: 1.5417\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8956 - val_loss: 1.5365\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8859 - val_loss: 1.5319\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8777 - val_loss: 1.5281\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8688 - val_loss: 1.5255\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8602 - val_loss: 1.5214\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8531 - val_loss: 1.5164\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8442 - val_loss: 1.5115\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8356 - val_loss: 1.5083\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8281 - val_loss: 1.5053\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8189 - val_loss: 1.4999\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8107 - val_loss: 1.4946\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8016 - val_loss: 1.4904\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7932 - val_loss: 1.4858\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7843 - val_loss: 1.4811\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7736 - val_loss: 1.4773\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7649 - val_loss: 1.4736\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7548 - val_loss: 1.4681\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7453 - val_loss: 1.4618\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7345 - val_loss: 1.4602\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7255 - val_loss: 1.4551\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7154 - val_loss: 1.4502\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7057 - val_loss: 1.4477\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6947 - val_loss: 1.4417\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6843 - val_loss: 1.4376\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6727 - val_loss: 1.4341\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6615 - val_loss: 1.4337\n",
      "Epoch 31/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6487 - val_loss: 1.4306\n",
      "Epoch 32/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6362 - val_loss: 1.4267\n",
      "Epoch 33/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6251 - val_loss: 1.4252\n",
      "Epoch 34/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6130 - val_loss: 1.4177\n",
      "Epoch 35/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6005 - val_loss: 1.4180\n",
      "Epoch 36/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5866 - val_loss: 1.4151\n",
      "Epoch 37/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5731 - val_loss: 1.4118\n",
      "Epoch 38/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5608 - val_loss: 1.4095\n",
      "Epoch 39/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5479 - val_loss: 1.4055\n",
      "Epoch 40/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5345 - val_loss: 1.4078\n",
      "Epoch 41/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5259 - val_loss: 1.4022\n",
      "Epoch 42/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5069 - val_loss: 1.4009\n",
      "Epoch 43/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4938 - val_loss: 1.3982\n",
      "Epoch 44/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4800 - val_loss: 1.3961\n",
      "Epoch 45/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4682 - val_loss: 1.3942\n",
      "Epoch 46/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4540 - val_loss: 1.3902\n",
      "Epoch 47/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4419 - val_loss: 1.3902\n",
      "Epoch 48/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4260 - val_loss: 1.3883\n",
      "Epoch 49/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4126 - val_loss: 1.3864\n",
      "Epoch 50/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4003 - val_loss: 1.3834\n",
      "Epoch 51/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3880 - val_loss: 1.3843\n",
      "Epoch 52/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3715 - val_loss: 1.3799\n",
      "Epoch 53/300\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.3613 - val_loss: 1.3760\n",
      "Epoch 54/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3454 - val_loss: 1.3707\n",
      "Epoch 55/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3334 - val_loss: 1.3684\n",
      "Epoch 56/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3193 - val_loss: 1.3649\n",
      "Epoch 57/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3080 - val_loss: 1.3649\n",
      "Epoch 58/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2907 - val_loss: 1.3578\n",
      "Epoch 59/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2790 - val_loss: 1.3544\n",
      "Epoch 60/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2646 - val_loss: 1.3508\n",
      "Epoch 61/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2497 - val_loss: 1.3472\n",
      "Epoch 62/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2371 - val_loss: 1.3425\n",
      "Epoch 63/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2264 - val_loss: 1.3377\n",
      "Epoch 64/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2097 - val_loss: 1.3347\n",
      "Epoch 65/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1969 - val_loss: 1.3296\n",
      "Epoch 66/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1841 - val_loss: 1.3267\n",
      "Epoch 67/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1703 - val_loss: 1.3211\n",
      "Epoch 68/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1590 - val_loss: 1.3191\n",
      "Epoch 69/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1423 - val_loss: 1.3161\n",
      "Epoch 70/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1304 - val_loss: 1.3109\n",
      "Epoch 71/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1142 - val_loss: 1.3068\n",
      "Epoch 72/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1007 - val_loss: 1.3023\n",
      "Epoch 73/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0875 - val_loss: 1.3004\n",
      "Epoch 74/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0747 - val_loss: 1.3010\n",
      "Epoch 75/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0653 - val_loss: 1.2972\n",
      "Epoch 76/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0491 - val_loss: 1.2972\n",
      "Epoch 77/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0416 - val_loss: 1.3000\n",
      "Epoch 78/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0282 - val_loss: 1.2923\n",
      "Epoch 79/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0150 - val_loss: 1.2927\n",
      "Epoch 80/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0029 - val_loss: 1.2919\n",
      "Epoch 81/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9900 - val_loss: 1.2923\n",
      "Epoch 82/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9813 - val_loss: 1.2932\n",
      "Epoch 83/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9689 - val_loss: 1.2888\n",
      "Epoch 84/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9614 - val_loss: 1.2910\n",
      "Epoch 85/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9481 - val_loss: 1.2917\n",
      "Epoch 86/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9378 - val_loss: 1.2953\n",
      "Epoch 87/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9299 - val_loss: 1.2859\n",
      "Epoch 88/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9220 - val_loss: 1.2932\n",
      "Epoch 89/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9087 - val_loss: 1.2920\n",
      "Epoch 90/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9003 - val_loss: 1.2912\n",
      "Epoch 91/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8902 - val_loss: 1.2914\n",
      "Epoch 92/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8839 - val_loss: 1.2896\n",
      "Epoch 93/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.8731 - val_loss: 1.2903\n",
      "Epoch 94/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8662 - val_loss: 1.2886\n",
      "Epoch 95/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8602 - val_loss: 1.2966\n",
      "Epoch 96/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8503 - val_loss: 1.2926\n",
      "Epoch 97/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8420 - val_loss: 1.2953\n",
      "8/8 [==============================] - 0s 850us/step - loss: 1.6882\n",
      "[CV] END .....learning_rate=0.0001, n_hidden=4, n_neurons=42; total time=   4.9s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 2.0500 - val_loss: 1.4975\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8148 - val_loss: 1.4038\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6077 - val_loss: 1.3479\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3929 - val_loss: 1.3855\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2568 - val_loss: 1.4591\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0628 - val_loss: 1.3166\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9378 - val_loss: 1.2739\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7921 - val_loss: 1.4137\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7590 - val_loss: 1.5024\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7042 - val_loss: 1.3470\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6145 - val_loss: 1.3432\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5099 - val_loss: 1.4684\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4870 - val_loss: 1.4148\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4310 - val_loss: 1.3941\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4049 - val_loss: 1.5141\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3765 - val_loss: 1.3717\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3588 - val_loss: 1.3873\n",
      "8/8 [==============================] - 0s 878us/step - loss: 1.4372\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=4, n_neurons=57; total time=   1.3s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 2.2468 - val_loss: 1.5055\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9867 - val_loss: 1.4399\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7471 - val_loss: 1.4159\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4722 - val_loss: 1.4088\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3460 - val_loss: 1.3851\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1965 - val_loss: 1.3974\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0449 - val_loss: 1.4384\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8796 - val_loss: 1.2468\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7790 - val_loss: 1.4694\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7163 - val_loss: 1.3804\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6447 - val_loss: 1.2327\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6986 - val_loss: 1.5028\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6599 - val_loss: 1.2090\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5262 - val_loss: 1.3211\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4722 - val_loss: 1.2542\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4284 - val_loss: 1.3722\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5364 - val_loss: 1.1838\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4537 - val_loss: 1.4246\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4555 - val_loss: 1.2440\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3540 - val_loss: 1.1787\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3144 - val_loss: 1.3026\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2743 - val_loss: 1.1898\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3205 - val_loss: 1.3670\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3110 - val_loss: 1.2866\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2156 - val_loss: 1.2758\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1974 - val_loss: 1.2185\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2009 - val_loss: 1.2394\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2175 - val_loss: 1.2134\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2069 - val_loss: 1.3124\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2320 - val_loss: 1.2172\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.4958\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=4, n_neurons=57; total time=   1.9s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 1.9575 - val_loss: 1.4978\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7537 - val_loss: 1.3995\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5581 - val_loss: 1.3555\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3659 - val_loss: 1.2602\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2170 - val_loss: 1.2546\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0611 - val_loss: 1.2868\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0572 - val_loss: 1.3349\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9823 - val_loss: 1.2206\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8532 - val_loss: 1.2948\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7967 - val_loss: 1.4728\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7145 - val_loss: 1.3483\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6605 - val_loss: 1.2777\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5488 - val_loss: 1.2937\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5022 - val_loss: 1.3660\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4267 - val_loss: 1.4385\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4887 - val_loss: 1.3605\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4096 - val_loss: 1.3516\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3564 - val_loss: 1.3167\n",
      "8/8 [==============================] - 0s 780us/step - loss: 1.5496\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=4, n_neurons=57; total time=   1.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 9ms/step - loss: 2.0564 - val_loss: 1.4822\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.8164 - val_loss: 1.4109\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.6522 - val_loss: 1.3628\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4951 - val_loss: 1.3502\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3833 - val_loss: 1.3338\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2065 - val_loss: 1.3587\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0973 - val_loss: 1.3768\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.9876 - val_loss: 1.3734\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8620 - val_loss: 1.3873\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7808 - val_loss: 1.3833\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7027 - val_loss: 1.4254\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6571 - val_loss: 1.4836\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5905 - val_loss: 1.4482\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5289 - val_loss: 1.4637\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4817 - val_loss: 1.4124\n",
      "8/8 [==============================] - 0s 902us/step - loss: 1.5730\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=3, n_neurons=87; total time=   1.2s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 8ms/step - loss: 2.1934 - val_loss: 1.4538\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.9144 - val_loss: 1.3850\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7277 - val_loss: 1.3410\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5422 - val_loss: 1.3489\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4343 - val_loss: 1.3384\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.2994 - val_loss: 1.4270\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1676 - val_loss: 1.3603\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.0321 - val_loss: 1.3390\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9364 - val_loss: 1.3266\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8777 - val_loss: 1.3836\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8097 - val_loss: 1.3273\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7608 - val_loss: 1.3331\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6987 - val_loss: 1.3322\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6842 - val_loss: 1.3718\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6346 - val_loss: 1.3164\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5647 - val_loss: 1.3687\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5930 - val_loss: 1.4767\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5745 - val_loss: 1.4207\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5175 - val_loss: 1.4243\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4381 - val_loss: 1.3630\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4963 - val_loss: 1.4141\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4448 - val_loss: 1.3962\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5044 - val_loss: 1.4607\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3668 - val_loss: 1.3093\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3315 - val_loss: 1.4134\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3191 - val_loss: 1.3458\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3218 - val_loss: 1.3642\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3027 - val_loss: 1.3959\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2884 - val_loss: 1.3280\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3235 - val_loss: 1.3065\n",
      "Epoch 31/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2822 - val_loss: 1.3168\n",
      "Epoch 32/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2874 - val_loss: 1.3071\n",
      "Epoch 33/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3149 - val_loss: 1.4754\n",
      "Epoch 34/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3065 - val_loss: 1.3787\n",
      "Epoch 35/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2728 - val_loss: 1.3847\n",
      "Epoch 36/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2240 - val_loss: 1.3286\n",
      "Epoch 37/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2272 - val_loss: 1.3923\n",
      "Epoch 38/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2044 - val_loss: 1.3595\n",
      "Epoch 39/300\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1883 - val_loss: 1.3930\n",
      "Epoch 40/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1785 - val_loss: 1.3608\n",
      "8/8 [==============================] - 0s 783us/step - loss: 1.2619\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=3, n_neurons=87; total time=   2.2s\n",
      "Epoch 1/300\n",
      "15/15 [==============================] - 1s 8ms/step - loss: 1.9361 - val_loss: 1.4701\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.7382 - val_loss: 1.4269\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.5825 - val_loss: 1.3697\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.4367 - val_loss: 1.3016\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.3058 - val_loss: 1.2615\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1714 - val_loss: 1.2919\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 1.1322 - val_loss: 1.3844\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9975 - val_loss: 1.2301\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9228 - val_loss: 1.2655\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8776 - val_loss: 1.3479\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7918 - val_loss: 1.2500\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7424 - val_loss: 1.2474\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6912 - val_loss: 1.2934\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6378 - val_loss: 1.2899\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6328 - val_loss: 1.4769\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6243 - val_loss: 1.3347\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5264 - val_loss: 1.3059\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4778 - val_loss: 1.3323\n",
      "8/8 [==============================] - 0s 784us/step - loss: 1.5418\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=3, n_neurons=87; total time=   1.3s\n",
      "Epoch 1/300\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 2.0695 - val_loss: 1.5245\n",
      "Epoch 2/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.9080 - val_loss: 1.4158\n",
      "Epoch 3/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.6863 - val_loss: 1.3570\n",
      "Epoch 4/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.4239 - val_loss: 1.3359\n",
      "Epoch 5/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.1761 - val_loss: 1.2236\n",
      "Epoch 6/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.9812 - val_loss: 1.2459\n",
      "Epoch 7/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.8921 - val_loss: 1.2119\n",
      "Epoch 8/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.7502 - val_loss: 1.2833\n",
      "Epoch 9/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6915 - val_loss: 1.3511\n",
      "Epoch 10/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6344 - val_loss: 1.3432\n",
      "Epoch 11/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5438 - val_loss: 1.2684\n",
      "Epoch 12/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5203 - val_loss: 1.2148\n",
      "Epoch 13/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4607 - val_loss: 1.1098\n",
      "Epoch 14/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4864 - val_loss: 1.2929\n",
      "Epoch 15/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5060 - val_loss: 1.1634\n",
      "Epoch 16/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4295 - val_loss: 1.1546\n",
      "Epoch 17/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4670 - val_loss: 1.1165\n",
      "Epoch 18/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5978 - val_loss: 1.1907\n",
      "Epoch 19/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3702 - val_loss: 1.0837\n",
      "Epoch 20/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3715 - val_loss: 1.2238\n",
      "Epoch 21/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3884 - val_loss: 1.0792\n",
      "Epoch 22/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3739 - val_loss: 1.0864\n",
      "Epoch 23/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2923 - val_loss: 1.1001\n",
      "Epoch 24/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3007 - val_loss: 1.0818\n",
      "Epoch 25/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2971 - val_loss: 1.1307\n",
      "Epoch 26/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2759 - val_loss: 1.0552\n",
      "Epoch 27/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2602 - val_loss: 1.1796\n",
      "Epoch 28/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3178 - val_loss: 1.1971\n",
      "Epoch 29/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3041 - val_loss: 1.1875\n",
      "Epoch 30/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2484 - val_loss: 1.0726\n",
      "Epoch 31/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2343 - val_loss: 1.1623\n",
      "Epoch 32/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2959 - val_loss: 1.0870\n",
      "Epoch 33/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3426 - val_loss: 1.2244\n",
      "Epoch 34/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3042 - val_loss: 1.1028\n",
      "Epoch 35/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2575 - val_loss: 1.0476\n",
      "Epoch 36/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3870 - val_loss: 1.2305\n",
      "Epoch 37/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3001 - val_loss: 1.0927\n",
      "Epoch 38/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2433 - val_loss: 1.1263\n",
      "Epoch 39/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2307 - val_loss: 1.0724\n",
      "Epoch 40/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1974 - val_loss: 1.0989\n",
      "Epoch 41/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2129 - val_loss: 1.2662\n",
      "Epoch 42/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2289 - val_loss: 1.1283\n",
      "Epoch 43/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2738 - val_loss: 1.1747\n",
      "Epoch 44/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2506 - val_loss: 1.1080\n",
      "Epoch 45/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2342 - val_loss: 1.0954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=3,\n",
       "              estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x000002C86F5F6370>,\n",
       "              n_iter=10,\n",
       "              search_spaces={'learning_rate': array([0.0001, 0.0011, 0.0021]),\n",
       "                             'n_hidden': [2, 3, 4, 5, 6],\n",
       "                             'n_neurons': array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,\n",
       "       27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43,\n",
       "       44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n",
       "       61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77,\n",
       "       78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94,\n",
       "       95, 96, 97, 98, 99])},\n",
       "              verbose=2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import skopt\n",
    "\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [2,3, 4, 5, 6],\n",
    "    \"n_neurons\": np.arange(10,100),\n",
    "    \"learning_rate\": np.arange(0.0001, 0.003, 0.001),\n",
    "}\n",
    "\n",
    "bayes_search_cv = skopt.BayesSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "bayes_search_cv.fit(X_train2, y_train2, epochs=300,\n",
    "                  validation_data=(X_test2, y_test2),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('learning_rate', 0.0011), ('n_hidden', 5), ('n_neurons', 63)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.354098876317342"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 744us/step - loss: 1.0954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.0954310894012451"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_search_cv.score(X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_149 (Dense)           (None, 63)                4221      \n",
      "                                                                 \n",
      " dense_150 (Dense)           (None, 63)                4032      \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 63)                4032      \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 63)                4032      \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 63)                4032      \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 1)                 64        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,413\n",
      "Trainable params: 20,413\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = bayes_search_cv.best_estimator_.model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 839us/step - loss: 1.0954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0954310894012451"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0466135867644752"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.sqrt(1.0954)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN for Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(n_hidden=1, n_neurons=60, learning_rate=1e-3, input_shape=X_train3.shape[1]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stvp2\\AppData\\Local\\Temp\\ipykernel_38324\\1370646454.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model3)\n"
     ]
    }
   ],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "Epoch 1/160\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.5366 - val_loss: 1.9317\n",
      "Epoch 2/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2516 - val_loss: 1.8687\n",
      "Epoch 3/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.0308 - val_loss: 1.8047\n",
      "Epoch 4/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.8680 - val_loss: 1.9452\n",
      "Epoch 5/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.7828 - val_loss: 1.7182\n",
      "Epoch 6/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4785 - val_loss: 1.6289\n",
      "Epoch 7/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3310 - val_loss: 1.6994\n",
      "Epoch 8/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1659 - val_loss: 1.5672\n",
      "Epoch 9/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0813 - val_loss: 1.5741\n",
      "Epoch 10/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9668 - val_loss: 1.6709\n",
      "Epoch 11/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9096 - val_loss: 1.6849\n",
      "Epoch 12/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8873 - val_loss: 1.5756\n",
      "Epoch 13/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8039 - val_loss: 1.6085\n",
      "Epoch 14/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7270 - val_loss: 1.5960\n",
      "Epoch 15/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6828 - val_loss: 1.7296\n",
      "Epoch 16/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6591 - val_loss: 1.7105\n",
      "Epoch 17/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7159 - val_loss: 1.5573\n",
      "Epoch 18/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6242 - val_loss: 1.5312\n",
      "Epoch 19/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6103 - val_loss: 1.5810\n",
      "Epoch 20/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5764 - val_loss: 1.6030\n",
      "Epoch 21/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5098 - val_loss: 1.7086\n",
      "Epoch 22/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4943 - val_loss: 1.5461\n",
      "Epoch 23/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4906 - val_loss: 1.4100\n",
      "Epoch 24/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5086 - val_loss: 1.5989\n",
      "Epoch 25/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4986 - val_loss: 1.5658\n",
      "Epoch 26/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4504 - val_loss: 1.4742\n",
      "Epoch 27/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - val_loss: 1.6263\n",
      "Epoch 28/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4019 - val_loss: 1.4464\n",
      "Epoch 29/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4143 - val_loss: 1.4452\n",
      "Epoch 30/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3771 - val_loss: 1.8977\n",
      "Epoch 31/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - val_loss: 1.4645\n",
      "Epoch 32/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3820 - val_loss: 1.5002\n",
      "Epoch 33/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3363 - val_loss: 1.4518\n",
      "Epoch 34/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3623 - val_loss: 1.5574\n",
      "Epoch 35/160\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3323 - val_loss: 1.5192\n",
      "Epoch 36/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3421 - val_loss: 1.4483\n",
      "Epoch 37/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2838 - val_loss: 1.4569\n",
      "Epoch 38/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2830 - val_loss: 1.4518\n",
      "Epoch 39/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2760 - val_loss: 1.4404\n",
      "Epoch 40/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2788 - val_loss: 1.4942\n",
      "Epoch 41/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2924 - val_loss: 1.3826\n",
      "Epoch 42/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2787 - val_loss: 1.7016\n",
      "Epoch 43/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3252 - val_loss: 1.3625\n",
      "Epoch 44/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2700 - val_loss: 1.4255\n",
      "Epoch 45/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2494 - val_loss: 1.4350\n",
      "Epoch 46/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2386 - val_loss: 1.3298\n",
      "Epoch 47/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2877 - val_loss: 1.4142\n",
      "Epoch 48/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2506 - val_loss: 1.5489\n",
      "Epoch 49/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2086 - val_loss: 1.4439\n",
      "Epoch 50/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2564 - val_loss: 1.4918\n",
      "Epoch 51/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2357 - val_loss: 1.3593\n",
      "Epoch 52/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2310 - val_loss: 1.4457\n",
      "Epoch 53/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2072 - val_loss: 1.4222\n",
      "Epoch 54/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2133 - val_loss: 1.4152\n",
      "Epoch 55/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2027 - val_loss: 1.4740\n",
      "Epoch 56/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2273 - val_loss: 1.3535\n",
      "Epoch 57/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2171 - val_loss: 1.4615\n",
      "Epoch 58/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2222 - val_loss: 1.4101\n",
      "Epoch 59/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1902 - val_loss: 1.4423\n",
      "Epoch 60/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2344 - val_loss: 1.3775\n",
      "Epoch 61/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2181 - val_loss: 1.5638\n",
      "Epoch 62/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2329 - val_loss: 1.3455\n",
      "Epoch 63/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2088 - val_loss: 1.4582\n",
      "Epoch 64/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2507 - val_loss: 1.3679\n",
      "Epoch 65/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2172 - val_loss: 1.4462\n",
      "Epoch 66/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1729 - val_loss: 1.4392\n",
      "Epoch 67/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1905 - val_loss: 1.5136\n",
      "Epoch 68/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1911 - val_loss: 1.4593\n",
      "Epoch 69/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2509 - val_loss: 1.6112\n",
      "Epoch 70/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2167 - val_loss: 1.3526\n",
      "Epoch 71/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 1.4705\n",
      "Epoch 72/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1731 - val_loss: 1.3541\n",
      "Epoch 73/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1978 - val_loss: 1.3101\n",
      "Epoch 74/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1655 - val_loss: 1.3266\n",
      "Epoch 75/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1531 - val_loss: 1.5065\n",
      "Epoch 76/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1515 - val_loss: 1.3945\n",
      "Epoch 77/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1213 - val_loss: 1.4077\n",
      "Epoch 78/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1493 - val_loss: 1.4404\n",
      "Epoch 79/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1535 - val_loss: 1.4492\n",
      "Epoch 80/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1675 - val_loss: 1.5427\n",
      "Epoch 81/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1849 - val_loss: 1.3540\n",
      "Epoch 82/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1601 - val_loss: 1.4527\n",
      "Epoch 83/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1686 - val_loss: 1.3192\n",
      "Epoch 84/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1384 - val_loss: 1.5043\n",
      "Epoch 85/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1333 - val_loss: 1.4652\n",
      "Epoch 86/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1311 - val_loss: 1.3986\n",
      "Epoch 87/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1364 - val_loss: 1.5144\n",
      "Epoch 88/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1220 - val_loss: 1.4095\n",
      "Epoch 89/160\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1022 - val_loss: 1.4179\n",
      "Epoch 90/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1000 - val_loss: 1.4314\n",
      "Epoch 91/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1246 - val_loss: 1.3342\n",
      "Epoch 92/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1177 - val_loss: 1.4022\n",
      "Epoch 93/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1116 - val_loss: 1.4625\n",
      "Epoch 94/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1089 - val_loss: 1.4376\n",
      "Epoch 95/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1451 - val_loss: 1.4731\n",
      "Epoch 96/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1602 - val_loss: 1.4477\n",
      "Epoch 97/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1224 - val_loss: 1.4572\n",
      "Epoch 98/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1890 - val_loss: 1.3815\n",
      "Epoch 99/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1515 - val_loss: 1.3784\n",
      "Epoch 100/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1378 - val_loss: 1.4817\n",
      "Epoch 101/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 1.5652\n",
      "Epoch 102/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1035 - val_loss: 1.3669\n",
      "Epoch 103/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0940 - val_loss: 1.4745\n",
      "Epoch 104/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 1.4586\n",
      "Epoch 105/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1167 - val_loss: 1.4428\n",
      "Epoch 106/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1084 - val_loss: 1.4564\n",
      "Epoch 107/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0960 - val_loss: 1.3945\n",
      "Epoch 108/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0931 - val_loss: 1.4222\n",
      "Epoch 109/160\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0801 - val_loss: 1.4239\n",
      "Epoch 110/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0788 - val_loss: 1.4669\n",
      "Epoch 111/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1045 - val_loss: 1.4011\n",
      "Epoch 112/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1265 - val_loss: 1.5143\n",
      "Epoch 113/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1148 - val_loss: 1.3642\n",
      "Epoch 114/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 1.5505\n",
      "Epoch 115/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0884 - val_loss: 1.4164\n",
      "Epoch 116/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0826 - val_loss: 1.3974\n",
      "Epoch 117/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0984 - val_loss: 1.3692\n",
      "Epoch 118/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0788 - val_loss: 1.3694\n",
      "Epoch 119/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0841 - val_loss: 1.5190\n",
      "Epoch 120/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1163 - val_loss: 1.5221\n",
      "Epoch 121/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1056 - val_loss: 1.4560\n",
      "Epoch 122/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0904 - val_loss: 1.4519\n",
      "Epoch 123/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1017 - val_loss: 1.3984\n",
      "Epoch 124/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1010 - val_loss: 1.4827\n",
      "Epoch 125/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0959 - val_loss: 1.4400\n",
      "Epoch 126/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0973 - val_loss: 1.4702\n",
      "Epoch 127/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1090 - val_loss: 1.4289\n",
      "Epoch 128/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0713 - val_loss: 1.4489\n",
      "Epoch 129/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0604 - val_loss: 1.4089\n",
      "Epoch 130/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0634 - val_loss: 1.4801\n",
      "Epoch 131/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1043 - val_loss: 1.3731\n",
      "Epoch 132/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0966 - val_loss: 1.4348\n",
      "Epoch 133/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0984 - val_loss: 1.4155\n",
      "Epoch 134/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0843 - val_loss: 1.3830\n",
      "Epoch 135/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 1.3862\n",
      "Epoch 136/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 1.3952\n",
      "Epoch 137/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0475 - val_loss: 1.3822\n",
      "Epoch 138/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0348 - val_loss: 1.3982\n",
      "Epoch 139/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0409 - val_loss: 1.4598\n",
      "Epoch 140/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0652 - val_loss: 1.3585\n",
      "Epoch 141/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1063 - val_loss: 1.4431\n",
      "Epoch 142/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1012 - val_loss: 1.4418\n",
      "Epoch 143/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1214 - val_loss: 1.4373\n",
      "Epoch 144/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0870 - val_loss: 1.4150\n",
      "Epoch 145/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0976 - val_loss: 1.3592\n",
      "Epoch 146/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1110 - val_loss: 1.4545\n",
      "Epoch 147/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 1.5119\n",
      "Epoch 148/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0781 - val_loss: 1.3323\n",
      "Epoch 149/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0658 - val_loss: 1.4173\n",
      "Epoch 150/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0629 - val_loss: 1.3384\n",
      "Epoch 151/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0970 - val_loss: 1.4657\n",
      "Epoch 152/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0848 - val_loss: 1.3727\n",
      "Epoch 153/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0992 - val_loss: 1.4504\n",
      "Epoch 154/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0878 - val_loss: 1.4217\n",
      "Epoch 155/160\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0700 - val_loss: 1.4240\n",
      "Epoch 156/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0628 - val_loss: 1.3585\n",
      "Epoch 157/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0621 - val_loss: 1.4380\n",
      "Epoch 158/160\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0856 - val_loss: 1.3689\n",
      "Epoch 159/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0853 - val_loss: 1.4721\n",
      "Epoch 160/160\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0566 - val_loss: 1.3644\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "# define the input shape and number of classes\n",
    "input_shape = X_train3.shape[1]\n",
    "num_classes = 1\n",
    "\n",
    "# define the model architecture\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(70, activation='relu', input_shape=(input_shape,)))\n",
    "for i in range(3):\n",
    "    model.add(layers.Dense(70, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='linear'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "# compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "#print(model.summary())\n",
    "print(input_shape)\n",
    "\n",
    "# train the model\n",
    "history = model.fit(X_train3, y_train3, epochs=160, validation_data=(X_test3, y_test3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.536648988723755, 2.2515628337860107, 2.0307998657226562, 1.868023157119751, 1.7828117609024048, 1.4784653186798096, 1.331016182899475, 1.1659215688705444, 1.0813229084014893, 0.9667714834213257, 0.9095911979675293, 0.8873499035835266, 0.8039260506629944, 0.7270190715789795, 0.6828060746192932, 0.6590933799743652, 0.7158951759338379, 0.6242271661758423, 0.6103334426879883, 0.5764213800430298, 0.5098221898078918, 0.49427950382232666, 0.49062833189964294, 0.5085828900337219, 0.49862149357795715, 0.45044395327568054, 0.4215429127216339, 0.40192827582359314, 0.41434812545776367, 0.3771483600139618, 0.4498596787452698, 0.3820241689682007, 0.33633166551589966, 0.3622523844242096, 0.33228811621665955, 0.3420710563659668, 0.2838175594806671, 0.2829543352127075, 0.2760413587093353, 0.27880245447158813, 0.29235512018203735, 0.278666615486145, 0.3252376616001129, 0.2699697017669678, 0.24939924478530884, 0.23859575390815735, 0.28770574927330017, 0.2506428360939026, 0.20861001312732697, 0.2564268410205841, 0.23574823141098022, 0.23098760843276978, 0.2071792334318161, 0.21333234012126923, 0.20265653729438782, 0.22730663418769836, 0.2171333134174347, 0.22218267619609833, 0.19018754363059998, 0.23435437679290771, 0.2181035429239273, 0.23289473354816437, 0.20879988372325897, 0.25071653723716736, 0.21719247102737427, 0.17288102209568024, 0.19045159220695496, 0.1910562813282013, 0.25090551376342773, 0.21673814952373505, 0.19600306451320648, 0.17314666509628296, 0.1977871209383011, 0.16551342606544495, 0.15309640765190125, 0.15148626267910004, 0.12126252055168152, 0.14927217364311218, 0.15347836911678314, 0.16754962503910065, 0.18487441539764404, 0.16010616719722748, 0.16862745583057404, 0.13844524323940277, 0.13334336876869202, 0.13105681538581848, 0.13636472821235657, 0.12198986113071442, 0.10219959169626236, 0.09998961538076401, 0.12458907067775726, 0.1177196055650711, 0.11157527565956116, 0.1088898777961731, 0.14506395161151886, 0.1601511538028717, 0.12238176167011261, 0.18896721303462982, 0.15146447718143463, 0.13781768083572388, 0.09850823879241943, 0.10345428436994553, 0.0939846783876419, 0.08668973296880722, 0.11674825102090836, 0.10842867195606232, 0.09600163996219635, 0.09306184202432632, 0.08009785413742065, 0.07878434658050537, 0.10447835922241211, 0.1264561116695404, 0.1147533431649208, 0.11084257811307907, 0.08839229494333267, 0.0825536772608757, 0.09839294850826263, 0.07881072908639908, 0.08410131931304932, 0.1162872463464737, 0.10557504743337631, 0.09035727381706238, 0.10168915241956711, 0.10104497522115707, 0.09586140513420105, 0.09725375473499298, 0.10897859930992126, 0.07131411880254745, 0.060434214770793915, 0.06343972682952881, 0.10429494082927704, 0.09664106369018555, 0.09836345165967941, 0.08428104966878891, 0.06797018647193909, 0.05857124924659729, 0.047539301216602325, 0.03482901304960251, 0.040911007672548294, 0.06521283835172653, 0.10627228021621704, 0.1012154072523117, 0.12139525264501572, 0.0869552418589592, 0.09756678342819214, 0.11101440340280533, 0.07190974801778793, 0.07812321186065674, 0.06582249701023102, 0.0628724992275238, 0.09701348841190338, 0.08484400063753128, 0.09920923411846161, 0.08783265948295593, 0.07000450044870377, 0.0628436803817749, 0.06210612505674362, 0.0855768620967865, 0.08527811616659164, 0.056580714881420135]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history[\"loss\"])\n",
    "plot_learning_curves(np.sqrt(history.history[\"loss\"]), np.sqrt(history.history[\"val_loss\"]))\n",
    "plt.ylim(0,2)\n",
    "plt.show()\n",
    "#plt.savefig(\"deepfoodsecurity.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.7014 - val_loss: 1.9448\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3284 - val_loss: 1.8901\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0384 - val_loss: 1.7946\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7057 - val_loss: 1.7734\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4417 - val_loss: 1.7783\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4250 - val_loss: 1.8090\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1757 - val_loss: 1.8508\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0314 - val_loss: 1.7119\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9091 - val_loss: 2.0965\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9298 - val_loss: 1.7742\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7040 - val_loss: 1.8618\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7424 - val_loss: 1.9479\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6027 - val_loss: 1.9764\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5801 - val_loss: 1.7811\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4979 - val_loss: 1.9089\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5208 - val_loss: 2.0165\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5120 - val_loss: 1.9614\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4507 - val_loss: 1.7505\n",
      "6/6 [==============================] - 0s 994us/step - loss: 1.6936\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=4, n_neurons=77; total time=   1.5s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 10ms/step - loss: 2.6268 - val_loss: 1.9459\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1657 - val_loss: 1.8566\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8379 - val_loss: 1.8546\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5559 - val_loss: 1.8944\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3464 - val_loss: 1.7861\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3149 - val_loss: 1.8990\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1091 - val_loss: 1.8836\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9624 - val_loss: 1.7836\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8216 - val_loss: 1.7938\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7433 - val_loss: 1.9556\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7054 - val_loss: 1.7510\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6603 - val_loss: 1.9308\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6030 - val_loss: 1.9845\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6093 - val_loss: 1.7039\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5382 - val_loss: 2.0075\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4333 - val_loss: 1.8519\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4101 - val_loss: 1.9109\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3797 - val_loss: 1.9755\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4359 - val_loss: 2.1546\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4181 - val_loss: 1.6651\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4930 - val_loss: 2.2256\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3693 - val_loss: 1.7030\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3124 - val_loss: 1.7511\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2622 - val_loss: 1.7104\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2329 - val_loss: 1.8918\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2736 - val_loss: 1.9927\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2638 - val_loss: 1.7593\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2787 - val_loss: 1.8628\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2164 - val_loss: 1.8683\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1798 - val_loss: 1.6897\n",
      "6/6 [==============================] - 0s 897us/step - loss: 1.7122\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=4, n_neurons=77; total time=   1.8s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.6165 - val_loss: 2.0567\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2726 - val_loss: 1.8759\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9279 - val_loss: 1.8234\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6359 - val_loss: 1.7370\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3722 - val_loss: 1.6297\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2011 - val_loss: 1.6655\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0186 - val_loss: 1.7526\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0069 - val_loss: 1.9058\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9057 - val_loss: 1.8132\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8620 - val_loss: 1.7360\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7203 - val_loss: 1.6693\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6089 - val_loss: 1.7035\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5207 - val_loss: 1.8068\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6012 - val_loss: 1.7060\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5349 - val_loss: 1.6099\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5155 - val_loss: 1.6651\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4066 - val_loss: 1.5006\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3302 - val_loss: 1.7069\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2913 - val_loss: 1.6707\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2871 - val_loss: 1.6350\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3301 - val_loss: 1.5736\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3287 - val_loss: 1.5561\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2511 - val_loss: 1.5400\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2352 - val_loss: 1.5662\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2534 - val_loss: 1.6371\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2800 - val_loss: 1.6770\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2527 - val_loss: 1.5444\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.8863\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=4, n_neurons=77; total time=   1.7s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.6566 - val_loss: 2.0400\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.5844 - val_loss: 2.0231\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5441 - val_loss: 1.9974\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4973 - val_loss: 1.9762\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4538 - val_loss: 1.9490\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3924 - val_loss: 1.9277\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3358 - val_loss: 1.9151\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2744 - val_loss: 1.9012\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2049 - val_loss: 1.8861\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1281 - val_loss: 1.9018\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0598 - val_loss: 1.8874\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.9644 - val_loss: 1.8811\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8875 - val_loss: 1.8726\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8121 - val_loss: 1.8599\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7395 - val_loss: 1.8798\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6624 - val_loss: 1.8575\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6032 - val_loss: 1.8590\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5612 - val_loss: 1.8053\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4974 - val_loss: 1.8173\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4657 - val_loss: 1.9342\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4134 - val_loss: 1.8194\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3751 - val_loss: 1.8229\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3387 - val_loss: 1.8065\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2799 - val_loss: 1.8472\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2326 - val_loss: 1.9771\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2266 - val_loss: 1.8305\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1531 - val_loss: 1.8556\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0921 - val_loss: 2.0078\n",
      "6/6 [==============================] - 0s 998us/step - loss: 2.1953\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=6, n_neurons=16; total time=   1.9s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.7713 - val_loss: 2.0576\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7017 - val_loss: 2.0231\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6457 - val_loss: 1.9914\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5861 - val_loss: 1.9597\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5310 - val_loss: 1.9278\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.4390 - val_loss: 1.9052\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3671 - val_loss: 1.8936\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2652 - val_loss: 1.8689\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1784 - val_loss: 1.8511\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0838 - val_loss: 1.8396\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9872 - val_loss: 1.8091\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8916 - val_loss: 1.7841\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7895 - val_loss: 1.7424\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7019 - val_loss: 1.7400\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6171 - val_loss: 1.7580\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5199 - val_loss: 1.7106\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4364 - val_loss: 1.7483\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3367 - val_loss: 1.7184\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2739 - val_loss: 1.7313\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2472 - val_loss: 1.7836\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1586 - val_loss: 1.6840\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1216 - val_loss: 1.7263\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0906 - val_loss: 1.8474\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0516 - val_loss: 1.7195\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9658 - val_loss: 1.7455\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9627 - val_loss: 1.7356\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8839 - val_loss: 1.7545\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8244 - val_loss: 1.7523\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.7995 - val_loss: 1.7824\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7827 - val_loss: 1.7400\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7129 - val_loss: 1.7699\n",
      "6/6 [==============================] - 0s 898us/step - loss: 1.9472\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=6, n_neurons=16; total time=   2.0s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 12ms/step - loss: 2.5455 - val_loss: 2.1192\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4882 - val_loss: 2.0711\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4335 - val_loss: 2.0141\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3634 - val_loss: 1.9543\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2540 - val_loss: 1.9005\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1221 - val_loss: 1.8602\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0038 - val_loss: 1.8508\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8910 - val_loss: 1.8415\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8172 - val_loss: 1.8463\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7212 - val_loss: 1.8595\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6939 - val_loss: 1.8335\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5720 - val_loss: 1.8667\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5287 - val_loss: 1.8419\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4967 - val_loss: 1.8645\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3901 - val_loss: 1.8870\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3293 - val_loss: 1.9335\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2969 - val_loss: 1.9215\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.2241 - val_loss: 1.9472\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1217 - val_loss: 1.9882\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0774 - val_loss: 1.9809\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0344 - val_loss: 2.0628\n",
      "6/6 [==============================] - 0s 915us/step - loss: 2.4291\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=6, n_neurons=16; total time=   1.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.6019 - val_loss: 1.9320\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4282 - val_loss: 1.9166\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2690 - val_loss: 1.8232\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0157 - val_loss: 1.7680\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7789 - val_loss: 1.8732\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6440 - val_loss: 1.9555\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4290 - val_loss: 1.8931\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2376 - val_loss: 1.9922\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0973 - val_loss: 1.7993\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9917 - val_loss: 1.9702\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8098 - val_loss: 2.1577\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8067 - val_loss: 2.2363\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7531 - val_loss: 2.1711\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6905 - val_loss: 1.9420\n",
      "6/6 [==============================] - 0s 987us/step - loss: 1.8865\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=5, n_neurons=60; total time=   1.3s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.7537 - val_loss: 1.9622\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5251 - val_loss: 1.8902\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2903 - val_loss: 1.7680\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9681 - val_loss: 1.7005\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7090 - val_loss: 1.6624\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4227 - val_loss: 1.6276\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2441 - val_loss: 1.7038\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0690 - val_loss: 1.5871\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9502 - val_loss: 1.6261\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8710 - val_loss: 1.6732\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8217 - val_loss: 1.5514\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7183 - val_loss: 1.6562\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6208 - val_loss: 1.6579\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6044 - val_loss: 1.6820\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5338 - val_loss: 1.6285\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5171 - val_loss: 1.9203\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4532 - val_loss: 1.8448\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4412 - val_loss: 1.7187\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3846 - val_loss: 1.8302\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3580 - val_loss: 1.7899\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2969 - val_loss: 1.7118\n",
      "6/6 [==============================] - 0s 793us/step - loss: 1.8787\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=5, n_neurons=60; total time=   1.5s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.5277 - val_loss: 2.0217\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3776 - val_loss: 1.9705\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2076 - val_loss: 1.9007\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9933 - val_loss: 1.9308\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7772 - val_loss: 1.8625\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5351 - val_loss: 1.7887\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2958 - val_loss: 1.8513\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1153 - val_loss: 1.8636\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9713 - val_loss: 1.9012\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8652 - val_loss: 1.9261\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8176 - val_loss: 1.8487\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8191 - val_loss: 1.8707\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6931 - val_loss: 1.9301\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6654 - val_loss: 1.9251\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6721 - val_loss: 1.9044\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6184 - val_loss: 1.7826\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5759 - val_loss: 1.8430\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4842 - val_loss: 1.8208\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4422 - val_loss: 1.9267\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4017 - val_loss: 1.7682\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3922 - val_loss: 1.8263\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3525 - val_loss: 1.7741\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3127 - val_loss: 1.8086\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2969 - val_loss: 1.7901\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2888 - val_loss: 1.8438\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3142 - val_loss: 1.7807\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3121 - val_loss: 1.8126\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3014 - val_loss: 1.6949\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2773 - val_loss: 1.7654\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2292 - val_loss: 1.7138\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2215 - val_loss: 1.7188\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2450 - val_loss: 1.8786\n",
      "Epoch 33/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2915 - val_loss: 1.8474\n",
      "Epoch 34/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1996 - val_loss: 1.6930\n",
      "Epoch 35/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1794 - val_loss: 1.8247\n",
      "Epoch 36/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1735 - val_loss: 1.7923\n",
      "Epoch 37/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1722 - val_loss: 1.8198\n",
      "Epoch 38/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1821 - val_loss: 1.8848\n",
      "Epoch 39/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1478 - val_loss: 1.8014\n",
      "Epoch 40/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1380 - val_loss: 1.8529\n",
      "Epoch 41/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1352 - val_loss: 1.8276\n",
      "Epoch 42/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1333 - val_loss: 1.8270\n",
      "Epoch 43/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1429 - val_loss: 1.7873\n",
      "Epoch 44/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1091 - val_loss: 1.7957\n",
      "6/6 [==============================] - 0s 893us/step - loss: 1.7870\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=5, n_neurons=60; total time=   2.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.6740 - val_loss: 2.0489\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5025 - val_loss: 1.9869\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3943 - val_loss: 1.9523\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2910 - val_loss: 1.9164\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1975 - val_loss: 1.8849\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0653 - val_loss: 1.8623\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9538 - val_loss: 1.8646\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8489 - val_loss: 1.8660\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7584 - val_loss: 1.8362\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6324 - val_loss: 1.8647\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5466 - val_loss: 1.8669\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4270 - val_loss: 1.8508\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3461 - val_loss: 1.8130\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2496 - val_loss: 1.8835\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1649 - val_loss: 1.8637\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0850 - val_loss: 1.8400\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0134 - val_loss: 1.8444\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9638 - val_loss: 1.8642\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9123 - val_loss: 1.9022\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8817 - val_loss: 1.8377\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7972 - val_loss: 1.8499\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7553 - val_loss: 1.8931\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7289 - val_loss: 1.8547\n",
      "6/6 [==============================] - 0s 902us/step - loss: 1.6591\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=4, n_neurons=29; total time=   1.7s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.7605 - val_loss: 1.9930\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5448 - val_loss: 1.9395\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4401 - val_loss: 1.9043\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3396 - val_loss: 1.8663\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2360 - val_loss: 1.8563\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1255 - val_loss: 1.8404\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0226 - val_loss: 1.8444\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8977 - val_loss: 1.8318\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7699 - val_loss: 1.8024\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6510 - val_loss: 1.8469\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5463 - val_loss: 1.8144\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4379 - val_loss: 1.8282\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3601 - val_loss: 1.8248\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2803 - val_loss: 1.8292\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2308 - val_loss: 1.8572\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1424 - val_loss: 1.7821\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0611 - val_loss: 1.7610\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9783 - val_loss: 1.7129\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9313 - val_loss: 1.7745\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9154 - val_loss: 1.8750\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8411 - val_loss: 1.7271\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.7907 - val_loss: 1.7349\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7535 - val_loss: 1.8276\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7565 - val_loss: 1.7543\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6629 - val_loss: 1.7940\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6603 - val_loss: 1.7558\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6560 - val_loss: 1.7398\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6036 - val_loss: 1.7402\n",
      "6/6 [==============================] - 0s 893us/step - loss: 1.8011\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=4, n_neurons=29; total time=   1.7s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.5151 - val_loss: 2.0003\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3881 - val_loss: 1.9755\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3019 - val_loss: 1.9514\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2258 - val_loss: 1.9296\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1494 - val_loss: 1.9031\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0660 - val_loss: 1.8717\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9789 - val_loss: 1.8442\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8848 - val_loss: 1.8020\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8068 - val_loss: 1.7882\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.7271 - val_loss: 1.7668\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6682 - val_loss: 1.7610\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5639 - val_loss: 1.7234\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4964 - val_loss: 1.7001\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4286 - val_loss: 1.6605\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3612 - val_loss: 1.7011\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2934 - val_loss: 1.6886\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2481 - val_loss: 1.6811\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1754 - val_loss: 1.6634\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1005 - val_loss: 1.6664\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0415 - val_loss: 1.7135\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9923 - val_loss: 1.6919\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9428 - val_loss: 1.6836\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8957 - val_loss: 1.7170\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8556 - val_loss: 1.7081\n",
      "6/6 [==============================] - 0s 888us/step - loss: 2.0027\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=4, n_neurons=29; total time=   1.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.6390 - val_loss: 1.9868\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4815 - val_loss: 1.9603\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3437 - val_loss: 1.9215\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1301 - val_loss: 1.8473\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9347 - val_loss: 1.8311\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7277 - val_loss: 1.8360\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5052 - val_loss: 1.7542\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3648 - val_loss: 1.7510\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1421 - val_loss: 1.8303\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0317 - val_loss: 1.7731\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8799 - val_loss: 1.7990\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9017 - val_loss: 2.0127\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8640 - val_loss: 1.8611\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7179 - val_loss: 1.8001\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6446 - val_loss: 1.9105\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5856 - val_loss: 1.8645\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5531 - val_loss: 1.8890\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5085 - val_loss: 1.9499\n",
      "6/6 [==============================] - 0s 902us/step - loss: 1.9559\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=5, n_neurons=56; total time=   1.5s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.7413 - val_loss: 2.0130\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5455 - val_loss: 1.9573\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3370 - val_loss: 1.8938\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0747 - val_loss: 1.9049\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8260 - val_loss: 1.8641\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5738 - val_loss: 1.8167\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3899 - val_loss: 1.8406\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2463 - val_loss: 1.7438\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0852 - val_loss: 1.7029\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9924 - val_loss: 1.8342\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9783 - val_loss: 1.7450\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8556 - val_loss: 1.7680\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7436 - val_loss: 1.7998\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7036 - val_loss: 1.9028\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6486 - val_loss: 1.8716\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5798 - val_loss: 1.8925\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5534 - val_loss: 2.0581\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5244 - val_loss: 1.9535\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4943 - val_loss: 2.0825\n",
      "6/6 [==============================] - 0s 869us/step - loss: 1.9204\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=5, n_neurons=56; total time=   1.5s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.4924 - val_loss: 2.0798\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3042 - val_loss: 1.8990\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0857 - val_loss: 1.8777\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9137 - val_loss: 1.8054\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.7565 - val_loss: 1.7165\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.5767 - val_loss: 1.6581\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4582 - val_loss: 1.6720\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3857 - val_loss: 1.6056\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2536 - val_loss: 1.6415\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1346 - val_loss: 1.6460\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1464 - val_loss: 1.5810\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1193 - val_loss: 1.6608\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9325 - val_loss: 1.8255\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9093 - val_loss: 1.7384\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8741 - val_loss: 1.7203\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7588 - val_loss: 1.7088\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.7122 - val_loss: 1.8068\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6504 - val_loss: 1.7146\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5496 - val_loss: 1.7959\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5066 - val_loss: 1.7213\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5321 - val_loss: 1.8011\n",
      "6/6 [==============================] - 0s 973us/step - loss: 1.9821\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=5, n_neurons=56; total time=   1.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.6517 - val_loss: 1.9429\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4012 - val_loss: 1.8923\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2010 - val_loss: 1.8026\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9179 - val_loss: 1.7595\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6884 - val_loss: 1.8827\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6150 - val_loss: 1.8827\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3941 - val_loss: 1.9848\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2523 - val_loss: 2.0268\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0549 - val_loss: 2.0833\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.0561 - val_loss: 1.7862\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8112 - val_loss: 1.9963\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8830 - val_loss: 1.9787\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8424 - val_loss: 1.7466\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6144 - val_loss: 1.7780\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5314 - val_loss: 1.8146\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4885 - val_loss: 1.7734\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4634 - val_loss: 1.8542\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4519 - val_loss: 1.8421\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4176 - val_loss: 1.8290\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3995 - val_loss: 1.8136\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4067 - val_loss: 1.8129\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3788 - val_loss: 1.7774\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4011 - val_loss: 1.8619\n",
      "6/6 [==============================] - 0s 999us/step - loss: 1.6194\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=5, n_neurons=44; total time=   1.6s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.7637 - val_loss: 1.9862\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5377 - val_loss: 1.8941\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2246 - val_loss: 1.7708\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8677 - val_loss: 1.7546\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.6293 - val_loss: 1.6888\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4170 - val_loss: 1.5995\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2779 - val_loss: 1.8007\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0866 - val_loss: 1.4833\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9369 - val_loss: 1.6772\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9180 - val_loss: 1.6126\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8121 - val_loss: 1.5720\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7548 - val_loss: 1.6310\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6740 - val_loss: 1.5751\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6395 - val_loss: 1.6390\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6418 - val_loss: 1.5650\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6460 - val_loss: 1.5862\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5776 - val_loss: 1.7091\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6573 - val_loss: 1.7267\n",
      "6/6 [==============================] - 0s 800us/step - loss: 1.6495\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=5, n_neurons=44; total time=   1.4s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.5166 - val_loss: 1.9780\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2559 - val_loss: 1.9292\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9961 - val_loss: 1.8220\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8100 - val_loss: 1.9532\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5892 - val_loss: 1.7758\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3756 - val_loss: 1.7288\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2520 - val_loss: 1.7905\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0723 - val_loss: 1.8309\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9253 - val_loss: 1.9235\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8320 - val_loss: 1.9161\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8149 - val_loss: 1.9038\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7646 - val_loss: 1.8763\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7343 - val_loss: 1.7916\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7158 - val_loss: 1.9839\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6862 - val_loss: 1.9141\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6530 - val_loss: 1.7659\n",
      "6/6 [==============================] - 0s 993us/step - loss: 2.2413\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=5, n_neurons=44; total time=   1.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.7154 - val_loss: 2.2382\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7013 - val_loss: 2.2273\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6893 - val_loss: 2.2182\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6775 - val_loss: 2.2083\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6675 - val_loss: 2.1981\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6562 - val_loss: 2.1900\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6470 - val_loss: 2.1822\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6379 - val_loss: 2.1750\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6288 - val_loss: 2.1685\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6208 - val_loss: 2.1619\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6125 - val_loss: 2.1560\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6041 - val_loss: 2.1507\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5960 - val_loss: 2.1445\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5879 - val_loss: 2.1395\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5805 - val_loss: 2.1349\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5727 - val_loss: 2.1294\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.5641 - val_loss: 2.1248\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5564 - val_loss: 2.1192\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5479 - val_loss: 2.1141\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5402 - val_loss: 2.1089\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5318 - val_loss: 2.1049\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5243 - val_loss: 2.1000\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5161 - val_loss: 2.0956\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5081 - val_loss: 2.0907\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5007 - val_loss: 2.0871\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4934 - val_loss: 2.0837\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4873 - val_loss: 2.0794\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4802 - val_loss: 2.0766\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4741 - val_loss: 2.0735\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4677 - val_loss: 2.0702\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4609 - val_loss: 2.0672\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.4550 - val_loss: 2.0635\n",
      "Epoch 33/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4477 - val_loss: 2.0604\n",
      "Epoch 34/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4402 - val_loss: 2.0573\n",
      "Epoch 35/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4337 - val_loss: 2.0545\n",
      "Epoch 36/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4271 - val_loss: 2.0520\n",
      "Epoch 37/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4203 - val_loss: 2.0494\n",
      "Epoch 38/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4144 - val_loss: 2.0464\n",
      "Epoch 39/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4075 - val_loss: 2.0434\n",
      "Epoch 40/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3999 - val_loss: 2.0408\n",
      "Epoch 41/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3928 - val_loss: 2.0379\n",
      "Epoch 42/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3855 - val_loss: 2.0354\n",
      "Epoch 43/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3789 - val_loss: 2.0325\n",
      "Epoch 44/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3716 - val_loss: 2.0298\n",
      "Epoch 45/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3652 - val_loss: 2.0280\n",
      "Epoch 46/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.3593 - val_loss: 2.0263\n",
      "Epoch 47/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3531 - val_loss: 2.0239\n",
      "Epoch 48/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3464 - val_loss: 2.0221\n",
      "Epoch 49/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3412 - val_loss: 2.0203\n",
      "Epoch 50/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3347 - val_loss: 2.0188\n",
      "Epoch 51/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3292 - val_loss: 2.0173\n",
      "Epoch 52/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3232 - val_loss: 2.0161\n",
      "Epoch 53/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3176 - val_loss: 2.0140\n",
      "Epoch 54/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3117 - val_loss: 2.0127\n",
      "Epoch 55/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3068 - val_loss: 2.0105\n",
      "Epoch 56/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3003 - val_loss: 2.0097\n",
      "Epoch 57/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2950 - val_loss: 2.0082\n",
      "Epoch 58/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2893 - val_loss: 2.0069\n",
      "Epoch 59/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2840 - val_loss: 2.0062\n",
      "Epoch 60/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.2784 - val_loss: 2.0055\n",
      "Epoch 61/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2732 - val_loss: 2.0046\n",
      "Epoch 62/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2683 - val_loss: 2.0037\n",
      "Epoch 63/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2625 - val_loss: 2.0030\n",
      "Epoch 64/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2575 - val_loss: 2.0019\n",
      "Epoch 65/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2525 - val_loss: 2.0004\n",
      "Epoch 66/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2475 - val_loss: 1.9991\n",
      "Epoch 67/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2430 - val_loss: 1.9986\n",
      "Epoch 68/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2382 - val_loss: 1.9981\n",
      "Epoch 69/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2334 - val_loss: 1.9974\n",
      "Epoch 70/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2291 - val_loss: 1.9974\n",
      "Epoch 71/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2237 - val_loss: 1.9955\n",
      "Epoch 72/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2197 - val_loss: 1.9946\n",
      "Epoch 73/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2146 - val_loss: 1.9935\n",
      "Epoch 74/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2103 - val_loss: 1.9924\n",
      "Epoch 75/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2062 - val_loss: 1.9913\n",
      "Epoch 76/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2020 - val_loss: 1.9919\n",
      "Epoch 77/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1966 - val_loss: 1.9906\n",
      "Epoch 78/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1923 - val_loss: 1.9892\n",
      "Epoch 79/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1877 - val_loss: 1.9890\n",
      "Epoch 80/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1836 - val_loss: 1.9882\n",
      "Epoch 81/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1788 - val_loss: 1.9867\n",
      "Epoch 82/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1741 - val_loss: 1.9858\n",
      "Epoch 83/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1696 - val_loss: 1.9859\n",
      "Epoch 84/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1662 - val_loss: 1.9852\n",
      "Epoch 85/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1602 - val_loss: 1.9846\n",
      "Epoch 86/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1555 - val_loss: 1.9842\n",
      "Epoch 87/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1509 - val_loss: 1.9835\n",
      "Epoch 88/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1462 - val_loss: 1.9824\n",
      "Epoch 89/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1414 - val_loss: 1.9813\n",
      "Epoch 90/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1365 - val_loss: 1.9816\n",
      "Epoch 91/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1315 - val_loss: 1.9806\n",
      "Epoch 92/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1268 - val_loss: 1.9810\n",
      "Epoch 93/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1222 - val_loss: 1.9803\n",
      "Epoch 94/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1175 - val_loss: 1.9794\n",
      "Epoch 95/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1124 - val_loss: 1.9780\n",
      "Epoch 96/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1076 - val_loss: 1.9773\n",
      "Epoch 97/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1024 - val_loss: 1.9771\n",
      "Epoch 98/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0977 - val_loss: 1.9771\n",
      "Epoch 99/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0928 - val_loss: 1.9762\n",
      "Epoch 100/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0882 - val_loss: 1.9771\n",
      "Epoch 101/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0838 - val_loss: 1.9782\n",
      "Epoch 102/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0790 - val_loss: 1.9778\n",
      "Epoch 103/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0738 - val_loss: 1.9768\n",
      "Epoch 104/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0693 - val_loss: 1.9756\n",
      "Epoch 105/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0652 - val_loss: 1.9763\n",
      "Epoch 106/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0605 - val_loss: 1.9765\n",
      "Epoch 107/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0552 - val_loss: 1.9747\n",
      "Epoch 108/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0511 - val_loss: 1.9752\n",
      "Epoch 109/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0463 - val_loss: 1.9757\n",
      "Epoch 110/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0412 - val_loss: 1.9760\n",
      "Epoch 111/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0367 - val_loss: 1.9755\n",
      "Epoch 112/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0321 - val_loss: 1.9756\n",
      "Epoch 113/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0272 - val_loss: 1.9739\n",
      "Epoch 114/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0227 - val_loss: 1.9740\n",
      "Epoch 115/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0179 - val_loss: 1.9727\n",
      "Epoch 116/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0129 - val_loss: 1.9725\n",
      "Epoch 117/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0087 - val_loss: 1.9731\n",
      "Epoch 118/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.0036 - val_loss: 1.9742\n",
      "Epoch 119/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9986 - val_loss: 1.9731\n",
      "Epoch 120/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9937 - val_loss: 1.9740\n",
      "Epoch 121/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9888 - val_loss: 1.9734\n",
      "Epoch 122/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9837 - val_loss: 1.9734\n",
      "Epoch 123/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9794 - val_loss: 1.9732\n",
      "Epoch 124/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9747 - val_loss: 1.9737\n",
      "Epoch 125/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9696 - val_loss: 1.9742\n",
      "Epoch 126/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9652 - val_loss: 1.9736\n",
      "6/6 [==============================] - 0s 914us/step - loss: 2.2532\n",
      "[CV] END .....learning_rate=0.0001, n_hidden=3, n_neurons=13; total time=   5.3s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 10ms/step - loss: 2.8340 - val_loss: 2.2064\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.8237 - val_loss: 2.1962\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.8143 - val_loss: 2.1873\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.8058 - val_loss: 2.1791\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7980 - val_loss: 2.1714\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7894 - val_loss: 2.1645\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7827 - val_loss: 2.1573\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7751 - val_loss: 2.1507\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7679 - val_loss: 2.1448\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7620 - val_loss: 2.1379\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7551 - val_loss: 2.1313\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7487 - val_loss: 2.1251\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7420 - val_loss: 2.1187\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7357 - val_loss: 2.1133\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7294 - val_loss: 2.1078\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.7231 - val_loss: 2.1021\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7168 - val_loss: 2.0962\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7110 - val_loss: 2.0906\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7053 - val_loss: 2.0858\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7006 - val_loss: 2.0803\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6947 - val_loss: 2.0761\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6897 - val_loss: 2.0719\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6851 - val_loss: 2.0677\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6807 - val_loss: 2.0631\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6755 - val_loss: 2.0598\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6709 - val_loss: 2.0561\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6662 - val_loss: 2.0522\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6614 - val_loss: 2.0487\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6567 - val_loss: 2.0453\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.6519 - val_loss: 2.0416\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6474 - val_loss: 2.0379\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6432 - val_loss: 2.0345\n",
      "Epoch 33/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6382 - val_loss: 2.0320\n",
      "Epoch 34/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6334 - val_loss: 2.0292\n",
      "Epoch 35/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6289 - val_loss: 2.0263\n",
      "Epoch 36/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6245 - val_loss: 2.0234\n",
      "Epoch 37/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6204 - val_loss: 2.0210\n",
      "Epoch 38/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6164 - val_loss: 2.0188\n",
      "Epoch 39/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6128 - val_loss: 2.0162\n",
      "Epoch 40/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6089 - val_loss: 2.0141\n",
      "Epoch 41/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6052 - val_loss: 2.0118\n",
      "Epoch 42/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6015 - val_loss: 2.0092\n",
      "Epoch 43/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5980 - val_loss: 2.0066\n",
      "Epoch 44/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.5942 - val_loss: 2.0045\n",
      "Epoch 45/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5902 - val_loss: 2.0027\n",
      "Epoch 46/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5870 - val_loss: 2.0007\n",
      "Epoch 47/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5835 - val_loss: 1.9984\n",
      "Epoch 48/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5797 - val_loss: 1.9966\n",
      "Epoch 49/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5767 - val_loss: 1.9937\n",
      "Epoch 50/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5727 - val_loss: 1.9915\n",
      "Epoch 51/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5692 - val_loss: 1.9898\n",
      "Epoch 52/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5656 - val_loss: 1.9877\n",
      "Epoch 53/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5623 - val_loss: 1.9850\n",
      "Epoch 54/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5589 - val_loss: 1.9836\n",
      "Epoch 55/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5549 - val_loss: 1.9812\n",
      "Epoch 56/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5508 - val_loss: 1.9796\n",
      "Epoch 57/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.5472 - val_loss: 1.9774\n",
      "Epoch 58/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5435 - val_loss: 1.9750\n",
      "Epoch 59/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5396 - val_loss: 1.9728\n",
      "Epoch 60/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5357 - val_loss: 1.9713\n",
      "Epoch 61/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5321 - val_loss: 1.9692\n",
      "Epoch 62/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5286 - val_loss: 1.9671\n",
      "Epoch 63/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5244 - val_loss: 1.9656\n",
      "Epoch 64/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5212 - val_loss: 1.9636\n",
      "Epoch 65/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5176 - val_loss: 1.9617\n",
      "Epoch 66/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5141 - val_loss: 1.9598\n",
      "Epoch 67/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5105 - val_loss: 1.9583\n",
      "Epoch 68/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5071 - val_loss: 1.9570\n",
      "Epoch 69/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5036 - val_loss: 1.9551\n",
      "Epoch 70/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5001 - val_loss: 1.9538\n",
      "Epoch 71/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4959 - val_loss: 1.9520\n",
      "Epoch 72/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4928 - val_loss: 1.9504\n",
      "Epoch 73/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4892 - val_loss: 1.9488\n",
      "Epoch 74/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4857 - val_loss: 1.9477\n",
      "Epoch 75/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4827 - val_loss: 1.9462\n",
      "Epoch 76/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4792 - val_loss: 1.9450\n",
      "Epoch 77/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4761 - val_loss: 1.9436\n",
      "Epoch 78/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4728 - val_loss: 1.9422\n",
      "Epoch 79/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4693 - val_loss: 1.9409\n",
      "Epoch 80/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4665 - val_loss: 1.9394\n",
      "Epoch 81/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4629 - val_loss: 1.9381\n",
      "Epoch 82/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4599 - val_loss: 1.9365\n",
      "Epoch 83/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4568 - val_loss: 1.9352\n",
      "Epoch 84/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4535 - val_loss: 1.9339\n",
      "Epoch 85/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.4502 - val_loss: 1.9328\n",
      "Epoch 86/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4470 - val_loss: 1.9321\n",
      "Epoch 87/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4440 - val_loss: 1.9313\n",
      "Epoch 88/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4407 - val_loss: 1.9302\n",
      "Epoch 89/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4380 - val_loss: 1.9287\n",
      "Epoch 90/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4346 - val_loss: 1.9282\n",
      "Epoch 91/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4311 - val_loss: 1.9271\n",
      "Epoch 92/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4281 - val_loss: 1.9261\n",
      "Epoch 93/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4249 - val_loss: 1.9254\n",
      "Epoch 94/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4216 - val_loss: 1.9241\n",
      "Epoch 95/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4183 - val_loss: 1.9230\n",
      "Epoch 96/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4153 - val_loss: 1.9219\n",
      "Epoch 97/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4121 - val_loss: 1.9212\n",
      "Epoch 98/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4087 - val_loss: 1.9203\n",
      "Epoch 99/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4057 - val_loss: 1.9192\n",
      "Epoch 100/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4025 - val_loss: 1.9183\n",
      "Epoch 101/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3993 - val_loss: 1.9173\n",
      "Epoch 102/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3966 - val_loss: 1.9163\n",
      "Epoch 103/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3929 - val_loss: 1.9152\n",
      "Epoch 104/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3897 - val_loss: 1.9144\n",
      "Epoch 105/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3870 - val_loss: 1.9137\n",
      "Epoch 106/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3835 - val_loss: 1.9127\n",
      "Epoch 107/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3802 - val_loss: 1.9114\n",
      "Epoch 108/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3772 - val_loss: 1.9104\n",
      "Epoch 109/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3739 - val_loss: 1.9099\n",
      "Epoch 110/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.3708 - val_loss: 1.9091\n",
      "Epoch 111/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3673 - val_loss: 1.9079\n",
      "Epoch 112/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3639 - val_loss: 1.9070\n",
      "Epoch 113/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3610 - val_loss: 1.9058\n",
      "Epoch 114/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3578 - val_loss: 1.9049\n",
      "Epoch 115/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3546 - val_loss: 1.9037\n",
      "Epoch 116/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3511 - val_loss: 1.9029\n",
      "Epoch 117/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3479 - val_loss: 1.9021\n",
      "Epoch 118/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3449 - val_loss: 1.9012\n",
      "Epoch 119/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3411 - val_loss: 1.9004\n",
      "Epoch 120/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3379 - val_loss: 1.8993\n",
      "Epoch 121/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3341 - val_loss: 1.8982\n",
      "Epoch 122/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3310 - val_loss: 1.8975\n",
      "Epoch 123/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3279 - val_loss: 1.8962\n",
      "Epoch 124/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.3241 - val_loss: 1.8954\n",
      "Epoch 125/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3207 - val_loss: 1.8947\n",
      "Epoch 126/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3174 - val_loss: 1.8934\n",
      "Epoch 127/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3138 - val_loss: 1.8921\n",
      "Epoch 128/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3102 - val_loss: 1.8910\n",
      "Epoch 129/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3063 - val_loss: 1.8904\n",
      "Epoch 130/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3031 - val_loss: 1.8894\n",
      "Epoch 131/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2992 - val_loss: 1.8887\n",
      "Epoch 132/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2953 - val_loss: 1.8878\n",
      "Epoch 133/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2921 - val_loss: 1.8870\n",
      "Epoch 134/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2882 - val_loss: 1.8863\n",
      "Epoch 135/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2842 - val_loss: 1.8852\n",
      "Epoch 136/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2808 - val_loss: 1.8846\n",
      "Epoch 137/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2768 - val_loss: 1.8841\n",
      "Epoch 138/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2735 - val_loss: 1.8834\n",
      "Epoch 139/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2693 - val_loss: 1.8825\n",
      "Epoch 140/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2660 - val_loss: 1.8820\n",
      "Epoch 141/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2626 - val_loss: 1.8807\n",
      "Epoch 142/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2588 - val_loss: 1.8802\n",
      "Epoch 143/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2551 - val_loss: 1.8793\n",
      "Epoch 144/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2515 - val_loss: 1.8781\n",
      "Epoch 145/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2479 - val_loss: 1.8779\n",
      "Epoch 146/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2444 - val_loss: 1.8762\n",
      "Epoch 147/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2403 - val_loss: 1.8758\n",
      "Epoch 148/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2368 - val_loss: 1.8747\n",
      "Epoch 149/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2332 - val_loss: 1.8740\n",
      "Epoch 150/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2296 - val_loss: 1.8730\n",
      "Epoch 151/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2263 - val_loss: 1.8722\n",
      "Epoch 152/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2222 - val_loss: 1.8716\n",
      "Epoch 153/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2187 - val_loss: 1.8711\n",
      "Epoch 154/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2153 - val_loss: 1.8702\n",
      "Epoch 155/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2115 - val_loss: 1.8689\n",
      "Epoch 156/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2076 - val_loss: 1.8679\n",
      "Epoch 157/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2039 - val_loss: 1.8670\n",
      "Epoch 158/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2001 - val_loss: 1.8661\n",
      "Epoch 159/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1961 - val_loss: 1.8653\n",
      "Epoch 160/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1926 - val_loss: 1.8647\n",
      "Epoch 161/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1886 - val_loss: 1.8633\n",
      "Epoch 162/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.1851 - val_loss: 1.8627\n",
      "Epoch 163/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1809 - val_loss: 1.8621\n",
      "Epoch 164/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1778 - val_loss: 1.8611\n",
      "Epoch 165/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1735 - val_loss: 1.8602\n",
      "Epoch 166/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1697 - val_loss: 1.8592\n",
      "Epoch 167/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1656 - val_loss: 1.8582\n",
      "Epoch 168/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1619 - val_loss: 1.8571\n",
      "Epoch 169/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1580 - val_loss: 1.8566\n",
      "Epoch 170/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1552 - val_loss: 1.8564\n",
      "Epoch 171/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1505 - val_loss: 1.8553\n",
      "Epoch 172/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1466 - val_loss: 1.8549\n",
      "Epoch 173/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1430 - val_loss: 1.8549\n",
      "Epoch 174/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1389 - val_loss: 1.8542\n",
      "Epoch 175/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1354 - val_loss: 1.8541\n",
      "Epoch 176/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1314 - val_loss: 1.8528\n",
      "Epoch 177/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1274 - val_loss: 1.8524\n",
      "Epoch 178/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1233 - val_loss: 1.8517\n",
      "Epoch 179/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1198 - val_loss: 1.8513\n",
      "Epoch 180/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1162 - val_loss: 1.8515\n",
      "Epoch 181/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1122 - val_loss: 1.8513\n",
      "Epoch 182/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1081 - val_loss: 1.8507\n",
      "Epoch 183/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1046 - val_loss: 1.8507\n",
      "Epoch 184/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1006 - val_loss: 1.8504\n",
      "Epoch 185/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0968 - val_loss: 1.8502\n",
      "Epoch 186/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0931 - val_loss: 1.8505\n",
      "Epoch 187/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.0897 - val_loss: 1.8495\n",
      "Epoch 188/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0851 - val_loss: 1.8491\n",
      "Epoch 189/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0812 - val_loss: 1.8490\n",
      "Epoch 190/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0773 - val_loss: 1.8481\n",
      "Epoch 191/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0732 - val_loss: 1.8472\n",
      "Epoch 192/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0688 - val_loss: 1.8471\n",
      "Epoch 193/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0655 - val_loss: 1.8466\n",
      "Epoch 194/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0617 - val_loss: 1.8457\n",
      "Epoch 195/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0579 - val_loss: 1.8460\n",
      "Epoch 196/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0540 - val_loss: 1.8449\n",
      "Epoch 197/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0496 - val_loss: 1.8456\n",
      "Epoch 198/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0457 - val_loss: 1.8458\n",
      "Epoch 199/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0418 - val_loss: 1.8451\n",
      "Epoch 200/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0381 - val_loss: 1.8448\n",
      "Epoch 201/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0346 - val_loss: 1.8450\n",
      "Epoch 202/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0299 - val_loss: 1.8446\n",
      "Epoch 203/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0262 - val_loss: 1.8437\n",
      "Epoch 204/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0226 - val_loss: 1.8440\n",
      "Epoch 205/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0183 - val_loss: 1.8441\n",
      "Epoch 206/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0149 - val_loss: 1.8440\n",
      "Epoch 207/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0110 - val_loss: 1.8440\n",
      "Epoch 208/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0075 - val_loss: 1.8427\n",
      "Epoch 209/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0035 - val_loss: 1.8436\n",
      "Epoch 210/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.9999 - val_loss: 1.8430\n",
      "Epoch 211/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9960 - val_loss: 1.8433\n",
      "Epoch 212/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9926 - val_loss: 1.8429\n",
      "Epoch 213/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9873 - val_loss: 1.8426\n",
      "Epoch 214/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9827 - val_loss: 1.8423\n",
      "Epoch 215/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9767 - val_loss: 1.8417\n",
      "Epoch 216/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9719 - val_loss: 1.8423\n",
      "Epoch 217/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9658 - val_loss: 1.8414\n",
      "Epoch 218/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9606 - val_loss: 1.8416\n",
      "Epoch 219/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9562 - val_loss: 1.8419\n",
      "Epoch 220/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9521 - val_loss: 1.8432\n",
      "Epoch 221/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9459 - val_loss: 1.8429\n",
      "Epoch 222/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9416 - val_loss: 1.8422\n",
      "Epoch 223/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9368 - val_loss: 1.8420\n",
      "Epoch 224/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9318 - val_loss: 1.8416\n",
      "Epoch 225/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9279 - val_loss: 1.8423\n",
      "Epoch 226/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9230 - val_loss: 1.8423\n",
      "Epoch 227/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9188 - val_loss: 1.8415\n",
      "6/6 [==============================] - 0s 894us/step - loss: 2.0551\n",
      "[CV] END .....learning_rate=0.0001, n_hidden=3, n_neurons=13; total time=   8.8s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 10ms/step - loss: 2.9114 - val_loss: 2.5123\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.8875 - val_loss: 2.4933\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.8663 - val_loss: 2.4741\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.8462 - val_loss: 2.4560\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.8264 - val_loss: 2.4390\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.8082 - val_loss: 2.4221\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7896 - val_loss: 2.4073\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7737 - val_loss: 2.3923\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7573 - val_loss: 2.3786\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7422 - val_loss: 2.3663\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7273 - val_loss: 2.3536\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7129 - val_loss: 2.3415\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7005 - val_loss: 2.3289\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6883 - val_loss: 2.3175\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6764 - val_loss: 2.3086\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.6664 - val_loss: 2.2987\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6561 - val_loss: 2.2912\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6460 - val_loss: 2.2825\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6365 - val_loss: 2.2738\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6272 - val_loss: 2.2644\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6177 - val_loss: 2.2571\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6091 - val_loss: 2.2501\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6009 - val_loss: 2.2431\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5930 - val_loss: 2.2365\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5851 - val_loss: 2.2308\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5776 - val_loss: 2.2248\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5697 - val_loss: 2.2197\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.5628 - val_loss: 2.2139\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5548 - val_loss: 2.2089\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5480 - val_loss: 2.2038\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5406 - val_loss: 2.2001\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5340 - val_loss: 2.1952\n",
      "Epoch 33/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5269 - val_loss: 2.1911\n",
      "Epoch 34/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5209 - val_loss: 2.1873\n",
      "Epoch 35/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5142 - val_loss: 2.1831\n",
      "Epoch 36/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5078 - val_loss: 2.1786\n",
      "Epoch 37/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5019 - val_loss: 2.1744\n",
      "Epoch 38/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4959 - val_loss: 2.1717\n",
      "Epoch 39/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4904 - val_loss: 2.1678\n",
      "Epoch 40/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4845 - val_loss: 2.1641\n",
      "Epoch 41/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4787 - val_loss: 2.1607\n",
      "Epoch 42/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4739 - val_loss: 2.1574\n",
      "Epoch 43/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4683 - val_loss: 2.1546\n",
      "Epoch 44/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4635 - val_loss: 2.1519\n",
      "Epoch 45/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4590 - val_loss: 2.1489\n",
      "Epoch 46/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4539 - val_loss: 2.1462\n",
      "Epoch 47/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4495 - val_loss: 2.1435\n",
      "Epoch 48/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4450 - val_loss: 2.1417\n",
      "Epoch 49/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4402 - val_loss: 2.1394\n",
      "Epoch 50/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4360 - val_loss: 2.1373\n",
      "Epoch 51/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4318 - val_loss: 2.1349\n",
      "Epoch 52/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.4270 - val_loss: 2.1329\n",
      "Epoch 53/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4225 - val_loss: 2.1305\n",
      "Epoch 54/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4186 - val_loss: 2.1278\n",
      "Epoch 55/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4140 - val_loss: 2.1259\n",
      "Epoch 56/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4101 - val_loss: 2.1235\n",
      "Epoch 57/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4053 - val_loss: 2.1215\n",
      "Epoch 58/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4017 - val_loss: 2.1193\n",
      "Epoch 59/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3980 - val_loss: 2.1169\n",
      "Epoch 60/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3936 - val_loss: 2.1152\n",
      "Epoch 61/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3895 - val_loss: 2.1129\n",
      "Epoch 62/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3854 - val_loss: 2.1105\n",
      "Epoch 63/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3814 - val_loss: 2.1082\n",
      "Epoch 64/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3775 - val_loss: 2.1053\n",
      "Epoch 65/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3729 - val_loss: 2.1033\n",
      "Epoch 66/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3695 - val_loss: 2.1010\n",
      "Epoch 67/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3653 - val_loss: 2.0989\n",
      "Epoch 68/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3617 - val_loss: 2.0962\n",
      "Epoch 69/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3575 - val_loss: 2.0946\n",
      "Epoch 70/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3537 - val_loss: 2.0929\n",
      "Epoch 71/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3499 - val_loss: 2.0903\n",
      "Epoch 72/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3455 - val_loss: 2.0883\n",
      "Epoch 73/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3414 - val_loss: 2.0862\n",
      "Epoch 74/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3379 - val_loss: 2.0854\n",
      "Epoch 75/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3329 - val_loss: 2.0835\n",
      "Epoch 76/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3289 - val_loss: 2.0813\n",
      "Epoch 77/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3248 - val_loss: 2.0795\n",
      "Epoch 78/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3203 - val_loss: 2.0775\n",
      "Epoch 79/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3165 - val_loss: 2.0757\n",
      "Epoch 80/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3124 - val_loss: 2.0743\n",
      "Epoch 81/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3082 - val_loss: 2.0730\n",
      "Epoch 82/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3037 - val_loss: 2.0715\n",
      "Epoch 83/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2994 - val_loss: 2.0699\n",
      "Epoch 84/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2952 - val_loss: 2.0679\n",
      "Epoch 85/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2909 - val_loss: 2.0665\n",
      "Epoch 86/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2868 - val_loss: 2.0650\n",
      "Epoch 87/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2824 - val_loss: 2.0634\n",
      "Epoch 88/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.2785 - val_loss: 2.0620\n",
      "Epoch 89/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2743 - val_loss: 2.0608\n",
      "Epoch 90/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2699 - val_loss: 2.0597\n",
      "Epoch 91/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2665 - val_loss: 2.0584\n",
      "Epoch 92/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2619 - val_loss: 2.0570\n",
      "Epoch 93/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2573 - val_loss: 2.0557\n",
      "Epoch 94/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2531 - val_loss: 2.0542\n",
      "Epoch 95/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2497 - val_loss: 2.0525\n",
      "Epoch 96/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2443 - val_loss: 2.0513\n",
      "Epoch 97/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2406 - val_loss: 2.0500\n",
      "Epoch 98/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2364 - val_loss: 2.0484\n",
      "Epoch 99/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2325 - val_loss: 2.0471\n",
      "Epoch 100/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2286 - val_loss: 2.0454\n",
      "Epoch 101/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2244 - val_loss: 2.0438\n",
      "Epoch 102/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2200 - val_loss: 2.0423\n",
      "Epoch 103/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2164 - val_loss: 2.0410\n",
      "Epoch 104/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2123 - val_loss: 2.0400\n",
      "Epoch 105/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2087 - val_loss: 2.0385\n",
      "Epoch 106/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2048 - val_loss: 2.0374\n",
      "Epoch 107/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2008 - val_loss: 2.0360\n",
      "Epoch 108/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1970 - val_loss: 2.0345\n",
      "Epoch 109/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1935 - val_loss: 2.0337\n",
      "Epoch 110/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1903 - val_loss: 2.0326\n",
      "Epoch 111/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1861 - val_loss: 2.0316\n",
      "Epoch 112/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1818 - val_loss: 2.0303\n",
      "Epoch 113/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1781 - val_loss: 2.0290\n",
      "Epoch 114/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1752 - val_loss: 2.0279\n",
      "Epoch 115/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1703 - val_loss: 2.0273\n",
      "Epoch 116/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1668 - val_loss: 2.0266\n",
      "Epoch 117/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1631 - val_loss: 2.0257\n",
      "Epoch 118/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1594 - val_loss: 2.0249\n",
      "Epoch 119/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1555 - val_loss: 2.0242\n",
      "Epoch 120/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1521 - val_loss: 2.0234\n",
      "Epoch 121/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1481 - val_loss: 2.0228\n",
      "Epoch 122/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1447 - val_loss: 2.0220\n",
      "Epoch 123/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1412 - val_loss: 2.0211\n",
      "Epoch 124/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1378 - val_loss: 2.0205\n",
      "Epoch 125/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1340 - val_loss: 2.0194\n",
      "Epoch 126/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1306 - val_loss: 2.0188\n",
      "Epoch 127/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1269 - val_loss: 2.0180\n",
      "Epoch 128/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.1235 - val_loss: 2.0173\n",
      "Epoch 129/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1198 - val_loss: 2.0167\n",
      "Epoch 130/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1162 - val_loss: 2.0161\n",
      "Epoch 131/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1124 - val_loss: 2.0152\n",
      "Epoch 132/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1087 - val_loss: 2.0144\n",
      "Epoch 133/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1049 - val_loss: 2.0133\n",
      "Epoch 134/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1010 - val_loss: 2.0130\n",
      "Epoch 135/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0965 - val_loss: 2.0119\n",
      "Epoch 136/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0931 - val_loss: 2.0112\n",
      "Epoch 137/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.0889 - val_loss: 2.0099\n",
      "Epoch 138/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0852 - val_loss: 2.0090\n",
      "Epoch 139/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0816 - val_loss: 2.0076\n",
      "Epoch 140/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0776 - val_loss: 2.0073\n",
      "Epoch 141/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0739 - val_loss: 2.0060\n",
      "Epoch 142/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0701 - val_loss: 2.0050\n",
      "Epoch 143/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0654 - val_loss: 2.0035\n",
      "Epoch 144/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0617 - val_loss: 2.0023\n",
      "Epoch 145/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0578 - val_loss: 2.0022\n",
      "Epoch 146/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0535 - val_loss: 2.0008\n",
      "Epoch 147/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0498 - val_loss: 2.0000\n",
      "Epoch 148/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0457 - val_loss: 1.9988\n",
      "Epoch 149/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0412 - val_loss: 1.9975\n",
      "Epoch 150/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0375 - val_loss: 1.9965\n",
      "Epoch 151/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0336 - val_loss: 1.9950\n",
      "Epoch 152/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0296 - val_loss: 1.9939\n",
      "Epoch 153/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0256 - val_loss: 1.9925\n",
      "Epoch 154/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0214 - val_loss: 1.9914\n",
      "Epoch 155/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0176 - val_loss: 1.9909\n",
      "Epoch 156/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0134 - val_loss: 1.9895\n",
      "Epoch 157/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0106 - val_loss: 1.9884\n",
      "Epoch 158/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0057 - val_loss: 1.9871\n",
      "Epoch 159/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0018 - val_loss: 1.9856\n",
      "Epoch 160/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9980 - val_loss: 1.9849\n",
      "Epoch 161/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9942 - val_loss: 1.9840\n",
      "Epoch 162/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9897 - val_loss: 1.9822\n",
      "Epoch 163/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9859 - val_loss: 1.9812\n",
      "Epoch 164/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9820 - val_loss: 1.9800\n",
      "Epoch 165/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9787 - val_loss: 1.9792\n",
      "Epoch 166/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9746 - val_loss: 1.9785\n",
      "Epoch 167/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9700 - val_loss: 1.9772\n",
      "Epoch 168/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9664 - val_loss: 1.9762\n",
      "Epoch 169/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9627 - val_loss: 1.9751\n",
      "Epoch 170/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9587 - val_loss: 1.9740\n",
      "Epoch 171/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9547 - val_loss: 1.9727\n",
      "Epoch 172/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9511 - val_loss: 1.9718\n",
      "Epoch 173/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9478 - val_loss: 1.9707\n",
      "Epoch 174/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9433 - val_loss: 1.9693\n",
      "Epoch 175/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9399 - val_loss: 1.9682\n",
      "Epoch 176/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9363 - val_loss: 1.9671\n",
      "Epoch 177/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9323 - val_loss: 1.9666\n",
      "Epoch 178/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9279 - val_loss: 1.9651\n",
      "Epoch 179/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9248 - val_loss: 1.9641\n",
      "Epoch 180/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9206 - val_loss: 1.9634\n",
      "Epoch 181/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9174 - val_loss: 1.9625\n",
      "Epoch 182/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9129 - val_loss: 1.9611\n",
      "Epoch 183/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.9093 - val_loss: 1.9593\n",
      "Epoch 184/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9056 - val_loss: 1.9580\n",
      "Epoch 185/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9020 - val_loss: 1.9575\n",
      "Epoch 186/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8978 - val_loss: 1.9562\n",
      "Epoch 187/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8944 - val_loss: 1.9551\n",
      "Epoch 188/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8908 - val_loss: 1.9542\n",
      "Epoch 189/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8872 - val_loss: 1.9517\n",
      "Epoch 190/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8839 - val_loss: 1.9511\n",
      "Epoch 191/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8799 - val_loss: 1.9504\n",
      "Epoch 192/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.8763 - val_loss: 1.9491\n",
      "Epoch 193/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8726 - val_loss: 1.9478\n",
      "Epoch 194/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8689 - val_loss: 1.9471\n",
      "Epoch 195/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8652 - val_loss: 1.9455\n",
      "Epoch 196/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8618 - val_loss: 1.9443\n",
      "Epoch 197/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8581 - val_loss: 1.9432\n",
      "Epoch 198/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8546 - val_loss: 1.9425\n",
      "Epoch 199/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8508 - val_loss: 1.9415\n",
      "Epoch 200/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8471 - val_loss: 1.9405\n",
      "Epoch 201/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.8437 - val_loss: 1.9381\n",
      "Epoch 202/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8404 - val_loss: 1.9376\n",
      "Epoch 203/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8365 - val_loss: 1.9361\n",
      "Epoch 204/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8325 - val_loss: 1.9352\n",
      "Epoch 205/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8295 - val_loss: 1.9337\n",
      "Epoch 206/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8254 - val_loss: 1.9332\n",
      "Epoch 207/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8220 - val_loss: 1.9319\n",
      "Epoch 208/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8182 - val_loss: 1.9308\n",
      "Epoch 209/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8152 - val_loss: 1.9306\n",
      "Epoch 210/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8113 - val_loss: 1.9286\n",
      "Epoch 211/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8074 - val_loss: 1.9275\n",
      "Epoch 212/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8039 - val_loss: 1.9266\n",
      "Epoch 213/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8000 - val_loss: 1.9256\n",
      "Epoch 214/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7970 - val_loss: 1.9244\n",
      "Epoch 215/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7938 - val_loss: 1.9233\n",
      "Epoch 216/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7894 - val_loss: 1.9221\n",
      "Epoch 217/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7857 - val_loss: 1.9217\n",
      "Epoch 218/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7818 - val_loss: 1.9203\n",
      "Epoch 219/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7785 - val_loss: 1.9187\n",
      "Epoch 220/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7754 - val_loss: 1.9177\n",
      "Epoch 221/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7714 - val_loss: 1.9177\n",
      "Epoch 222/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7678 - val_loss: 1.9166\n",
      "Epoch 223/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.7640 - val_loss: 1.9163\n",
      "Epoch 224/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7607 - val_loss: 1.9155\n",
      "Epoch 225/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7564 - val_loss: 1.9144\n",
      "Epoch 226/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7525 - val_loss: 1.9131\n",
      "Epoch 227/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7489 - val_loss: 1.9129\n",
      "Epoch 228/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7453 - val_loss: 1.9121\n",
      "Epoch 229/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7417 - val_loss: 1.9116\n",
      "Epoch 230/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7383 - val_loss: 1.9099\n",
      "Epoch 231/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7340 - val_loss: 1.9096\n",
      "Epoch 232/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7300 - val_loss: 1.9081\n",
      "Epoch 233/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.7265 - val_loss: 1.9074\n",
      "Epoch 234/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7223 - val_loss: 1.9072\n",
      "Epoch 235/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7189 - val_loss: 1.9060\n",
      "Epoch 236/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7147 - val_loss: 1.9059\n",
      "Epoch 237/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7109 - val_loss: 1.9042\n",
      "Epoch 238/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7070 - val_loss: 1.9039\n",
      "Epoch 239/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7036 - val_loss: 1.9032\n",
      "Epoch 240/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6996 - val_loss: 1.9021\n",
      "Epoch 241/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6962 - val_loss: 1.9018\n",
      "Epoch 242/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.6919 - val_loss: 1.9002\n",
      "Epoch 243/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6879 - val_loss: 1.9003\n",
      "Epoch 244/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6845 - val_loss: 1.8994\n",
      "Epoch 245/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6806 - val_loss: 1.8988\n",
      "Epoch 246/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6765 - val_loss: 1.8985\n",
      "Epoch 247/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6728 - val_loss: 1.8979\n",
      "Epoch 248/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6687 - val_loss: 1.8968\n",
      "Epoch 249/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6653 - val_loss: 1.8964\n",
      "Epoch 250/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6617 - val_loss: 1.8962\n",
      "Epoch 251/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6577 - val_loss: 1.8954\n",
      "Epoch 252/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6540 - val_loss: 1.8953\n",
      "Epoch 253/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6520 - val_loss: 1.8939\n",
      "Epoch 254/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6466 - val_loss: 1.8943\n",
      "Epoch 255/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6429 - val_loss: 1.8932\n",
      "Epoch 256/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6397 - val_loss: 1.8939\n",
      "Epoch 257/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6357 - val_loss: 1.8932\n",
      "Epoch 258/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6322 - val_loss: 1.8934\n",
      "Epoch 259/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6288 - val_loss: 1.8921\n",
      "Epoch 260/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6245 - val_loss: 1.8921\n",
      "Epoch 261/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6210 - val_loss: 1.8910\n",
      "Epoch 262/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6177 - val_loss: 1.8910\n",
      "Epoch 263/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.6146 - val_loss: 1.8913\n",
      "Epoch 264/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6108 - val_loss: 1.8902\n",
      "Epoch 265/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6065 - val_loss: 1.8904\n",
      "Epoch 266/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6035 - val_loss: 1.8899\n",
      "Epoch 267/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5999 - val_loss: 1.8906\n",
      "Epoch 268/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5963 - val_loss: 1.8902\n",
      "Epoch 269/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5927 - val_loss: 1.8902\n",
      "Epoch 270/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5901 - val_loss: 1.8887\n",
      "Epoch 271/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5863 - val_loss: 1.8890\n",
      "Epoch 272/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5836 - val_loss: 1.8892\n",
      "Epoch 273/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5791 - val_loss: 1.8895\n",
      "Epoch 274/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5759 - val_loss: 1.8888\n",
      "Epoch 275/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5723 - val_loss: 1.8890\n",
      "Epoch 276/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5692 - val_loss: 1.8887\n",
      "Epoch 277/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5656 - val_loss: 1.8890\n",
      "Epoch 278/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5623 - val_loss: 1.8895\n",
      "Epoch 279/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5594 - val_loss: 1.8891\n",
      "Epoch 280/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5556 - val_loss: 1.8888\n",
      "6/6 [==============================] - 0s 997us/step - loss: 2.4020\n",
      "[CV] END .....learning_rate=0.0001, n_hidden=3, n_neurons=13; total time=  10.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.6591 - val_loss: 2.0070\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5001 - val_loss: 1.9733\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4109 - val_loss: 1.9372\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3259 - val_loss: 1.9060\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2603 - val_loss: 1.8789\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1875 - val_loss: 1.8574\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1259 - val_loss: 1.8397\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0577 - val_loss: 1.8215\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0016 - val_loss: 1.8034\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9289 - val_loss: 1.7892\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8754 - val_loss: 1.7797\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.8139 - val_loss: 1.7639\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7515 - val_loss: 1.7458\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6935 - val_loss: 1.7395\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6425 - val_loss: 1.7320\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5900 - val_loss: 1.7199\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5365 - val_loss: 1.7213\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4938 - val_loss: 1.7091\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4455 - val_loss: 1.7046\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4072 - val_loss: 1.7072\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.3624 - val_loss: 1.7104\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3295 - val_loss: 1.7081\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3023 - val_loss: 1.7014\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2621 - val_loss: 1.7047\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2274 - val_loss: 1.6864\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1887 - val_loss: 1.6927\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1575 - val_loss: 1.6877\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1357 - val_loss: 1.6860\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0986 - val_loss: 1.7110\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0716 - val_loss: 1.7105\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0488 - val_loss: 1.7148\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0282 - val_loss: 1.7186\n",
      "Epoch 33/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9823 - val_loss: 1.7639\n",
      "Epoch 34/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9760 - val_loss: 1.7174\n",
      "Epoch 35/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9426 - val_loss: 1.7414\n",
      "Epoch 36/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9202 - val_loss: 1.7345\n",
      "Epoch 37/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8923 - val_loss: 1.7336\n",
      "Epoch 38/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8836 - val_loss: 1.7350\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 2.1754\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=2, n_neurons=27; total time=   1.9s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 10ms/step - loss: 2.7470 - val_loss: 2.0533\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5693 - val_loss: 1.9768\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4413 - val_loss: 1.9197\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3312 - val_loss: 1.8918\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2453 - val_loss: 1.8639\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1499 - val_loss: 1.8470\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0765 - val_loss: 1.8326\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9834 - val_loss: 1.8267\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.9103 - val_loss: 1.8234\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8437 - val_loss: 1.8258\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7843 - val_loss: 1.8083\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7297 - val_loss: 1.8270\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6741 - val_loss: 1.8121\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6227 - val_loss: 1.8285\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5838 - val_loss: 1.8267\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5349 - val_loss: 1.8172\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.4974 - val_loss: 1.8101\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4576 - val_loss: 1.8059\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4179 - val_loss: 1.8065\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3961 - val_loss: 1.8121\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3464 - val_loss: 1.7886\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3134 - val_loss: 1.7758\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2867 - val_loss: 1.7774\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2412 - val_loss: 1.7659\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2061 - val_loss: 1.7522\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1711 - val_loss: 1.7623\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1365 - val_loss: 1.7494\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1049 - val_loss: 1.7462\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0705 - val_loss: 1.7341\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0416 - val_loss: 1.7379\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0072 - val_loss: 1.7344\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9861 - val_loss: 1.7290\n",
      "Epoch 33/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9581 - val_loss: 1.7587\n",
      "Epoch 34/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9321 - val_loss: 1.7150\n",
      "Epoch 35/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9040 - val_loss: 1.7578\n",
      "Epoch 36/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8794 - val_loss: 1.7546\n",
      "Epoch 37/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.8671 - val_loss: 1.7334\n",
      "Epoch 38/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8364 - val_loss: 1.7411\n",
      "Epoch 39/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8095 - val_loss: 1.7494\n",
      "Epoch 40/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8045 - val_loss: 1.7473\n",
      "Epoch 41/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7727 - val_loss: 1.7681\n",
      "Epoch 42/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7520 - val_loss: 1.7350\n",
      "Epoch 43/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7377 - val_loss: 1.7836\n",
      "Epoch 44/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7227 - val_loss: 1.7845\n",
      "6/6 [==============================] - 0s 992us/step - loss: 1.7913\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=2, n_neurons=27; total time=   2.1s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.7046 - val_loss: 2.1388\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4823 - val_loss: 2.0410\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.3502 - val_loss: 1.9800\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2694 - val_loss: 1.9367\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1996 - val_loss: 1.8977\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1307 - val_loss: 1.8615\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.0608 - val_loss: 1.8315\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9903 - val_loss: 1.7978\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9270 - val_loss: 1.7675\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8617 - val_loss: 1.7409\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8030 - val_loss: 1.7163\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7322 - val_loss: 1.6908\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6851 - val_loss: 1.6708\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6214 - val_loss: 1.6508\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.5749 - val_loss: 1.6432\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5184 - val_loss: 1.6315\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4731 - val_loss: 1.6225\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4235 - val_loss: 1.6075\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3734 - val_loss: 1.5950\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3309 - val_loss: 1.5947\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2923 - val_loss: 1.5978\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2529 - val_loss: 1.5931\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.2118 - val_loss: 1.6048\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1744 - val_loss: 1.5956\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1401 - val_loss: 1.5919\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1055 - val_loss: 1.5760\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0748 - val_loss: 1.5998\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0388 - val_loss: 1.6351\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0168 - val_loss: 1.6226\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9839 - val_loss: 1.6376\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9650 - val_loss: 1.6481\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9464 - val_loss: 1.6718\n",
      "Epoch 33/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9143 - val_loss: 1.6596\n",
      "Epoch 34/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8985 - val_loss: 1.6726\n",
      "Epoch 35/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8691 - val_loss: 1.6521\n",
      "Epoch 36/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8583 - val_loss: 1.6683\n",
      "6/6 [==============================] - 0s 893us/step - loss: 2.0058\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=2, n_neurons=27; total time=   1.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.6903 - val_loss: 1.9138\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.2079 - val_loss: 1.8749\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9726 - val_loss: 1.8046\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7537 - val_loss: 1.7214\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5960 - val_loss: 1.8092\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5022 - val_loss: 1.6653\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3025 - val_loss: 1.6849\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1904 - val_loss: 1.7003\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1048 - val_loss: 1.7470\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0296 - val_loss: 1.7056\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9440 - val_loss: 1.7583\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9722 - val_loss: 1.7546\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8780 - val_loss: 1.8855\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8222 - val_loss: 1.8621\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7317 - val_loss: 1.8294\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7320 - val_loss: 1.8329\n",
      "6/6 [==============================] - 0s 898us/step - loss: 2.4440\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=2, n_neurons=90; total time=   1.1s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.8438 - val_loss: 1.9450\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2419 - val_loss: 1.8678\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9453 - val_loss: 1.8310\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7086 - val_loss: 1.8160\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5343 - val_loss: 1.8156\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3933 - val_loss: 1.7493\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2617 - val_loss: 1.8038\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1815 - val_loss: 1.7289\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.0311 - val_loss: 1.7153\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9956 - val_loss: 1.7004\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9011 - val_loss: 1.6786\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8396 - val_loss: 1.6942\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7842 - val_loss: 1.6472\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7357 - val_loss: 1.8076\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7683 - val_loss: 1.6562\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6340 - val_loss: 1.6068\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6416 - val_loss: 1.6270\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6245 - val_loss: 1.6255\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5494 - val_loss: 1.6960\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5416 - val_loss: 1.6441\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4931 - val_loss: 1.5972\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4648 - val_loss: 1.6054\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4617 - val_loss: 1.6541\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4469 - val_loss: 1.6215\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4128 - val_loss: 1.7186\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3993 - val_loss: 1.7018\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3834 - val_loss: 1.5960\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3638 - val_loss: 1.6100\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3164 - val_loss: 1.7118\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3209 - val_loss: 1.5976\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2912 - val_loss: 1.7412\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3222 - val_loss: 1.7206\n",
      "Epoch 33/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2993 - val_loss: 1.7158\n",
      "Epoch 34/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2940 - val_loss: 1.7593\n",
      "Epoch 35/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3155 - val_loss: 1.5804\n",
      "Epoch 36/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3158 - val_loss: 1.8448\n",
      "Epoch 37/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2670 - val_loss: 1.6319\n",
      "Epoch 38/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2606 - val_loss: 1.7769\n",
      "Epoch 39/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2398 - val_loss: 1.5892\n",
      "Epoch 40/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2681 - val_loss: 1.8289\n",
      "Epoch 41/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2712 - val_loss: 1.6362\n",
      "Epoch 42/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2246 - val_loss: 1.7495\n",
      "Epoch 43/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2092 - val_loss: 1.7182\n",
      "Epoch 44/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2354 - val_loss: 1.7030\n",
      "Epoch 45/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2268 - val_loss: 1.8350\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.8494\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=2, n_neurons=90; total time=   2.1s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.5832 - val_loss: 1.9980\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0641 - val_loss: 1.8694\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7929 - val_loss: 1.8592\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.6196 - val_loss: 1.7871\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4707 - val_loss: 1.7328\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3196 - val_loss: 1.7072\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2282 - val_loss: 1.7464\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1214 - val_loss: 1.6833\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0519 - val_loss: 1.7985\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9849 - val_loss: 1.7500\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9887 - val_loss: 1.6671\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8722 - val_loss: 1.7734\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8188 - val_loss: 1.7486\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.9025 - val_loss: 1.8005\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7935 - val_loss: 1.7281\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7086 - val_loss: 1.7033\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6364 - val_loss: 1.7681\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6709 - val_loss: 1.6734\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5864 - val_loss: 1.7029\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5691 - val_loss: 1.7568\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5355 - val_loss: 1.7442\n",
      "6/6 [==============================] - 0s 997us/step - loss: 1.8427\n",
      "[CV] END .....learning_rate=0.0021, n_hidden=2, n_neurons=90; total time=   1.3s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.6472 - val_loss: 1.9651\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4062 - val_loss: 1.8810\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.1567 - val_loss: 1.7382\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.8468 - val_loss: 1.6305\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5241 - val_loss: 1.6188\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3790 - val_loss: 1.6758\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1325 - val_loss: 1.7154\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9589 - val_loss: 1.6984\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8350 - val_loss: 1.8224\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7598 - val_loss: 1.8222\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6265 - val_loss: 1.9439\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6511 - val_loss: 1.9465\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5376 - val_loss: 1.9431\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5632 - val_loss: 1.9340\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4818 - val_loss: 1.7967\n",
      "6/6 [==============================] - 0s 898us/step - loss: 1.5940\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=5, n_neurons=85; total time=   1.4s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 12ms/step - loss: 2.7248 - val_loss: 1.9106\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.3644 - val_loss: 1.8636\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0149 - val_loss: 1.9695\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.7714 - val_loss: 2.0556\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4955 - val_loss: 1.8999\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2985 - val_loss: 1.9255\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1189 - val_loss: 1.9346\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9630 - val_loss: 1.7959\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8155 - val_loss: 1.8246\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7554 - val_loss: 1.8387\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6736 - val_loss: 1.7116\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5551 - val_loss: 1.8911\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4848 - val_loss: 1.9260\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5024 - val_loss: 1.8932\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5167 - val_loss: 1.9237\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5276 - val_loss: 1.8960\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4639 - val_loss: 1.9193\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4389 - val_loss: 1.8414\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3776 - val_loss: 2.0125\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3413 - val_loss: 1.7713\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2871 - val_loss: 1.9130\n",
      "6/6 [==============================] - 0s 965us/step - loss: 1.9448\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=5, n_neurons=85; total time=   1.6s\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 2.4940 - val_loss: 1.9961\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2757 - val_loss: 1.8562\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.0263 - val_loss: 1.7565\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.7555 - val_loss: 1.6987\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5614 - val_loss: 1.5795\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3686 - val_loss: 1.5518\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.2585 - val_loss: 1.5201\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0072 - val_loss: 1.6321\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8738 - val_loss: 1.6729\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.7861 - val_loss: 1.5995\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6902 - val_loss: 1.5419\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6295 - val_loss: 1.6639\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5744 - val_loss: 1.5912\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7660 - val_loss: 1.8458\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7157 - val_loss: 1.5436\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6505 - val_loss: 1.5764\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5324 - val_loss: 1.7407\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1.8346\n",
      "[CV] END .....learning_rate=0.0011, n_hidden=5, n_neurons=85; total time=   1.6s\n",
      "Epoch 1/300\n",
      "18/18 [==============================] - 1s 7ms/step - loss: 2.6231 - val_loss: 1.8434\n",
      "Epoch 2/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2041 - val_loss: 1.7244\n",
      "Epoch 3/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.8796 - val_loss: 1.5384\n",
      "Epoch 4/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.5523 - val_loss: 1.6657\n",
      "Epoch 5/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4546 - val_loss: 1.6861\n",
      "Epoch 6/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4624 - val_loss: 1.6757\n",
      "Epoch 7/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1106 - val_loss: 1.5005\n",
      "Epoch 8/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9881 - val_loss: 1.5586\n",
      "Epoch 9/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9945 - val_loss: 1.5636\n",
      "Epoch 10/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7826 - val_loss: 1.7099\n",
      "Epoch 11/300\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7387 - val_loss: 1.6434\n",
      "Epoch 12/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6729 - val_loss: 1.7468\n",
      "Epoch 13/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7532 - val_loss: 1.5042\n",
      "Epoch 14/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6248 - val_loss: 1.5727\n",
      "Epoch 15/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5862 - val_loss: 1.6667\n",
      "Epoch 16/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5966 - val_loss: 1.6424\n",
      "Epoch 17/300\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7109 - val_loss: 1.8573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=3,\n",
       "              estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x000002C87FD6A5E0>,\n",
       "              n_iter=10,\n",
       "              search_spaces={'learning_rate': array([0.0001, 0.0011, 0.0021]),\n",
       "                             'n_hidden': [2, 3, 4, 5, 6],\n",
       "                             'n_neurons': array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,\n",
       "       27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43,\n",
       "       44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n",
       "       61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77,\n",
       "       78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94,\n",
       "       95, 96, 97, 98, 99])},\n",
       "              verbose=2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import skopt\n",
    "\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [2,3, 4, 5, 6],\n",
    "    \"n_neurons\": np.arange(10,100),\n",
    "    \"learning_rate\": np.arange(0.0001, 0.003, 0.001),\n",
    "}\n",
    "\n",
    "bayes_search_cv = skopt.BayesSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "bayes_search_cv.fit(X_train3, y_train3, epochs=300,\n",
    "                  validation_data=(X_test3, y_test3),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('learning_rate', 0.0021), ('n_hidden', 4), ('n_neurons', 77)])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.7640119791030884"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 868us/step - loss: 1.8573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.8573025465011597"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_search_cv.score(X_test3, y_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_313 (Dense)           (None, 77)                5159      \n",
      "                                                                 \n",
      " dense_314 (Dense)           (None, 77)                6006      \n",
      "                                                                 \n",
      " dense_315 (Dense)           (None, 77)                6006      \n",
      "                                                                 \n",
      " dense_316 (Dense)           (None, 77)                6006      \n",
      "                                                                 \n",
      " dense_317 (Dense)           (None, 1)                 78        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,255\n",
      "Trainable params: 23,255\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = bayes_search_cv.best_estimator_.model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 844us/step - loss: 1.8573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.8573025465011597"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test3, y_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3627178724886526"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(1.857)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
